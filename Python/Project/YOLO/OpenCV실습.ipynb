{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb92644",
   "metadata": {},
   "source": [
    "# OpenCV 체험 학습 - 컴퓨터 비전의 첫걸음\n",
    "\n",
    "## 🎥 OpenCV 체험 학습에 오신 것을 환영합니다!\n",
    "\n",
    "### 🎯 학습 목표\n",
    "오늘은 컴퓨터 비전의 핵심 도구인 OpenCV를 직접 체험해보겠습니다. \n",
    "마치 포토샵을 프로그래밍으로 다루는 것처럼, 이미지와 영상을 코드로 조작하는 \n",
    "놀라운 세계를 경험해보세요!\n",
    "\n",
    "### 📚 OpenCV란?\n",
    "- **Open Source Computer Vision Library**의 줄임말\n",
    "- 이미지 처리와 컴퓨터 비전을 위한 최강의 라이브러리\n",
    "- 전 세계 개발자들이 가장 많이 사용하는 비전 도구\n",
    "- 인스타그램 필터부터 자율주행차까지 모든 곳에서 활용\n",
    "\n",
    "### 🛠️ 오늘 배울 내용\n",
    "1. 웹캠과 이미지 다루기\n",
    "2. 색상과 필터 조작\n",
    "3. 도형 그리기와 텍스트 표시\n",
    "4. 실시간 이미지 변환\n",
    "5. 간단한 얼굴 인식\n",
    "6. 미니 포토 에디터 만들기\n",
    "\n",
    "### 💡 실생활 응용\n",
    "- SNS 필터 효과\n",
    "- 보안 카메라 시스템\n",
    "- 의료 영상 분석\n",
    "- 제품 품질 검사\n",
    "- 증강현실(AR) 앱\n",
    "\n",
    "자, 이제 디지털 세상을 마음대로 조작하는 마법사가 되어보세요! ✨\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a327de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 환경 설정 및 기본 확인\n",
    "# =============================================================================\n",
    "# 필요한 라이브러리 불러오기\n",
    "import cv2  # OpenCV - 컴퓨터 비전의 핵심 도구임\n",
    "# OpenCV는 이미지와 영상 처리를 위한 가장 유명한 라이브러리임\n",
    "# 웹캠에서 영상을 읽고, 얼굴을 검출하고, 결과를 화면에 보여주는 모든 기능을 제공함\n",
    "# cv2라는 이름으로 import하는 것이 파이썬에서의 관례임\n",
    "\n",
    "import numpy as np  # 수치 연산 라이브러리 (별명 np로 줄여서 사용)\n",
    "# numpy는 숫자 배열을 다루는 라이브러리임\n",
    "# 이미지는 실제로 픽셀값들의 숫자 배열로 표현되므로 이미지 처리에 필수임\n",
    "# OpenCV의 모든 이미지 데이터는 numpy 배열 형태로 저장됨\n",
    "# np라는 짧은 이름으로 사용하는 것이 일반적인 관례임\n",
    "\n",
    "import matplotlib.pyplot as plt  # 그래프와 이미지를 예쁘게 표시하는 도구\n",
    "# matplotlib는 데이터 시각화를 위한 라이브러리임\n",
    "# pyplot 모듈은 그래프나 이미지를 화면에 보여주는 기능을 제공함\n",
    "# plt라는 별명으로 사용하는 것이 표준 관례임\n",
    "# OpenCV와 함께 사용하면 더 깔끔한 결과 화면을 만들 수 있음\n",
    "\n",
    "import time  # 시간 측정용 라이브러리\n",
    "# time 모듈은 시간과 관련된 기능들을 제공함\n",
    "# 프로그램 실행 시간 측정, 딜레이 주기, 현재 시간 확인 등에 사용됨\n",
    "# 성능 체크나 파일명에 타임스탬프 넣을 때 필요함\n",
    "\n",
    "# OpenCV 설치 확인 및 버전 출력\n",
    "print(\"🎥 OpenCV 체험 학습 시작!\")  # 환영 메시지 출력\n",
    "# print() 함수는 괄호 안의 내용을 화면에 출력하는 함수임\n",
    "# 🎥 이모지는 영상/카메라와 관련된 직관적인 아이콘임\n",
    "\n",
    "print(\"=\"*30)  # 구분선 그리기\n",
    "# \"=\"*30은 = 문자를 30번 반복해서 출력하는 것임\n",
    "# 문자열 * 숫자 연산은 해당 문자열을 숫자만큼 반복함\n",
    "# 시각적으로 구분선을 만들어서 화면을 정리하고 가독성을 높임\n",
    "\n",
    "# f-string을 사용해서 설치된 버전 정보를 동적으로 출력함\n",
    "print(f\"✅ OpenCV 버전: {cv2.__version__}\")\n",
    "# f-string은 문자열 앞에 f를 붙이고 {}안에 변수나 표현식을 넣는 방법임\n",
    "# cv2.__version__은 현재 설치된 OpenCV의 버전 정보를 담고 있는 속성임\n",
    "# __version__은 파이썬 라이브러리들이 공통적으로 제공하는 버전 정보 속성임\n",
    "# ✅ 이모지는 체크마크로 성공/확인을 나타냄\n",
    "# 버전을 확인하는 이유: 호환성 문제를 미리 파악하기 위해서임\n",
    "\n",
    "print(f\"✅ NumPy 버전: {np.__version__}\")\n",
    "# np.__version__은 현재 설치된 NumPy의 버전 정보임\n",
    "# OpenCV와 NumPy는 서로 연동되므로 두 라이브러리 버전을 모두 확인함\n",
    "# 버전이 너무 오래되었거나 호환되지 않으면 오류가 발생할 수 있음\n",
    "\n",
    "print(f\"✅ matplotlib 버전: {plt.matplotlib.__version__}\") \n",
    "# plt.matplotlib.__version__은 현재 설치된 matplotlib의 버전 정보임\n",
    "# OpenCV와 함께 사용하면 더 깔끔한 결과 화면을 만들 수 있으므로 두 라이브러리 버전을 모두 확인함\n",
    "# OpenCV와 NumPy는 서로 연동되므로 두 라이브러리 버전을 모두 확인함\n",
    "\n",
    "\n",
    "# 웹캠 연결 테스트 (실습에 웹캠이 필요하므로 미리 확인함)\n",
    "cap = cv2.VideoCapture(0)\n",
    "# cv2.VideoCapture()는 비디오 입력을 받기 위한 객체를 만드는 함수임\n",
    "# 매개변수 0은 첫 번째 카메라 장치를 의미함\n",
    "# 0=첫번째 카메라(보통 내장 웹캠), 1=두번째 카메라(외장 USB 카메라) 이런 식임\n",
    "# cap은 capture의 줄임말로 웹캠 객체를 담는 변수명임\n",
    "# 이 객체를 통해서 웹캠에서 영상을 읽어올 수 있음\n",
    "\n",
    "# 웹캠이 정상적으로 열렸는지 확인하는 조건문\n",
    "if cap.isOpened():\n",
    "   # isOpened()는 카메라가 성공적으로 연결되었는지 확인하는 메서드임\n",
    "   # 연결 성공시 True, 실패시 False를 반환함\n",
    "   # 카메라가 없거나, 다른 프로그램에서 사용 중이거나, 권한이 없으면 False가 됨\n",
    "   \n",
    "   print(\"✅ 웹캠 연결 성공!\")\n",
    "   # 웹캠 연결이 성공했음을 사용자에게 알려주는 메시지임\n",
    "   # ✅ 체크마크로 성공을 시각적으로 표현함\n",
    "   \n",
    "   cap.release()\n",
    "   # release() 메서드는 웹캠 자원을 해제하는 함수임\n",
    "   # 테스트가 끝났으므로 웹캠을 닫아서 다른 프로그램에서도 사용할 수 있게 함\n",
    "   # 이걸 안 하면 웹캠이 계속 점유되어 다른 곳에서 사용하지 못함\n",
    "   # 컴퓨터 자원을 절약하고 충돌을 방지하는 중요한 과정임\n",
    "   \n",
    "else:\n",
    "   # 웹캠 연결이 실패한 경우 실행되는 부분임\n",
    "   print(\"⚠️ 웹캠 연결 실패 - 일부 실습은 정적 이미지로 진행됩니다\")\n",
    "   # ⚠️ 이모지는 경고나 주의를 나타냄\n",
    "   # 정적 이미지로도 얼굴 인식 등의 기본 개념을 학습할 수 있음\n",
    "\n",
    "print(\"\\n🚀 모든 준비가 완료되었습니다!\")\n",
    "# \\n은 줄바꿈 문자로 한 줄을 띄워서 출력함\n",
    "# 🚀 로켓 이모지는 시작/출발을 의미하는 역동적인 아이콘임\n",
    "# 모든 초기 설정이 끝났고 본격적인 실습을 시작할 준비가 됐음을 알려줌\n",
    "\n",
    "print(\"=\"*40)\n",
    "# = 문자를 40개 출력해서 마무리 구분선을 그림\n",
    "# 위의 구분선(30개)보다 길게 해서 단락의 끝임을 명확히 표현함\n",
    "# 시각적으로 정리된 느낌을 주어 가독성을 높임\n",
    "\n",
    "# 💡 이 전체 코드 블록의 목적:\n",
    "# 1. 필요한 라이브러리들이 모두 정상적으로 설치되어 있는지 확인함\n",
    "# 2. 웹캠이 제대로 작동하는지 미리 테스트해서 실습 준비 상태를 점검함\n",
    "# 3. 라이브러리 버전 정보를 확인해서 호환성 문제가 없는지 체크함\n",
    "# 4. 사용자에게 현재 상태를 친근하고 명확하게 알려줌\n",
    "# 5. 프로그램이 안정적으로 실행될 수 있는 환경인지 사전 검증함\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84b1036",
   "metadata": {},
   "source": [
    "## 🖼️ 1단계: 기본 이미지 조작 마스터하기\n",
    "\n",
    "### 🎯 목표\n",
    "OpenCV에서 이미지를 어떻게 생성하고 조작하는지 배워보겠습니다. \n",
    "컴퓨터에게 이미지는 단순한 숫자 배열일 뿐입니다!\n",
    "\n",
    "### 🧮 이미지의 비밀\n",
    "- **픽셀**: 이미지의 가장 작은 단위 (Picture Element)\n",
    "- **색상**: RGB (빨강, 초록, 파랑)의 조합으로 표현\n",
    "- **해상도**: 가로 × 세로 픽셀 수\n",
    "- **배열**: 컴퓨터는 이미지를 3차원 숫자 배열로 이해\n",
    "\n",
    "### 💡 실습 내용\n",
    "- 빈 캔버스 만들기\n",
    "- 색상 조작하기\n",
    "- 기본 도형 그리기\n",
    "- 텍스트 추가하기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4d6fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1단계: 기본 이미지 생성 및 조작\n",
    "# =============================================================================\n",
    "\n",
    "print(\"🎨 1단계: 기본 이미지 조작\")\n",
    "# print() 함수로 현재 진행할 단계를 사용자에게 알려줌\n",
    "# 🎨 이모지는 그림/이미지와 관련된 직관적인 아이콘임\n",
    "# 단계별로 나누어서 학습하면 이해하기 쉬움\n",
    "\n",
    "print(\"=\"*25)\n",
    "# = 문자를 25번 반복해서 시각적 구분선을 만듦\n",
    "# 각 단계를 명확히 구분해서 보기 좋게 정리함\n",
    "\n",
    "# 1. 빈 캔버스 만들기 (검은 화면)\n",
    "height, width = 400, 600\n",
    "# height는 이미지의 세로 크기(높이)를 픽셀 단위로 설정함\n",
    "# width는 이미지의 가로 크기(너비)를 픽셀 단위로 설정함\n",
    "# 400x600은 적당한 크기로 너무 크지도 작지도 않음\n",
    "# 변수 두 개를 동시에 할당하는 것을 튜플 언패킹이라고 함\n",
    "\n",
    "black_canvas = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "# np.zeros()는 모든 값이 0으로 채워진 배열을 만드는 함수임\n",
    "# (height, width, 3)는 배열의 모양을 지정함\n",
    "#   height: 세로 픽셀 수 (행의 개수)\n",
    "#   width: 가로 픽셀 수 (열의 개수)  \n",
    "#   3: 색상 채널 개수 (BGR - 파랑, 초록, 빨강)\n",
    "# dtype=np.uint8은 데이터 타입을 지정함\n",
    "#   uint8 = 0~255 범위의 양의 정수 (이미지 픽셀값의 표준)\n",
    "#   0이면 완전히 어둡고(검정), 255면 완전히 밝음(해당 색상 최대값)\n",
    "# 모든 픽셀이 0이므로 완전히 검은 이미지가 만들어짐\n",
    "\n",
    "print(\"📝 검은 캔버스 생성 완료!\")\n",
    "# 캔버스 생성이 끝났음을 사용자에게 알려주는 메시지\n",
    "# 📝 이모지는 작성/생성과 관련된 의미를 나타냄\n",
    "\n",
    "# 2. 색상별 캔버스 만들기 (RGB 각 색상의 순수한 캔버스 제작)\n",
    "# 주의: OpenCV는 BGR 순서를 사용함 (파랑, 초록, 빨강)\n",
    "\n",
    "# 빨간색 캔버스 만들기\n",
    "red_canvas = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "# 먼저 모든 픽셀이 0인 검은 캔버스를 만듦\n",
    "# 이후에 특정 색상 채널만 255로 바꿔서 해당 색상을 만들 예정\n",
    "\n",
    "red_canvas[:, :, 2] = 255\n",
    "# 배열 슬라이싱 문법: [행 범위, 열 범위, 채널 범위]\n",
    "# [:, :, 2]의 의미:\n",
    "#   첫 번째 :: 모든 행 (세로 방향 전체)\n",
    "#   두 번째 :: 모든 열 (가로 방향 전체)\n",
    "#   2: 세 번째 채널 (BGR에서 R=빨강 채널)\n",
    "# = 255는 해당 영역의 모든 픽셀을 255(최대 밝기)로 설정함\n",
    "# 결과: 빨강 채널만 최대값이고 나머지는 0인 순수한 빨간색\n",
    "\n",
    "# 초록색 캔버스 만들기\n",
    "green_canvas = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "# 동일하게 검은 캔버스부터 시작함\n",
    "\n",
    "green_canvas[:, :, 1] = 255\n",
    "# [:, :, 1]에서 1은 G(초록) 채널을 의미함\n",
    "# BGR 순서에서 가운데가 초록색임\n",
    "# 초록 채널만 255로 설정해서 순수한 초록색 만듦\n",
    "\n",
    "# 파란색 캔버스 만들기\n",
    "blue_canvas = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "# 같은 방식으로 검은 캔버스 준비\n",
    "\n",
    "blue_canvas[:, :, 0] = 255\n",
    "# [:, :, 0]에서 0은 B(파랑) 채널을 의미함\n",
    "# BGR 순서에서 첫 번째가 파랑색임\n",
    "# 파랑 채널만 255로 설정해서 순수한 파란색 만듦\n",
    "\n",
    "# 3. 그라데이션 효과 만들기 (왼쪽에서 오른쪽으로 점점 밝아지는 효과)\n",
    "gradient = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "# 그라데이션을 그릴 빈 캔버스를 준비함\n",
    "\n",
    "for i in range(width):\n",
    "   # range(width)는 0부터 width-1까지의 숫자를 순서대로 만듦\n",
    "   # i는 현재 처리 중인 가로 위치(열 번호)를 나타냄\n",
    "   # width가 600이면 i는 0, 1, 2, ..., 599까지 반복됨\n",
    "   \n",
    "   intensity = int((i / width) * 255)\n",
    "   # 현재 위치 비율 계산: i / width\n",
    "   #   i=0일 때: 0/600 = 0 (왼쪽 끝)\n",
    "   #   i=300일 때: 300/600 = 0.5 (가운데)  \n",
    "   #   i=599일 때: 599/600 ≈ 1 (오른쪽 끝)\n",
    "   # 비율에 255를 곱하면 0~255 사이의 밝기값이 됨\n",
    "   # int()로 소수점을 제거해서 정수로 변환함 (픽셀값은 정수여야 함)\n",
    "   \n",
    "   gradient[:, i] = [intensity, intensity, intensity]\n",
    "   # [:, i]는 i번째 열의 모든 행(세로 전체)을 의미함\n",
    "   # [intensity, intensity, intensity]는 BGR 세 채널 모두 같은 값으로 설정\n",
    "   # 세 채널이 모두 같으면 무채색(회색조)이 됨\n",
    "   # intensity가 점점 커지므로 왼쪽부터 오른쪽으로 점점 밝아짐\n",
    "\n",
    "print(\"🌈 다양한 색상 캔버스 생성 완료!\")\n",
    "# 모든 색상 캔버스 생성이 끝났음을 알리는 메시지\n",
    "# 🌈 무지개 이모지는 다양한 색상을 의미함\n",
    "\n",
    "# 4. 생성된 캔버스들을 화면에 출력 (하나씩 순서대로 보여주기)\n",
    "canvases = [\n",
    "   (black_canvas, \"Black Canvas\"),\n",
    "   (red_canvas, \"Red Canvas\"),\n",
    "   (green_canvas, \"Green Canvas\"),\n",
    "   (blue_canvas, \"Blue Canvas\"),\n",
    "   (gradient, \"Gradient Effect\")\n",
    "]\n",
    "# 리스트 안에 튜플을 넣어서 (이미지, 제목) 쌍으로 저장함\n",
    "# 튜플은 ()로 묶인 데이터 모음으로 순서가 있고 변경할 수 없음\n",
    "# 이렇게 하면 이미지와 그에 해당하는 제목을 함께 관리할 수 있음\n",
    "\n",
    "print(\"\\n👀 생성된 캔버스들을 차례로 보여드립니다...\")\n",
    "# \\n은 줄바꿈 문자로 한 줄을 띄워서 출력함\n",
    "# 👀 눈 이모지는 '보여주기/시각적 표시'를 의미함\n",
    "\n",
    "print(\"💡 각 이미지는 3초간 표시됩니다. 아무 키나 누르면 다음으로 넘어갑니다.\")\n",
    "# 💡 전구 이모지는 팁이나 도움말을 의미함\n",
    "\n",
    "for i, (canvas, title) in enumerate(canvases, 1):\n",
    "   # enumerate(리스트, 시작숫자)는 (인덱스, 값) 형태로 반복함\n",
    "   # 1부터 시작하므로 i는 1, 2, 3, 4, 5가 됨 (사용자 친화적인 번호)\n",
    "   # (canvas, title)은 튜플 언패킹으로 이미지와 제목을 각각 변수에 할당\n",
    "   \n",
    "   print(f\"  🖼️ {i}/{len(canvases)}: {title}\")\n",
    "   # f-string으로 현재 몇 번째 이미지인지 표시함\n",
    "   # len(canvases)는 전체 이미지 개수를 반환함 (5개)\n",
    "   # 🖼️ 액자 이모지는 이미지/그림을 의미함\n",
    "   # 예: \"🖼️ 1/5: Black Canvas\" 형태로 출력됨\n",
    "   \n",
    "   cv2.imshow(f'OpenCV Canvas Demo - {title}', canvas)\n",
    "   # cv2.imshow(창제목, 이미지데이터)는 새 창을 열어서 이미지를 표시함\n",
    "   # 첫 번째 매개변수는 창의 제목 (문자열)\n",
    "   # 두 번째 매개변수는 표시할 이미지 데이터 (numpy 배열)\n",
    "   # f-string으로 제목에 현재 캔버스 이름을 포함시킴\n",
    "   \n",
    "   key = cv2.waitKey(3000)\n",
    "   # cv2.waitKey(밀리초)는 지정된 시간만큼 키보드 입력을 기다림\n",
    "   # 3000ms = 3초 동안 대기함\n",
    "   # 키가 눌리면 즉시 해당 키의 코드를 반환함\n",
    "   # 키가 안 눌리고 시간이 지나면 -1을 반환함\n",
    "   \n",
    "   if key != -1:\n",
    "       # waitKey()가 -1이 아니면 키가 눌린 것임\n",
    "       print(f\"    ⏭️ 사용자 입력으로 다음 캔버스로...\")\n",
    "       # ⏭️ 다음 버튼 이모지로 건너뛰기를 표현함\n",
    "       # 들여쓰기(4칸)로 하위 메시지임을 표현함\n",
    "   \n",
    "   cv2.destroyAllWindows()\n",
    "   # 현재 열린 모든 OpenCV 창을 닫고 메모리를 정리함\n",
    "   # 다음 이미지를 보여주기 전에 이전 창을 깔끔하게 정리\n",
    "   # 메모리 누수 방지와 화면 정리를 위해 필수임\n",
    "\n",
    "# 5. 모든 캔버스를 한 번에 비교해서 보기 (격자 형태로 배치)\n",
    "print(f\"\\n🎨 모든 캔버스 한번에 비교하기 (10초간)\")\n",
    "# 이제 모든 이미지를 한 화면에서 비교할 수 있게 보여줄 예정\n",
    "# 🎨 팔레트 이모지는 여러 색상을 한 번에 보는 것을 의미\n",
    "\n",
    "# 작은 크기로 조정해서 한 화면에 여러 개 배치하기 위한 크기 설정\n",
    "small_height, small_width = 200, 300\n",
    "# 원본 크기 400x600을 절반으로 줄여서 200x300으로 만듦\n",
    "# 작게 만들어야 여러 개를 한 화면에 배치할 수 있음\n",
    "\n",
    "# 2행 3열 격자를 만들기 위한 큰 캔버스 생성\n",
    "comparison_canvas = np.zeros((small_height * 2, small_width * 3, 3), dtype=np.uint8)\n",
    "# 세로: 200 * 2 = 400픽셀 (2행)\n",
    "# 가로: 300 * 3 = 900픽셀 (3열)\n",
    "# 2행 3열 격자 형태로 총 6개 공간이 생김 (5개만 사용할 예정)\n",
    "\n",
    "# 각 캔버스를 작은 크기로 변환해서 저장할 리스트\n",
    "resized_canvases = []\n",
    "# 크기가 조정된 이미지들을 저장할 빈 리스트 준비\n",
    "\n",
    "for canvas, title in canvases[:5]:\n",
    "   # canvases[:5]는 리스트의 처음 5개 요소만 가져옴\n",
    "   # 2행 3열 격자에는 6개 공간이 있지만 이미지는 5개만 있으므로\n",
    "   \n",
    "   resized = cv2.resize(canvas, (small_width, small_height))\n",
    "   # cv2.resize(이미지, (새로운 가로, 새로운 세로))로 이미지 크기를 변경함\n",
    "   # 원본 600x400을 300x200으로 축소함\n",
    "   # 비율을 유지하면서 크기를 줄임\n",
    "   \n",
    "   resized_canvases.append((resized, title))\n",
    "   # append()로 리스트 끝에 (작은이미지, 제목) 튜플을 추가함\n",
    "   # 크기가 변경된 이미지와 원래 제목을 함께 저장함\n",
    "\n",
    "# 2x3 격자의 각 위치 좌표 정의 (행, 열)\n",
    "positions = [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1)]\n",
    "# 2행 3열 격자에서 5개 이미지가 들어갈 위치를 좌표로 정의함\n",
    "# (0,0): 1행 1열, (0,1): 1행 2열, (0,2): 1행 3열\n",
    "# (1,0): 2행 1열, (1,1): 2행 2열\n",
    "# (1,2) 위치는 비워둠 (이미지가 5개뿐이므로)\n",
    "\n",
    "for i, ((resized_canvas, title), (row, col)) in enumerate(zip(resized_canvases, positions)):\n",
    "   # zip()은 두 리스트를 하나씩 짝지어서 반환함\n",
    "   # enumerate()로 순서 번호도 함께 얻음\n",
    "   # 복잡한 언패킹: ((이미지, 제목), (행, 열))을 각각 변수로 분리\n",
    "   \n",
    "   # 격자에서의 실제 픽셀 좌표 계산\n",
    "   y_start = row * small_height\n",
    "   # 행 번호에 이미지 높이를 곱하면 시작 y좌표가 나옴\n",
    "   # row=0: y_start=0, row=1: y_start=200\n",
    "   \n",
    "   y_end = y_start + small_height\n",
    "   # 시작점에 높이를 더하면 끝 y좌표가 나옴\n",
    "   # y_start=0이면 y_end=200, y_start=200이면 y_end=400\n",
    "   \n",
    "   x_start = col * small_width\n",
    "   # 열 번호에 이미지 너비를 곱하면 시작 x좌표가 나옴\n",
    "   # col=0: x_start=0, col=1: x_start=300, col=2: x_start=600\n",
    "   \n",
    "   x_end = x_start + small_width\n",
    "   # 시작점에 너비를 더하면 끝 x좌표가 나옴\n",
    "   \n",
    "   comparison_canvas[y_start:y_end, x_start:x_end] = resized_canvas\n",
    "   # 배열 슬라이싱으로 큰 캔버스의 특정 영역을 지정함\n",
    "   # [y_start:y_end, x_start:x_end]는 해당 격자 위치의 사각형 영역\n",
    "   # 그 영역에 작은 이미지를 통째로 복사해서 넣음\n",
    "   \n",
    "   cv2.putText(comparison_canvas, title, (x_start + 10, y_start + 30), \n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "   # cv2.putText()로 각 이미지에 제목 텍스트를 추가함\n",
    "   # 매개변수 설명:\n",
    "   #   comparison_canvas: 텍스트를 그릴 이미지\n",
    "   #   title: 표시할 텍스트 내용\n",
    "   #   (x_start + 10, y_start + 30): 텍스트 위치 (약간의 여백 추가)\n",
    "   #   cv2.FONT_HERSHEY_SIMPLEX: 폰트 종류 (기본 폰트)\n",
    "   #   0.6: 폰트 크기 (적당한 크기)\n",
    "   #   (255, 255, 255): 텍스트 색상 (흰색)\n",
    "   #   2: 텍스트 두께 (굵기)\n",
    "\n",
    "# 모든 캔버스가 한 번에 보이는 비교 화면 표시\n",
    "cv2.imshow('All Canvases Comparison', comparison_canvas)\n",
    "# 격자 형태로 배치된 모든 이미지를 한 번에 보여줌\n",
    "# 각 색상과 효과를 쉽게 비교할 수 있음\n",
    "\n",
    "cv2.waitKey(10000)\n",
    "# 10초 동안 화면을 표시함 (10000ms = 10초)\n",
    "# 사용자가 충분히 비교해볼 수 있는 시간 제공\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "# 모든 OpenCV 창을 닫고 메모리 정리함\n",
    "\n",
    "print(\"✅ 기본 캔버스 생성 및 출력 완료!\")\n",
    "# 1단계 실습이 모두 완료되었음을 알리는 메시지\n",
    "# ✅ 체크마크로 성공적인 완료를 표현함\n",
    "\n",
    "# 💡 이 코드에서 배우는 핵심 개념들:\n",
    "# 1. NumPy 배열로 이미지 데이터를 생성하는 방법\n",
    "# 2. BGR 색상 체계 이해 (OpenCV의 특징)\n",
    "# 3. 배열 슬라이싱으로 특정 영역이나 채널을 조작하는 기법\n",
    "# 4. 반복문을 사용해서 점진적인 효과를 만드는 방법\n",
    "# 5. OpenCV 윈도우 관리 (imshow, waitKey, destroyAllWindows)\n",
    "# 6. 이미지 크기 조정과 격자 형태로 배치하는 방법\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e774176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 기본 도형 그리기 (단계별로 도형을 하나씩 추가하며 과정 보여주기)\n",
    "print(\"\\n🎭 기본 도형 그리기 시작...\")\n",
    "# \\n으로 줄바꿈을 해서 이전 내용과 구분함\n",
    "# 🎭 연극 마스크 이모지는 그리기/창작 활동을 의미함\n",
    "\n",
    "canvas = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "# 도형을 그릴 새로운 빈 캔버스를 생성함\n",
    "# 이전에 설정한 height(400), width(600) 크기를 재사용함\n",
    "# np.zeros()로 모든 픽셀이 0(검정색)인 깨끗한 캔버스 준비\n",
    "# 이 캔버스 위에 여러 도형들을 하나씩 그려나갈 예정\n",
    "\n",
    "# 사각형 그리기 (테두리만 있는 사각형)\n",
    "cv2.rectangle(canvas, (50, 50), (200, 150), (0, 255, 0), 3)\n",
    "# cv2.rectangle() 함수는 사각형을 그리는 OpenCV 함수임\n",
    "# 매개변수 순서: (그릴이미지, 좌상단좌표, 우하단좌표, BGR색상, 선두께)\n",
    "# canvas: 그림을 그릴 대상 이미지\n",
    "# (50, 50): 사각형의 왼쪽 위 모서리 좌표 (x=50픽셀, y=50픽셀)\n",
    "# (200, 150): 사각형의 오른쪽 아래 모서리 좌표 (x=200픽셀, y=150픽셀)\n",
    "#   결과적으로 가로 150픽셀, 세로 100픽셀 크기의 사각형이 만들어짐\n",
    "# (0, 255, 0): BGR 색상값 (Blue=0, Green=255, Red=0) → 순수한 녹색\n",
    "# 3: 테두리 선의 두께를 3픽셀로 설정 (굵은 선)\n",
    "\n",
    "print(\"  ✅ 녹색 테두리 사각형 그리기 완료\")\n",
    "# 들여쓰기 2칸으로 하위 작업임을 표현함\n",
    "# ✅ 체크마크로 단계 완료를 시각적으로 표현함\n",
    "\n",
    "# 그린 결과를 즉시 화면에 보여주기 (단계별 확인)\n",
    "cv2.imshow('Step 1: Green Rectangle', canvas)\n",
    "# 현재까지 진행된 단계를 즉시 화면에 보여줌\n",
    "# 'Step 1:'으로 몇 번째 단계인지 명확히 표시함\n",
    "\n",
    "cv2.waitKey(1500)\n",
    "# 1500ms = 1.5초 동안 화면을 표시함\n",
    "# 너무 짧으면 확인하기 어렵고, 너무 길면 지루하므로 적당한 시간\n",
    "# 사용자가 결과를 충분히 관찰할 수 있는 시간 제공\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "# 현재 열린 모든 OpenCV 창을 닫음\n",
    "# 다음 단계를 보여주기 전에 화면을 깔끔하게 정리함\n",
    "# 메모리 누수 방지와 화면 정리를 위해 필수\n",
    "\n",
    "# 채워진 사각형 그리기 (내부가 꽉 찬 사각형)\n",
    "cv2.rectangle(canvas, (250, 50), (400, 150), (255, 0, 0), -1)\n",
    "# 두 번째 사각형을 기존 캔버스에 추가로 그림\n",
    "# (250, 50)~(400, 150): 첫 번째 사각형과 겹치지 않는 위치에 배치\n",
    "#   x좌표를 250으로 시작해서 첫 번째(50~200)와 50픽셀 간격 확보\n",
    "# (255, 0, 0): BGR 색상 (Blue=255, Green=0, Red=0) → 순수한 파란색\n",
    "# -1: 특별한 값으로 테두리가 아닌 내부를 완전히 채움을 의미함\n",
    "#   양수값이면 테두리 두께, -1이면 내부 채우기\n",
    "\n",
    "print(\"  ✅ 파란색 채운 사각형 추가 완료\")\n",
    "# 두 번째 도형 추가 완료를 알리는 메시지\n",
    "\n",
    "# 결과 보여주기 (이전 도형 + 새로 추가된 도형)\n",
    "cv2.imshow('Step 2: + Blue Filled Rectangle', canvas)\n",
    "# '+ Blue Filled Rectangle'으로 새로 추가된 요소를 명시함\n",
    "# 이제 화면에는 녹색 테두리 사각형과 파란색 채운 사각형이 함께 보임\n",
    "\n",
    "cv2.waitKey(1500)\n",
    "# 동일한 1.5초 대기 시간으로 일관성 유지\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "# 창 정리\n",
    "\n",
    "# 원 그리기 (테두리만 있는 원)\n",
    "cv2.circle(canvas, (125, 250), 50, (0, 0, 255), 5)\n",
    "# cv2.circle() 함수는 원을 그리는 OpenCV 함수임\n",
    "# 매개변수 순서: (그릴이미지, 중심좌표, 반지름, BGR색상, 선두께)\n",
    "# canvas: 그림을 그릴 대상 이미지 (기존 사각형들이 있는 캔버스)\n",
    "# (125, 250): 원의 중심점 좌표 (x=125, y=250)\n",
    "#   y=250으로 설정해서 위쪽 사각형들(y=50~150)과 겹치지 않게 배치\n",
    "# 50: 원의 반지름 (중심에서 가장자리까지의 거리) 50픽셀\n",
    "#   지름은 100픽셀이 되므로 적당한 크기의 원\n",
    "# (0, 0, 255): BGR 색상 (Blue=0, Green=0, Red=255) → 순수한 빨간색\n",
    "# 5: 원 테두리의 두께를 5픽셀로 설정 (사각형 3픽셀보다 두껍게)\n",
    "\n",
    "print(\"  ✅ 빨간색 테두리 원 추가 완료\")\n",
    "# 세 번째 도형 추가 완료 알림\n",
    "\n",
    "# 결과 보여주기\n",
    "cv2.imshow('Step 3: + Red Circle', canvas)\n",
    "# 이제 사각형 2개 + 원 1개가 화면에 보임\n",
    "\n",
    "cv2.waitKey(1500)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 채워진 원 그리기 (내부가 꽉 찬 원)\n",
    "cv2.circle(canvas, (325, 250), 50, (255, 255, 0), -1)\n",
    "# 두 번째 원을 첫 번째 원과 나란히 배치\n",
    "# (325, 250): 첫 번째 원 (125, 250)에서 x좌표를 200 증가시킴\n",
    "#   원의 지름이 100이므로 200 간격이면 적당히 떨어져 있음\n",
    "# 50: 첫 번째 원과 같은 반지름으로 크기 통일\n",
    "# (255, 255, 0): BGR 색상 (Blue=255, Green=255, Red=0)\n",
    "#   파랑+초록 = 청록색(Cyan)이 만들어짐\n",
    "# -1: 사각형과 마찬가지로 내부를 완전히 채움\n",
    "\n",
    "print(\"  ✅ 청록색 채운 원 추가 완료\")\n",
    "# 네 번째 도형 추가 완료 알림\n",
    "\n",
    "# 결과 보여주기\n",
    "cv2.imshow('Step 4: + Cyan Filled Circle', canvas)\n",
    "# 사각형 2개 + 원 2개가 화면에 보임\n",
    "\n",
    "cv2.waitKey(1500)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 직선 그리기\n",
    "cv2.line(canvas, (450, 50), (550, 150), (255, 0, 255), 3)\n",
    "# cv2.line() 함수는 직선을 그리는 OpenCV 함수임\n",
    "# 매개변수 순서: (그릴이미지, 시작점좌표, 끝점좌표, BGR색상, 선두께)\n",
    "# canvas: 그림을 그릴 대상 이미지\n",
    "# (450, 50): 직선의 시작점 (캔버스 오른쪽 위 영역)\n",
    "#   x=450으로 설정해서 기존 도형들과 겹치지 않는 오른쪽 공간 활용\n",
    "# (550, 150): 직선의 끝점 (시작점에서 대각선 아래 방향)\n",
    "#   가로 100픽셀, 세로 100픽셀 이동한 대각선 방향\n",
    "# (255, 0, 255): BGR 색상 (Blue=255, Green=0, Red=255)\n",
    "#   파랑+빨강 = 자주색(Magenta)이 만들어짐\n",
    "# 3: 직선의 두께를 3픽셀로 설정\n",
    "\n",
    "print(\"  ✅ 자주색 직선 추가 완료\")\n",
    "# 다섯 번째 도형 추가 완료 알림\n",
    "\n",
    "# 결과 보여주기\n",
    "cv2.imshow('Step 5: + Purple Line', canvas)\n",
    "# 사각형 2개 + 원 2개 + 직선 1개가 화면에 보임\n",
    "\n",
    "cv2.waitKey(1500)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 텍스트 추가하기 (글자 쓰기)\n",
    "cv2.putText(canvas, 'OpenCV Magic!', (200, 350), \n",
    "           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "# cv2.putText() 함수는 이미지에 텍스트를 그리는 OpenCV 함수임\n",
    "# 매개변수 순서: (그릴이미지, 텍스트내용, 시작좌표, 폰트종류, 폰트크기, BGR색상, 글자두께)\n",
    "# canvas: 텍스트를 그릴 대상 이미지\n",
    "# 'OpenCV Magic!': 화면에 표시할 문자열 내용\n",
    "#   OpenCV의 강력함을 표현하는 재미있는 문구\n",
    "# (200, 350): 텍스트의 시작 위치 (기준점은 텍스트의 왼쪽 아래)\n",
    "#   x=200으로 중앙 정렬, y=350으로 하단 영역에 배치\n",
    "# cv2.FONT_HERSHEY_SIMPLEX: OpenCV에서 제공하는 기본 폰트\n",
    "#   가장 일반적이고 읽기 쉬운 sans-serif 계열 폰트\n",
    "# 1: 폰트 크기 배율 (1=기본크기, 2=2배크기, 0.5=절반크기)\n",
    "# (255, 255, 255): BGR 색상 (모든 채널 최대값 255) → 순수한 흰색\n",
    "#   검은 배경에서 가장 잘 보이는 색상\n",
    "# 2: 글자 선의 두께 (진하기 정도) 2픽셀로 적당히 굵게\n",
    "\n",
    "print(\"  ✅ 흰색 텍스트 추가 완료\")\n",
    "# 여섯 번째이자 마지막 요소 추가 완료 알림\n",
    "\n",
    "# 최종 결과 보여주기 (모든 도형과 텍스트가 완성된 상태)\n",
    "cv2.imshow('Final: Complete Shapes and Text', canvas)\n",
    "# 'Final:'로 최종 완성 상태임을 명시함\n",
    "# 모든 도형과 텍스트가 포함된 완전한 작품을 표시\n",
    "\n",
    "print(\"🎭 기본 도형과 텍스트 추가 완료!\")\n",
    "# 전체 도형 그리기 섹션의 완료를 알리는 메시지\n",
    "# 🎭 이모지로 창작 활동의 완성을 표현함\n",
    "\n",
    "print(\"👀 최종 결과를 5초간 보여드립니다...\")\n",
    "# 👀 눈 이모지로 '보여주기'를 표현함\n",
    "# 최종 결과는 더 오래(5초) 보여줘서 시간을 충분히 제공\n",
    "\n",
    "cv2.waitKey(5000)\n",
    "# 5000ms = 5초 동안 최종 결과를 표시함\n",
    "# 단계별 확인(1.5초)보다 길게 해서 완성작을 충분히 볼 수 있게함\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "# 모든 창을 닫고 메모리 정리\n",
    "\n",
    "# 5. 결과 이미지들을 화면에 표시 (지금까지 만든 모든 캔버스 순서대로 보여주기)\n",
    "images = [\n",
    "   (black_canvas, \"Black Canvas\"),      # 처음에 만든 검은 캔버스\n",
    "   (red_canvas, \"Red Canvas\"),          # 빨간색 캔버스\n",
    "   (green_canvas, \"Green Canvas\"),      # 초록색 캔버스\n",
    "   (blue_canvas, \"Blue Canvas\"),        # 파란색 캔버스\n",
    "   (gradient, \"Gradient Effect\"),       # 그라데이션 효과 캔버스\n",
    "   (canvas, \"Shapes and Text\")          # 방금 완성한 도형과 텍스트 캔버스\n",
    "]\n",
    "# 지금까지 만든 모든 캔버스들을 하나의 리스트로 정리함\n",
    "# 튜플 형태로 (이미지데이터, 설명제목)을 함께 저장함\n",
    "# 마지막에 방금 완성한 도형 캔버스를 추가해서 총 6개 이미지\n",
    "# 나중에 이 리스트를 사용해서 모든 결과를 차례로 보여줄 수 있음\n",
    "\n",
    "# 💡 이 코드 섹션에서 배우는 핵심 개념들:\n",
    "# 1. OpenCV의 기본 도형 그리기 함수들 사용법\n",
    "#    - cv2.rectangle(): 사각형 그리기\n",
    "#    - cv2.circle(): 원 그리기  \n",
    "#    - cv2.line(): 직선 그리기\n",
    "#    - cv2.putText(): 텍스트 추가하기\n",
    "# 2. 좌표계 이해하기 (왼쪽 위가 (0,0), x는 오른쪽 증가, y는 아래쪽 증가)\n",
    "# 3. BGR 색상 체계와 다양한 색상 조합 만들기\n",
    "# 4. 테두리 그리기(양수 두께)와 내부 채우기(-1) 구분하기\n",
    "# 5. 단계별 시각화를 통한 학습 과정 이해하기\n",
    "# 6. 같은 캔버스에 여러 요소를 누적해서 그리는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df8e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n👀 모든 결과 이미지들을 차례로 보여드립니다 (각각 3초간)...\")\n",
    "# \\n으로 줄바꿈해서 이전 내용과 구분함\n",
    "# 👀 눈 이모지는 '시각적으로 보여주기'를 의미함\n",
    "# 지금까지 만든 6개의 캔버스를 순서대로 하나씩 보여주는 최종 리뷰 시간\n",
    "# 괄호 안에 시간 정보를 미리 알려줘서 사용자가 예상할 수 있게 함\n",
    "\n",
    "# images 리스트의 각 항목을 하나씩 꺼내서 반복\n",
    "for img, title in images:\n",
    "   # for 반복문으로 images 리스트를 처음부터 끝까지 순회함\n",
    "   # 튜플 언패킹: (이미지데이터, 제목문자열) → img와 title 변수로 분리\n",
    "   # img = 실제 이미지 데이터 (NumPy 배열 형태의 픽셀 정보)\n",
    "   # title = 이미지 설명 텍스트 (예: \"Black Canvas\", \"Red Canvas\" 등)\n",
    "   # 매 반복마다 다음 이미지와 제목이 자동으로 할당됨\n",
    "   \n",
    "   cv2.imshow(f'OpenCV Demo - {title}', img)\n",
    "   # cv2.imshow()로 각 이미지를 화면에 표시함\n",
    "   # f-string 문법을 사용해서 창 제목을 동적으로 생성함\n",
    "   # f'OpenCV Demo - {title}' → 'OpenCV Demo - Black Canvas' 형태로 만들어짐\n",
    "   # 통일된 제목 형식으로 어떤 프로그램인지 명확히 알 수 있음\n",
    "   # title 변수 내용에 따라 창 제목이 자동으로 바뀜\n",
    "   \n",
    "   cv2.waitKey(3000)\n",
    "   # 3000ms = 3초 동안 각 이미지를 화면에 표시함\n",
    "   # 사용자가 각 결과를 충분히 관찰하고 비교할 수 있는 적절한 시간\n",
    "   # 너무 짧으면 확인하기 어렵고, 너무 길면 지루할 수 있음\n",
    "   # 3초는 이미지를 차근차근 살펴볼 수 있는 적당한 시간\n",
    "   \n",
    "   cv2.destroyAllWindows()\n",
    "   # 현재 창을 완전히 닫고 메모리에서 제거함\n",
    "   # 다음 이미지를 보여주기 전에 이전 창을 깔끔하게 정리함\n",
    "   # 창이 겹치지 않게 하나씩 보여주기 위한 중요한 과정\n",
    "   # 메모리 누수 방지와 시각적 정리를 동시에 해결함\n",
    "\n",
    "print(\"✅ 1단계 완료! 기본 이미지 조작을 마스터했습니다!\")\n",
    "# ✅ 체크마크로 성공적인 완료를 시각적으로 표현함\n",
    "# 1단계에서 배운 모든 내용이 성공적으로 끝났음을 명확히 알림\n",
    "\n",
    "# 💡 이 코드 블록의 교육적 의미와 배우는 핵심 개념들:\n",
    "# 1. 반복문(for loop)으로 여러 이미지를 자동으로 순차 표시하는 방법\n",
    "#    - 수동으로 하나씩 코딩하지 않고 효율적으로 처리\n",
    "#    - 코드 재사용성과 유지보수성 향상\n",
    "# 2. 튜플 언패킹 기법 (img, title = 각 튜플의 요소들)\n",
    "#    - 하나의 데이터 구조에서 여러 값을 동시에 추출\n",
    "#    - 파이썬의 강력한 문법 기능 활용\n",
    "# 3. f-string 문법으로 동적 문자열 생성하기\n",
    "#    - 변수 내용에 따라 자동으로 문자열 조합\n",
    "#    - 코드가 간결하고 읽기 쉬워짐\n",
    "# 4. 사용자 경험(UX) 고려하기\n",
    "#    - 적절한 시간 간격으로 보여줘서 인지 부담 줄이기\n",
    "#    - 예측 가능한 패턴으로 사용자 편의성 향상\n",
    "# 5. 리소스 관리의 중요성\n",
    "#    - 창을 하나씩 열고 닫아서 메모리 효율성 확보\n",
    "#    - 시스템 자원을 적절히 관리하는 프로그래밍 습관\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f3a87b",
   "metadata": {},
   "source": [
    "## 📹 2단계: 웹캠 실시간 마법 부리기\n",
    "\n",
    "### 🎯 목표\n",
    "이제 실시간으로 들어오는 영상을 다양하게 변환해보겠습니다. \n",
    "마치 인스타그램 필터처럼 실시간으로 효과를 적용할 수 있어요!\n",
    "\n",
    "### 🎭 적용할 효과들\n",
    "- **회색조 변환**: 흑백 영화 느낌\n",
    "- **색상 반전**: 네거티브 필름 효과  \n",
    "- **블러 효과**: 몽환적인 분위기\n",
    "- **엣지 검출**: 스케치북 같은 효과\n",
    "- **색상 공간 변환**: 다양한 색감 체험\n",
    "\n",
    "### ⌨️ 조작법\n",
    "- **'1'**: 원본 영상\n",
    "- **'2'**: 회색조 (흑백)\n",
    "- **'3'**: 색상 반전 (네거티브)\n",
    "- **'4'**: 블러 효과\n",
    "- **'5'**: 엣지 검출 (윤곽선)\n",
    "- **'6'**: HSV 색상 공간\n",
    "- **'s'**: 스크린샷 저장\n",
    "- **'q'**: 종료\n",
    "\n",
    "### 💡 실제 응용\n",
    "이런 기술들이 실제로는:\n",
    "- 화상 회의 배경 블러\n",
    "- 의료 영상에서 병변 검출\n",
    "- 자율주행차의 차선 인식\n",
    "- 얼굴 인식 시스템\n",
    "- AR 필터 앱\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c4c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2-1단계: 웹캠 기본 연결 테스트\n",
    "# =============================================================================\n",
    "print(\"📹 2-1단계: 웹캠 기본 연결 테스트\")\n",
    "# 📹 비디오 카메라 이모지로 웹캠 관련 학습임을 직관적으로 표현함\n",
    "\n",
    "print(\"=\"*30)\n",
    "# = 문자를 30번 반복해서 시각적 구분선을 만듦\n",
    "# 각 단계를 명확히 구분해서 가독성을 높임\n",
    "\n",
    "def test_webcam_basic():\n",
    "   \"\"\"웹캠 기본 연결 및 원본 영상 테스트하는 함수\"\"\"\n",
    "   # 독스트링(docstring): 함수의 기능을 설명하는 문서화 문자열\n",
    "   # 삼중 따옴표로 감싸서 여러 줄 설명이 가능함\n",
    "   # 함수의 목적과 기능을 명확히 설명해서 코드 이해도를 높임\n",
    "   # 함수로 만드는 이유들:\n",
    "   #   1. 코드 정리: 관련 기능을 하나로 묶어서 구조화\n",
    "   #   2. 재사용성: 필요할 때마다 함수 이름으로 간단히 호출 가능\n",
    "   #   3. 오류 처리 용이: try-except 블록을 함수 안에 깔끔하게 포함\n",
    "   #   4. 변수 범위 관리: 함수 내 변수들이 전역 공간을 오염시키지 않음\n",
    "   \n",
    "   # 웹캠 연결 시도\n",
    "   cap = cv2.VideoCapture(0)\n",
    "   # cv2.VideoCapture()는 비디오 입력을 받기 위한 객체를 생성하는 함수\n",
    "   # 매개변수 0은 시스템의 첫 번째 카메라 장치를 의미함\n",
    "   #   0 = 기본 웹캠 (노트북 내장 카메라 또는 첫 번째 외장 카메라)\n",
    "   #   1 = 두 번째 카메라 (추가로 연결된 외장 웹캠)\n",
    "   #   2 = 세 번째 카메라 (여러 카메라가 연결된 경우)\n",
    "   # cap 변수에 카메라 객체가 저장되어 이후 모든 카메라 조작에 사용됨\n",
    "   \n",
    "   # 웹캠이 제대로 열렸는지 확인하는 안전 장치\n",
    "   if not cap.isOpened():\n",
    "       # cap.isOpened()는 카메라가 성공적으로 연결되었는지 확인하는 메서드\n",
    "       # 연결 성공시 True, 실패시 False를 반환함\n",
    "       # not으로 부정하면 연결 실패인 경우에 조건이 True가 됨\n",
    "       # 연결 실패 원인: 카메라 없음, 다른 프로그램에서 사용 중, 권한 없음, 하드웨어 문제\n",
    "       \n",
    "       print(\"❌ 웹캠을 열 수 없습니다!\")\n",
    "       # ❌ X 표시 이모지로 오류를 시각적으로 명확히 표현함\n",
    "       # 사용자에게 웹캠 연결 실패를 즉시 알려줌\n",
    "       \n",
    "       return\n",
    "       # return으로 함수를 즉시 종료함\n",
    "       # 웹캠이 없으면 더 이상 진행할 수 없으므로 안전하게 종료\n",
    "       # 이렇게 하면 나머지 코드에서 오류가 발생하지 않음\n",
    "   \n",
    "   # 웹캠 해상도 설정 (성능과 화질의 균형점)\n",
    "   cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "   # cap.set(속성, 값)은 웹캠의 특정 속성을 원하는 값으로 설정하는 메서드\n",
    "   # cv2.CAP_PROP_FRAME_WIDTH는 프레임 너비(가로 해상도)를 설정하는 상수\n",
    "   # 640픽셀로 설정: 적당한 화질과 빠른 처리 속도의 균형점\n",
    "   # 너무 높으면 처리 속도 저하, 너무 낮으면 화질 저하\n",
    "   \n",
    "   cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "   # cv2.CAP_PROP_FRAME_HEIGHT는 프레임 높이(세로 해상도)를 설정하는 상수\n",
    "   # 480픽셀로 설정: 640x480은 VGA 표준 해상도\n",
    "   # 이 해상도는 대부분의 웹캠에서 안정적으로 지원되고 처리 속도도 빠름\n",
    "   # 웹캠 실습과 얼굴 인식에 충분한 화질을 제공함\n",
    "   \n",
    "   print(\"✅ 웹캠 연결 성공!\")\n",
    "   # ✅ 체크마크로 성공을 시각적으로 표현함\n",
    "   # 웹캠이 정상적으로 연결되었음을 알림림\n",
    "   \n",
    "   print(\"📱 'q' 키를 눌러 종료하세요\")\n",
    "   # 📱 스마트폰 이모지로 조작 방법을 연상시킴\n",
    "   # 사용자에게 프로그램 종료 방법을 미리 안내함\n",
    "   # 명확한 종료 방법 제시로 사용자 경험 향상\n",
    "   \n",
    "   frame_count = 0\n",
    "   # 처리한 프레임 수를 세는 카운터 변수 초기화\n",
    "   # 0부터 시작해서 프레임을 처리할 때마다 1씩 증가\n",
    "   # 성능 확인용: 얼마나 많은 프레임을 처리했는지 추적\n",
    "   # 초당 프레임 수(FPS) 계산이나 통계 분석에 활용\n",
    "   \n",
    "   try:\n",
    "       # try 블록: 예외(오류)가 발생할 수 있는 코드를 감쌈\n",
    "       # 웹캠 처리 중에 다양한 오류가 발생할 수 있으므로 안전장치 필요\n",
    "       # 오류가 발생해도 프로그램이 비정상 종료되지 않게 보호함\n",
    "       \n",
    "       while True:\n",
    "           # 무한 루프: 실시간 영상 처리의 핵심 구조\n",
    "           # True 조건은 항상 참이므로 break를 만나기 전까지 계속 반복\n",
    "           # 웹캠에서 연속적으로 프레임을 읽어서 처리하는 패턴\n",
    "           # 실시간성을 위해 끊임없이 새로운 영상 데이터를 받아야 함\n",
    "           \n",
    "           # 웹캠에서 한 프레임(한 장의 사진) 읽어오기\n",
    "           ret, frame = cap.read()\n",
    "           # cap.read()는 웹캠에서 현재 프레임을 읽어오는 메서드\n",
    "           # 두 개의 값을 반환함 (튜플 언패킹):\n",
    "           #   ret (return): 읽기 성공 여부 (True/False)\n",
    "           #   frame: 실제 이미지 데이터 (numpy 배열)\n",
    "           # 성공시 ret=True, frame=이미지데이터\n",
    "           # 실패시 ret=False, frame=빈값 또는 이전 프레임\n",
    "           \n",
    "           if not ret:\n",
    "               # ret이 False인 경우: 프레임 읽기 실패\n",
    "               # 원인: 카메라 연결 끊김, 하드웨어 문제, 드라이버 오류 등\n",
    "               print(\"⚠️ 프레임 읽기 실패\")\n",
    "               # ⚠️ 경고 이모지로 문제 상황을 표시함\n",
    "               break\n",
    "               # while 루프를 즉시 종료해서 더 이상 오류가 발생하지 않게 함\n",
    "           \n",
    "           frame_count += 1\n",
    "           # 성공적으로 프레임을 읽었으므로 카운터를 1 증가\n",
    "           # += 연산자: frame_count = frame_count + 1과 동일\n",
    "           # 매 프레임마다 누적되어 총 처리량을 추적\n",
    "           \n",
    "           # 거울 효과 적용 (좌우 반전) - 사용자가 보기에 자연스럽게\n",
    "           frame = cv2.flip(frame, 1)\n",
    "           # cv2.flip(이미지, 방향)은 이미지를 뒤집는 함수\n",
    "           # 방향 매개변수:\n",
    "           #   0 = 상하 반전 (위아래 뒤집기)\n",
    "           #   1 = 좌우 반전 (거울처럼 좌우 뒤집기)\n",
    "           #   -1 = 상하좌우 모두 반전 (180도 회전)\n",
    "           # 1을 사용해서 거울 효과 구현\n",
    "           # 이렇게 하면 사용자가 자신의 모습을 자연스럽게 인식할 수 있음\n",
    "           # 셀카 모드와 같은 효과로 사용성 향상\n",
    "           \n",
    "           # 화면에 정보 텍스트 표시 (현재 상태를 사용자에게 알려줌)\n",
    "           # 첫 번째 텍스트: 프로그램 제목\n",
    "           cv2.putText(frame, 'Original Webcam Feed', (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "           # cv2.putText()로 이미지에 텍스트를 추가함\n",
    "           # 매개변수 설명:\n",
    "           #   frame: 텍스트를 그릴 대상 이미지\n",
    "           #   'Original Webcam Feed': 표시할 텍스트 (원본 웹캠 영상임을 표시)\n",
    "           #   (10, 30): 텍스트 위치 좌표 (왼쪽 위에서 조금 떨어진 곳)\n",
    "           #   cv2.FONT_HERSHEY_SIMPLEX: 깔끔하고 읽기 쉬운 기본 폰트\n",
    "           #   1: 폰트 크기 (1=기본 크기)\n",
    "           #   (0, 255, 0): BGR 색상 (파랑=0, 초록=255, 빨강=0) → 녹색\n",
    "           #   2: 글자 두께 (2픽셀로 굵고 선명하게)\n",
    "           \n",
    "           # 두 번째 텍스트: 현재 프레임 번호 (얼마나 많이 처리했는지)\n",
    "           cv2.putText(frame, f'Frame: {frame_count}', (10, 70), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "           # f'Frame: {frame_count}': f-string으로 실시간 숫자 표시\n",
    "           # frame_count 변수 값이 실시간으로 업데이트되어 표시됨\n",
    "           # (10, 70): 첫 번째 텍스트에서 40픽셀 아래 위치\n",
    "           # 0.8: 제목보다 조금 작은 폰트 크기\n",
    "           # (255, 255, 255): 흰색 (모든 배경에서 잘 보임)\n",
    "           \n",
    "           # 세 번째 텍스트: 사용 방법 안내\n",
    "           cv2.putText(frame, 'Press Q to quit', (10, 110), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "           # 'Press Q to quit': 종료 방법을 명확히 안내\n",
    "           # (10, 110): 두 번째 텍스트에서 40픽셀 더 아래\n",
    "           # 0.6: 더 작은 폰트 크기 (안내 텍스트이므로)\n",
    "           # 1: 얇은 글자 두께 (덜 두드러지게)\n",
    "           \n",
    "           # 완성된 프레임을 화면에 표시\n",
    "           cv2.imshow('Webcam Test - Original', frame)\n",
    "           # cv2.imshow(창제목, 이미지)로 화면에 영상을 출력\n",
    "           # 'Webcam Test - Original': 창의 제목 (테스트 단계임을 명시)\n",
    "           # frame: 텍스트가 추가된 최종 이미지 데이터\n",
    "           \n",
    "           # 키 입력 확인 (사용자가 'q'를 눌렀는지 체크)\n",
    "           if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "               # cv2.waitKey(1): 1밀리초 동안 키 입력을 기다림\n",
    "               #   1ms는 매우 짧아서 실시간성을 유지하면서도 키 입력 감지 가능\n",
    "               #   너무 길면 영상이 끊어져 보이고, 너무 짧으면 키 입력 놓칠 수 있음\n",
    "               # & 0xFF: 키 코드의 마지막 8비트만 사용 (특수키 문제 방지)\n",
    "               #   일부 시스템에서 키 코드가 32비트로 반환되는 문제 해결\n",
    "               # ord('q'): 문자 'q'의 ASCII 코드 값 (113)\n",
    "               # 전체 조건: 'q' 키가 눌렸는지 확인\n",
    "               break\n",
    "               # 'q' 키가 눌리면 while 루프를 즉시 종료함\n",
    "               # 사용자가 원할 때 언제든 프로그램을 종료할 수 있게 함\n",
    "   \n",
    "   except KeyboardInterrupt:\n",
    "       # KeyboardInterrupt: Ctrl+C를 눌러서 강제 종료했을 때 발생하는 예외\n",
    "       # 사용자가 의도적으로 프로그램을 중단시킨 경우\n",
    "       print(\"\\n⚠️ 중단됨\")\n",
    "       # \\n으로 줄바꿈해서 깔끔하게 메시지 출력\n",
    "       # ⚠️ 경고 이모지로 비정상 종료가 아닌 의도적 중단임을 표시\n",
    "   \n",
    "   finally:\n",
    "       # finally 블록: try 블록이 어떤 방식으로 끝나든 반드시 실행되는 부분\n",
    "       # 정상 종료든 예외 발생이든 상관없이 리소스 정리는 반드시 해야 함\n",
    "       # 이 부분이 없으면 웹캠이나 창이 제대로 닫히지 않을 수 있음\n",
    "       \n",
    "       # 리소스 정리 (매우 중요한 과정!)\n",
    "       cap.release()\n",
    "       # 웹캠 자원을 해제해서 시스템에 반환함\n",
    "       # 이걸 안 하면 웹캠이 계속 점유되어 다른 프로그램에서 사용 못함\n",
    "       # 메모리 누수 방지와 하드웨어 자원 관리를 위해 필수\n",
    "       \n",
    "       cv2.destroyAllWindows()\n",
    "       # 열린 모든 OpenCV 창을 닫고 메모리에서 제거함\n",
    "       # 창이 남아있으면 시스템 자원을 계속 사용하므로 정리 필요\n",
    "       # GUI 자원 해제로 시스템 안정성 확보\n",
    "       \n",
    "       print(f\"✅ 기본 테스트 완료! (총 {frame_count} 프레임)\")\n",
    "       # f-string으로 최종 통계를 출력함\n",
    "       # frame_count로 총 처리된 프레임 수를 보여줌\n",
    "       # 사용자에게 프로그램이 얼마나 많은 데이터를 처리했는지 알려줌\n",
    "       # 성능 지표와 완료 확인을 동시에 제공\n",
    "\n",
    "# 기본 웹캠 테스트 함수 실행\n",
    "test_webcam_basic()\n",
    "# 위에서 정의한 함수를 실제로 호출해서 실행함\n",
    "# 함수 정의만으로는 실행되지 않으므로 반드시 호출 필요\n",
    "# 이 한 줄로 전체 웹캠 테스트 과정이 시작됨\n",
    "\n",
    "# 💡 이 코드에서 배우는 핵심 개념들:\n",
    "# 1. 웹캠 연결과 설정 방법 (VideoCapture, set 메서드 활용)\n",
    "# 2. 실시간 영상 처리의 기본 구조 (무한 루프 + 프레임 읽기 패턴)\n",
    "# 3. 안전한 프로그래밍 기법 (try-except-finally, 조건 확인, 조기 반환)\n",
    "# 4. 사용자 인터페이스 설계 (정보 표시, 키 입력 처리, 직관적 안내)\n",
    "# 5. 시스템 리소스 관리 (release, destroyAllWindows로 메모리 정리)\n",
    "# 6. 함수 활용으로 코드 구조화 (재사용성, 가독성, 유지보수성 향상)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea1492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2-3단계: 네거티브 효과\n",
    "# =============================================================================\n",
    "print(\"📹 2-3단계: 네거티브 효과\")\n",
    "# 📹 비디오 카메라 이모지로 웹캠 관련 학습임을 표시함\n",
    "# 네거티브 효과: 색상을 반전시켜서 필름의 네거티브 필름 같은 효과를 만드는 기법\n",
    "\n",
    "print(\"=\"*20)\n",
    "# = 문자 20개로 구분선을 만들어서 시각적으로 새로운 섹션임을 표시함\n",
    "\n",
    "def webcam_negative_effect():\n",
    "   \"\"\"웹캠 네거티브 효과\"\"\"\n",
    "   # 독스트링으로 함수의 기능을 간단명료하게 설명함\n",
    "   # 네거티브 효과: 모든 색상을 반대 색상으로 바꾸는 이미지 처리 기법\n",
    "   # 흑백 필름의 네거티브(음화)처럼 밝은 부분은 어둡게, 어두운 부분은 밝게 변환함\n",
    "   \n",
    "   # 웹캠을 연결함 (0번은 기본 카메라를 의미함)\n",
    "   cap = cv2.VideoCapture(0)\n",
    "   # cv2.VideoCapture(0)으로 시스템의 첫 번째 카메라에 연결 시도\n",
    "   # 0 = 기본 웹캠, 1 = 두 번째 카메라, 2 = 세 번째 카메라...\n",
    "   # cap 변수에 카메라 객체를 저장해서 이후 모든 카메라 조작에 사용\n",
    "   \n",
    "   # 웹캠이 제대로 열렸는지 확인함\n",
    "   if not cap.isOpened():\n",
    "       # cap.isOpened()는 카메라 연결 성공 여부를 확인하는 메서드\n",
    "       # True: 연결 성공, False: 연결 실패\n",
    "       # not으로 부정해서 연결 실패인 경우 조건이 참이 됨\n",
    "       print(\"❌ 웹캠을 열 수 없습니다!\")\n",
    "       # ❌ X표시 이모지로 오류 상황을 명확히 표현함\n",
    "       return\n",
    "       # 함수를 즉시 종료해서 더 이상 진행하지 않음\n",
    "       # 웹캠이 없으면 네거티브 효과를 적용할 수 없으므로 안전하게 종료\n",
    "   \n",
    "   # 웹캠 해상도를 설정함 (가로 640픽셀, 세로 480픽셀)\n",
    "   cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "   # cv2.CAP_PROP_FRAME_WIDTH 상수로 프레임 너비를 설정\n",
    "   # 640픽셀: 표준 VGA 해상도의 너비로 안정적이고 빠른 처리 가능\n",
    "   \n",
    "   cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "   # cv2.CAP_PROP_FRAME_HEIGHT 상수로 프레임 높이를 설정\n",
    "   # 480픽셀: VGA 해상도의 높이로 640x480 조합이 가장 호환성 좋음\n",
    "   \n",
    "   print(\"🎬 네거티브 효과 시작!\")\n",
    "   # 🎬 영화 카메라 이모지로 특수 효과 시작을 표현함\n",
    "   # 사용자에게 네거티브 효과 모드가 시작되었음을 알림\n",
    "   \n",
    "   print(\"📱 's' 키로 저장, 'q' 키로 종료\")\n",
    "   # 📱 스마트폰 이모지로 키보드 조작을 연상시킴\n",
    "   # 's' 키: save의 줄임말로 현재 화면 저장\n",
    "   # 'q' 키: quit의 줄임말로 프로그램 종료\n",
    "   # 사용자에게 미리 조작 방법을 명확히 안내함\n",
    "   \n",
    "   # 프레임 개수를 세기 위한 변수 초기화\n",
    "   frame_count = 0\n",
    "   # 0부터 시작해서 매 프레임마다 1씩 증가시킬 카운터\n",
    "   # 처리 성능 모니터링과 통계 분석에 활용\n",
    "   # 프로그램이 얼마나 많은 영상 데이터를 처리했는지 추적\n",
    "   \n",
    "   try:\n",
    "       # try 블록으로 예외 상황에 대비한 안전장치 설정\n",
    "       # 웹캠 처리 중 다양한 오류가 발생할 수 있으므로 보호 필요\n",
    "       \n",
    "       while True:\n",
    "           # 무한 루프로 실시간 영상 처리 구현\n",
    "           # 웹캠에서 연속적으로 프레임을 받아서 처리하는 기본 패턴\n",
    "           \n",
    "           # 웹캠에서 한 프레임(한 장면)을 읽어옴\n",
    "           ret, frame = cap.read()\n",
    "           # cap.read()로 웹캠에서 현재 프레임을 획득\n",
    "           # 튜플 언패킹으로 두 개 값을 동시에 받음:\n",
    "           #   ret: 프레임 읽기 성공 여부 (True/False)\n",
    "           #   frame: 실제 영상 데이터 (numpy 배열)\n",
    "           \n",
    "           if not ret:\n",
    "               # ret이 False면 프레임 읽기 실패\n",
    "               # 카메라 연결 끊김, 하드웨어 문제 등의 원인\n",
    "               break\n",
    "               # while 루프를 즉시 종료해서 더 이상 처리하지 않음\n",
    "           \n",
    "           frame_count += 1\n",
    "           # 성공적으로 프레임을 읽었으므로 카운터 증가\n",
    "           # += 연산자로 기존 값에 1을 더함\n",
    "           \n",
    "           # 좌우 반전 효과 (거울처럼 보이게 함)\n",
    "           frame = cv2.flip(frame, 1)\n",
    "           # cv2.flip(이미지, 방향)으로 이미지 뒤집기\n",
    "           # 방향 1 = 좌우 반전 (수평 반전)\n",
    "           # 거울 효과로 사용자가 자연스럽게 인식할 수 있게 함\n",
    "           \n",
    "           # ★ 네거티브 효과: 색상을 완전히 반전시킨다 ★\n",
    "           negative_frame = 255 - frame\n",
    "           # 핵심 알고리즘: 모든 픽셀값을 255에서 빼기\n",
    "           # 픽셀값 범위: 0~255 (8비트 정수)\n",
    "           # 반전 원리:\n",
    "           #   검은색 (0, 0, 0) → (255, 255, 255) 흰색\n",
    "           #   흰색 (255, 255, 255) → (0, 0, 0) 검은색\n",
    "           #   빨간색 (0, 0, 255) → (255, 255, 0) 노란색\n",
    "           #   파란색 (255, 0, 0) → (0, 255, 255) 하늘색\n",
    "           # NumPy 배열 연산으로 모든 픽셀에 동시 적용되어 매우 빠름\n",
    "           \n",
    "           # 화면에 텍스트 정보들을 표시함\n",
    "           \n",
    "           # 제목 텍스트 표시\n",
    "           cv2.putText(negative_frame,\n",
    "                       # 네거티브 효과가 적용된 이미지에 텍스트 추가\n",
    "                       'Negative Effect',\n",
    "                       # 현재 적용 중인 효과 이름 표시\n",
    "                       (10, 30),\n",
    "                       # 텍스트 위치: 왼쪽 위에서 (10, 30) 픽셀 떨어진 곳\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                       # 가장 일반적이고 읽기 쉬운 기본 폰트\n",
    "                       1,\n",
    "                       # 폰트 크기 1 (기본 크기)\n",
    "                       (0, 255, 255),\n",
    "                       # BGR 색상: (파랑=0, 초록=255, 빨강=255) → 노란색\n",
    "                       # 네거티브 효과에서 잘 보이는 색상 선택\n",
    "                       2)\n",
    "                       # 텍스트 두께 2픽셀 (굵고 선명하게)\n",
    "           \n",
    "           # 현재 프레임 번호 표시\n",
    "           cv2.putText(negative_frame, \n",
    "                       f'Frame: {frame_count}',\n",
    "                       # f-string으로 실시간 프레임 번호 삽입\n",
    "                       # 예: \"Frame: 1234\" 형태로 표시\n",
    "                       (10, 70),\n",
    "                       # 첫 번째 텍스트에서 40픽셀 아래 위치\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       0.8,\n",
    "                       # 제목보다 조금 작은 폰트 크기\n",
    "                       (255, 255, 0),\n",
    "                       # BGR 색상: (파랑=255, 초록=255, 빨강=0) → 하늘색\n",
    "                       2)\n",
    "           \n",
    "           # 조작 방법 안내 텍스트\n",
    "           cv2.putText(negative_frame, \n",
    "                       'Press S to save, Q to quit',\n",
    "                       # 키보드 조작 방법을 명확히 안내\n",
    "                       (10, 110),\n",
    "                       # 두 번째 텍스트에서 40픽셀 더 아래\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       0.6,\n",
    "                       # 안내 텍스트이므로 더 작은 폰트 사용\n",
    "                       (255, 0, 255),\n",
    "                       # BGR 색상: (파랑=255, 초록=0, 빨강=255) → 자주색\n",
    "                       1)\n",
    "                       # 얇은 텍스트 두께 (덜 두드러지게)\n",
    "           \n",
    "           # 처리된 영상을 화면에 표시함\n",
    "           cv2.imshow('Webcam - Negative Effect', negative_frame)\n",
    "           # cv2.imshow()로 네거티브 효과가 적용된 영상을 출력\n",
    "           # 창 제목에 'Negative Effect'를 포함해서 현재 효과를 명시\n",
    "           \n",
    "           # 키보드 입력을 확인함 (1ms 대기)\n",
    "           key = cv2.waitKey(1) & 0xFF\n",
    "           # cv2.waitKey(1): 1밀리초 동안 키 입력 대기\n",
    "           # & 0xFF: 키 값을 8비트로 제한하는 비트 연산\n",
    "           #   일부 시스템에서 32비트 값이 반환되는 문제 해결\n",
    "           #   마지막 8비트만 사용해서 정확한 키 코드 얻기\n",
    "           \n",
    "           if key == ord('q'):\n",
    "               # ord('q')는 문자 'q'의 ASCII 코드 값 (113)\n",
    "               # 사용자가 'q' 키를 눌렀는지 확인\n",
    "               break\n",
    "               # while 루프를 종료해서 프로그램 끝내기\n",
    "               \n",
    "           elif key == ord('s'):\n",
    "               # ord('s')는 문자 's'의 ASCII 코드 값 (115)\n",
    "               # 사용자가 's' 키를 눌렀는지 확인 (save 기능)\n",
    "               \n",
    "               # 현재 시간을 이용해 고유한 파일명 생성\n",
    "               filename = f'negative_effect_{int(time.time())}.jpg'\n",
    "               # f-string으로 파일명 구성:\n",
    "               #   'negative_effect_': 파일명 접두사 (효과 종류 표시)\n",
    "               #   {int(time.time())}: 현재 시간을 정수로 변환한 타임스탬프\n",
    "               #   '.jpg': 파일 확장자 (JPEG 형식)\n",
    "               # time.time()은 1970년 1월 1일부터 현재까지의 초를 반환\n",
    "               # 타임스탬프로 파일명이 중복되지 않게 보장\n",
    "               \n",
    "               # 네거티브 효과가 적용된 이미지를 파일로 저장함\n",
    "               cv2.imwrite(filename, negative_frame)\n",
    "               # cv2.imwrite(파일명, 이미지데이터)로 이미지 저장\n",
    "               # negative_frame: 네거티브 효과가 적용된 현재 프레임\n",
    "               # JPEG 형식으로 압축되어 저장됨\n",
    "               \n",
    "               print(f\"📸 저장: {filename}\")\n",
    "               # 📸 카메라 이모지로 저장 완료를 표시\n",
    "               # f-string으로 저장된 파일명을 사용자에게 알려줌\n",
    "   \n",
    "   finally:\n",
    "       # finally 블록: try 블록이 어떻게 끝나든 반드시 실행\n",
    "       # 정상 종료든 예외 발생이든 리소스 정리는 필수\n",
    "       \n",
    "       cap.release()\n",
    "       # 웹캠 자원을 해제해서 시스템에 반환\n",
    "       # 다른 프로그램에서도 웹캠을 사용할 수 있게 함\n",
    "       # 메모리 누수 방지와 하드웨어 자원 관리\n",
    "       \n",
    "       cv2.destroyAllWindows()\n",
    "       # 모든 OpenCV 창을 닫고 메모리에서 제거\n",
    "       # GUI 자원 해제로 시스템 안정성 확보\n",
    "       \n",
    "       print(f\"✅ 네거티브 효과 완료! (총 {frame_count} 프레임)\")\n",
    "       # ✅ 체크마크로 성공적인 완료 표시\n",
    "       # f-string으로 총 처리한 프레임 수를 통계로 제공\n",
    "       # 사용자에게 프로그램 성과와 완료를 동시에 알림\n",
    "\n",
    "# 네거티브 효과 함수를 실행함\n",
    "webcam_negative_effect()\n",
    "# 위에서 정의한 함수를 실제로 호출해서 실행\n",
    "# 이 한 줄로 전체 네거티브 효과 기능이 시작됨\n",
    "\n",
    "# 💡 이 코드에서 배우는 핵심 개념들:\n",
    "# 1. 픽셀 단위 수학 연산으로 특수 효과 만들기 (255 - frame)\n",
    "# 2. NumPy 배열 연산의 효율성 (모든 픽셀에 동시 적용)\n",
    "# 3. 실시간 이미지 처리 파이프라인 구조\n",
    "# 4. 키보드 이벤트 처리와 조건 분기 (q키 종료, s키 저장)\n",
    "# 5. 파일명 생성 전략 (타임스탬프로 중복 방지)\n",
    "# 6. 색상 반전의 수학적 원리와 시각적 효과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14601e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2-4단계: 블러 효과\n",
    "# =============================================================================\n",
    "print(\"📹 2-4단계: 블러 효과\")\n",
    "# 📹 비디오 카메라 이모지로 웹캠 관련 학습임을 표시함\n",
    "# 2-4단계로 세분화해서 단계적 학습 진행을 명확히 구분함\n",
    "# 블러 효과: 이미지를 의도적으로 흐리게 만들어서 부드럽고 몽환적인 느낌을 주는 기법\n",
    "\n",
    "print(\"=\"*17)\n",
    "# = 문자 17개로 구분선을 만들어서 시각적으로 새로운 섹션임을 표시함\n",
    "\n",
    "def webcam_blur_effect():\n",
    "   \"\"\"웹캠 블러 효과\"\"\"\n",
    "   # 독스트링으로 함수의 기능을 간단명료하게 설명함\n",
    "   # 블러 효과: 픽셀들의 값을 주변 픽셀들과 평균화해서 경계를 부드럽게 만드는 기법\n",
    "   # 사진의 배경 흐리기, 노이즈 제거, 부드러운 느낌 연출 등에 활용됨\n",
    "   \n",
    "   # 웹캠을 연결함 (0번은 기본 카메라를 의미함)\n",
    "   cap = cv2.VideoCapture(0)\n",
    "   # cv2.VideoCapture(0)으로 시스템의 첫 번째 카메라에 연결 시도\n",
    "   # 0 = 기본 웹캠, 1 = 두 번째 카메라, 2 = 세 번째 카메라...\n",
    "   # cap 변수에 카메라 객체를 저장해서 이후 모든 카메라 조작에 사용\n",
    "   \n",
    "   # 웹캠이 제대로 열렸는지 확인함\n",
    "   if not cap.isOpened():\n",
    "       # cap.isOpened()는 카메라 연결 성공 여부를 확인하는 메서드\n",
    "       # True: 연결 성공, False: 연결 실패\n",
    "       # not으로 부정해서 연결 실패인 경우 조건이 참이 됨\n",
    "       print(\"❌ 웹캠을 열 수 없습니다!\")\n",
    "       # ❌ X표시 이모지로 오류 상황을 명확히 표현함\n",
    "       return\n",
    "       # 함수를 즉시 종료해서 더 이상 진행하지 않음\n",
    "       # 웹캠이 없으면 블러 효과를 적용할 수 없으므로 안전하게 종료\n",
    "   \n",
    "   # 웹캠 해상도를 설정함 (가로 640픽셀, 세로 480픽셀)\n",
    "   cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "   # cv2.CAP_PROP_FRAME_WIDTH 상수로 프레임 너비를 설정\n",
    "   # 640픽셀: 표준 VGA 해상도의 너비로 안정적이고 빠른 처리 가능\n",
    "   \n",
    "   cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "   # cv2.CAP_PROP_FRAME_HEIGHT 상수로 프레임 높이를 설정\n",
    "   # 480픽셀: VGA 해상도의 높이로 640x480 조합이 가장 호환성 좋음\n",
    "   \n",
    "   print(\"🎬 블러 효과 시작!\")\n",
    "   # 🎬 영화 카메라 이모지로 특수 효과 시작을 표현함\n",
    "   # 사용자에게 블러 효과 모드가 시작되었음을 알림\n",
    "   \n",
    "   print(\"📱 's' 키로 저장, 'q' 키로 종료\")\n",
    "   # 📱 스마트폰 이모지로 키보드 조작을 연상시킴\n",
    "   # 's' 키: save의 줄임말로 현재 화면 저장\n",
    "   # 'q' 키: quit의 줄임말로 프로그램 종료\n",
    "   # 사용자에게 미리 조작 방법을 명확히 안내함\n",
    "   \n",
    "   # 프레임 개수를 세기 위한 변수 초기화\n",
    "   frame_count = 0\n",
    "   # 0부터 시작해서 매 프레임마다 1씩 증가시킬 카운터\n",
    "   # 처리 성능 모니터링과 통계 분석에 활용\n",
    "   # 프로그램이 얼마나 많은 영상 데이터를 처리했는지 추적\n",
    "   \n",
    "   try:\n",
    "       # try 블록으로 예외 상황에 대비한 안전장치 설정\n",
    "       # 웹캠 처리 중 다양한 오류가 발생할 수 있으므로 보호 필요\n",
    "       \n",
    "       while True:\n",
    "           # 무한 루프로 실시간 영상 처리 구현\n",
    "           # 웹캠에서 연속적으로 프레임을 받아서 처리하는 기본 패턴\n",
    "           \n",
    "           # 웹캠에서 한 프레임(한 장면)을 읽어옴\n",
    "           ret, frame = cap.read()\n",
    "           # cap.read()로 웹캠에서 현재 프레임을 획득\n",
    "           # 튜플 언패킹으로 두 개 값을 동시에 받음:\n",
    "           #   ret: 프레임 읽기 성공 여부 (True/False)\n",
    "           #   frame: 실제 영상 데이터 (numpy 배열)\n",
    "           \n",
    "           if not ret:\n",
    "               # ret이 False면 프레임 읽기 실패\n",
    "               # 카메라 연결 끊김, 하드웨어 문제 등의 원인\n",
    "               break\n",
    "               # while 루프를 즉시 종료해서 더 이상 처리하지 않음\n",
    "           \n",
    "           frame_count += 1\n",
    "           # 성공적으로 프레임을 읽었으므로 카운터 증가\n",
    "           # += 연산자로 기존 값에 1을 더함\n",
    "           \n",
    "           # 좌우 반전 효과 (거울처럼 보이게 함)\n",
    "           frame = cv2.flip(frame, 1)\n",
    "           # cv2.flip(이미지, 방향)으로 이미지 뒤집기\n",
    "           # 방향 1 = 좌우 반전 (수평 반전)\n",
    "           # 거울 효과로 사용자가 자연스럽게 인식할 수 있게 함\n",
    "           \n",
    "           # ★ 가우시안 블러 효과: 이미지를 부드럽게 흐리게 만듦 ★\n",
    "           blur_frame = cv2.GaussianBlur(frame, (21, 21), 0)\n",
    "           # cv2.GaussianBlur() 함수는 가우시안 분포를 이용한 블러 효과를 적용함\n",
    "           # 매개변수 설명:\n",
    "           #   frame: 블러를 적용할 원본 이미지\n",
    "           #   (21, 21): 커널 크기 (블러 강도를 결정하는 핵심 요소)\n",
    "           #     - 21x21 픽셀 크기의 필터를 사용해서 블러 처리\n",
    "           #     - 크기가 클수록 더 강한 블러 효과 (더 흐려짐)\n",
    "           #     - 반드시 홀수여야 함 (중심점이 있어야 하므로)\n",
    "           #     - 작은 값: (5,5), (7,7) → 약한 블러\n",
    "           #     - 큰 값: (15,15), (21,21), (31,31) → 강한 블러\n",
    "           #   0: 표준편차 (시그마 값, 0이면 커널 크기로 자동 계산)\n",
    "           #     - 가우시안 분포의 퍼짐 정도를 결정\n",
    "           #     - 0으로 설정하면 OpenCV가 커널 크기에 맞춰 최적값 계산\n",
    "           \n",
    "           # 가우시안 블러의 작동 원리:\n",
    "           # 1. 각 픽셀을 중심으로 21x21 영역의 픽셀들을 선택\n",
    "           # 2. 가우시안 분포(정규분포)에 따라 가중치를 부여\n",
    "           #    - 중심에 가까울수록 높은 가중치\n",
    "           #    - 가장자리로 갈수록 낮은 가중치\n",
    "           # 3. 가중 평균을 계산해서 새로운 픽셀값 결정\n",
    "           # 4. 결과: 자연스럽고 부드러운 블러 효과\n",
    "           \n",
    "           # 화면에 텍스트 정보들을 표시함\n",
    "           \n",
    "           # 제목 텍스트 표시\n",
    "           cv2.putText(blur_frame,\n",
    "                       # 블러 효과가 적용된 이미지에 텍스트 추가\n",
    "                       'Blur Effect',\n",
    "                       # 현재 적용 중인 효과 이름 표시\n",
    "                       (10, 30),\n",
    "                       # 텍스트 위치: 왼쪽 위에서 (10, 30) 픽셀 떨어진 곳\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                       # 가장 일반적이고 읽기 쉬운 기본 폰트\n",
    "                       1,\n",
    "                       # 폰트 크기 1 (기본 크기)\n",
    "                       (255, 255, 255),\n",
    "                       # BGR 색상: (파랑=255, 초록=255, 빨강=255) → 흰색\n",
    "                       # 흰색은 대부분의 배경에서 잘 보이는 안전한 색상\n",
    "                       2)\n",
    "                       # 텍스트 두께 2픽셀 (굵고 선명하게)\n",
    "           \n",
    "           # 현재 프레임 번호 표시\n",
    "           cv2.putText(blur_frame, \n",
    "                       f'Frame: {frame_count}',\n",
    "                       # f-string으로 실시간 프레임 번호 삽입\n",
    "                       # 예: \"Frame: 1234\" 형태로 표시\n",
    "                       (10, 70),\n",
    "                       # 첫 번째 텍스트에서 40픽셀 아래 위치\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       0.8,\n",
    "                       # 제목보다 조금 작은 폰트 크기\n",
    "                       (0, 255, 0),\n",
    "                       # BGR 색상: (파랑=0, 초록=255, 빨강=0) → 순수한 초록색\n",
    "                       2)\n",
    "           \n",
    "           # 조작 방법 안내 텍스트\n",
    "           cv2.putText(blur_frame, \n",
    "                       'Press S to save, Q to quit',\n",
    "                       # 키보드 조작 방법을 명확히 안내\n",
    "                       (10, 110),\n",
    "                       # 두 번째 텍스트에서 40픽셀 더 아래\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       0.6,\n",
    "                       # 안내 텍스트이므로 더 작은 폰트 사용\n",
    "                       (255, 255, 0),\n",
    "                       # BGR 색상: (파랑=255, 초록=255, 빨강=0) → 노란색\n",
    "                       1)\n",
    "                       # 얇은 텍스트 두께 (덜 두드러지게)\n",
    "           \n",
    "           # 처리된 영상을 화면에 표시함\n",
    "           cv2.imshow('Webcam - Blur Effect', blur_frame)\n",
    "           # cv2.imshow()로 블러 효과가 적용된 영상을 출력\n",
    "           # 창 제목에 'Blur Effect'를 포함해서 현재 효과를 명시\n",
    "           \n",
    "           # 키보드 입력을 확인함 (1ms 대기)\n",
    "           key = cv2.waitKey(1) & 0xFF\n",
    "           # cv2.waitKey(1): 1밀리초 동안 키 입력 대기\n",
    "           # & 0xFF: 키 값을 8비트로 제한하는 비트 연산\n",
    "           #   일부 시스템에서 32비트 값이 반환되는 문제 해결\n",
    "           #   마지막 8비트만 사용해서 정확한 키 코드 얻기\n",
    "           \n",
    "           if key == ord('q'):\n",
    "               # ord('q')는 문자 'q'의 ASCII 코드 값 (113)\n",
    "               # 사용자가 'q' 키를 눌렀는지 확인\n",
    "               break\n",
    "               # while 루프를 종료해서 프로그램 끝내기\n",
    "               \n",
    "           elif key == ord('s'):\n",
    "               # ord('s')는 문자 's'의 ASCII 코드 값 (115)\n",
    "               # 사용자가 's' 키를 눌렀는지 확인 (save 기능)\n",
    "               \n",
    "               # 현재 시간을 이용해 고유한 파일명 생성\n",
    "               filename = f'blur_effect_{int(time.time())}.jpg'\n",
    "               # f-string으로 파일명 구성:\n",
    "               #   'blur_effect_': 파일명 접두사 (효과 종류 표시)\n",
    "               #   {int(time.time())}: 현재 시간을 정수로 변환한 타임스탬프\n",
    "               #   '.jpg': 파일 확장자 (JPEG 형식)\n",
    "               # time.time()은 1970년 1월 1일부터 현재까지의 초를 반환\n",
    "               # 타임스탬프로 파일명이 중복되지 않게 보장\n",
    "               \n",
    "               # 블러 효과가 적용된 이미지를 파일로 저장함\n",
    "               cv2.imwrite(filename, blur_frame)\n",
    "               # cv2.imwrite(파일명, 이미지데이터)로 이미지 저장\n",
    "               # blur_frame: 블러 효과가 적용된 현재 프레임\n",
    "               # JPEG 형식으로 압축되어 저장됨\n",
    "               \n",
    "               print(f\"📸 저장: {filename}\")\n",
    "               # 📸 카메라 이모지로 저장 완료를 표시\n",
    "               # f-string으로 저장된 파일명을 사용자에게 알려줌\n",
    "   \n",
    "   finally:\n",
    "       # finally 블록: try 블록이 어떻게 끝나든 반드시 실행\n",
    "       # 정상 종료든 예외 발생이든 리소스 정리는 필수\n",
    "       \n",
    "       cap.release()\n",
    "       # 웹캠 자원을 해제해서 시스템에 반환\n",
    "       # 다른 프로그램에서도 웹캠을 사용할 수 있게 함\n",
    "       # 메모리 누수 방지와 하드웨어 자원 관리\n",
    "       \n",
    "       cv2.destroyAllWindows()\n",
    "       # 모든 OpenCV 창을 닫고 메모리에서 제거\n",
    "       # GUI 자원 해제로 시스템 안정성 확보\n",
    "       \n",
    "       print(f\"✅ 블러 효과 완료! (총 {frame_count} 프레임)\")\n",
    "       # ✅ 체크마크로 성공적인 완료 표시\n",
    "       # f-string으로 총 처리한 프레임 수를 통계로 제공\n",
    "       # 사용자에게 프로그램 성과와 완료를 동시에 알림\n",
    "\n",
    "# 블러 효과 함수를 실행함\n",
    "webcam_blur_effect()\n",
    "# 위에서 정의한 함수를 실제로 호출해서 실행\n",
    "# 이 한 줄로 전체 블러 효과 기능이 시작됨\n",
    "\n",
    "# 💡 이 코드에서 배우는 핵심 개념들:\n",
    "# 1. 가우시안 블러의 수학적 원리와 시각적 효과\n",
    "# 2. 커널 크기와 블러 강도의 관계 이해\n",
    "# 3. 실시간 이미지 필터링 기법\n",
    "# 4. OpenCV의 다양한 블러 함수들 (GaussianBlur 외에도 blur, medianBlur 등)\n",
    "# 5. 이미지 처리에서 가중 평균의 개념\n",
    "# 6. 부드러운 시각 효과 구현 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9692b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2-5단계: 엣지 검출 효과\n",
    "# =============================================================================\n",
    "print(\"📹 2-5단계: 엣지 검출 효과\")\n",
    "# 📹 비디오 카메라 이모지로 웹캠 관련 학습임을 표시함\n",
    "# 2-5단계로 세분화해서 단계적 학습 진행을 명확히 구분함\n",
    "# 엣지 검출: 이미지에서 물체의 경계선을 찾아내는 컴퓨터 비전의 핵심 기법\n",
    "\n",
    "print(\"=\"*22)\n",
    "# = 문자 22개로 구분선을 만들어서 시각적으로 새로운 섹션임을 표시함\n",
    "\n",
    "def webcam_edge_effect():\n",
    "   \"\"\"웹캠 엣지 검출 효과\"\"\"\n",
    "   # 독스트링으로 함수의 기능을 간단명료하게 설명함\n",
    "   # 엣지 검출: 픽셀 밝기가 급격히 변하는 경계 부분을 찾아내는 기법\n",
    "   # 물체 인식, 윤곽선 추출, 스케치 효과 등에 널리 활용됨\n",
    "   # Canny 엣지 검출은 가장 정확하고 널리 사용되는 알고리즘임\n",
    "   \n",
    "   # 웹캠을 연결함 (0번은 기본 카메라를 의미함)\n",
    "   cap = cv2.VideoCapture(0)\n",
    "   # cv2.VideoCapture(0)으로 시스템의 첫 번째 카메라에 연결 시도\n",
    "   # 0 = 기본 웹캠, 1 = 두 번째 카메라, 2 = 세 번째 카메라...\n",
    "   # cap 변수에 카메라 객체를 저장해서 이후 모든 카메라 조작에 사용\n",
    "   \n",
    "   # 웹캠이 제대로 열렸는지 확인함\n",
    "   if not cap.isOpened():\n",
    "       # cap.isOpened()는 카메라 연결 성공 여부를 확인하는 메서드\n",
    "       # True: 연결 성공, False: 연결 실패\n",
    "       # not으로 부정해서 연결 실패인 경우 조건이 참이 됨\n",
    "       print(\"❌ 웹캠을 열 수 없습니다!\")\n",
    "       # ❌ X표시 이모지로 오류 상황을 명확히 표현함\n",
    "       return\n",
    "       # 함수를 즉시 종료해서 더 이상 진행하지 않음\n",
    "       # 웹캠이 없으면 엣지 검출을 적용할 수 없으므로 안전하게 종료\n",
    "   \n",
    "   # 웹캠 해상도를 설정함 (가로 640픽셀, 세로 480픽셀)\n",
    "   cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "   # cv2.CAP_PROP_FRAME_WIDTH 상수로 프레임 너비를 설정\n",
    "   # 640픽셀: 표준 VGA 해상도의 너비로 안정적이고 빠른 처리 가능\n",
    "   \n",
    "   cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "   # cv2.CAP_PROP_FRAME_HEIGHT 상수로 프레임 높이를 설정\n",
    "   # 480픽셀: VGA 해상도의 높이로 640x480 조합이 가장 호환성 좋음\n",
    "   \n",
    "   print(\"🎬 엣지 검출 효과 시작!\")\n",
    "   # 🎬 영화 카메라 이모지로 특수 효과 시작을 표현함\n",
    "   # 사용자에게 엣지 검출 모드가 시작되었음을 알림\n",
    "   \n",
    "   print(\"📱 's' 키로 저장, 'q' 키로 종료\")\n",
    "   # 📱 스마트폰 이모지로 키보드 조작을 연상시킴\n",
    "   # 's' 키: save의 줄임말로 현재 화면 저장\n",
    "   # 'q' 키: quit의 줄임말로 프로그램 종료\n",
    "   # 사용자에게 미리 조작 방법을 명확히 안내함\n",
    "   \n",
    "   # 프레임 개수를 세기 위한 변수 초기화\n",
    "   frame_count = 0\n",
    "   # 0부터 시작해서 매 프레임마다 1씩 증가시킬 카운터\n",
    "   # 처리 성능 모니터링과 통계 분석에 활용\n",
    "   # 프로그램이 얼마나 많은 영상 데이터를 처리했는지 추적\n",
    "   \n",
    "   try:\n",
    "       # try 블록으로 예외 상황에 대비한 안전장치 설정\n",
    "       # 웹캠 처리 중 다양한 오류가 발생할 수 있으므로 보호 필요\n",
    "       \n",
    "       while True:\n",
    "           # 무한 루프로 실시간 영상 처리 구현\n",
    "           # 웹캠에서 연속적으로 프레임을 받아서 처리하는 기본 패턴\n",
    "           \n",
    "           # 웹캠에서 한 프레임(한 장면)을 읽어옴\n",
    "           ret, frame = cap.read()\n",
    "           # cap.read()로 웹캠에서 현재 프레임을 획득\n",
    "           # 튜플 언패킹으로 두 개 값을 동시에 받음:\n",
    "           #   ret: 프레임 읽기 성공 여부 (True/False)\n",
    "           #   frame: 실제 영상 데이터 (numpy 배열)\n",
    "           \n",
    "           if not ret:\n",
    "               # ret이 False면 프레임 읽기 실패\n",
    "               # 카메라 연결 끊김, 하드웨어 문제 등의 원인\n",
    "               break\n",
    "               # while 루프를 즉시 종료해서 더 이상 처리하지 않음\n",
    "           \n",
    "           frame_count += 1\n",
    "           # 성공적으로 프레임을 읽었으므로 카운터 증가\n",
    "           # += 연산자로 기존 값에 1을 더함\n",
    "           \n",
    "           # 좌우 반전 효과 (거울처럼 보이게 함)\n",
    "           frame = cv2.flip(frame, 1)\n",
    "           # cv2.flip(이미지, 방향)으로 이미지 뒤집기\n",
    "           # 방향 1 = 좌우 반전 (수평 반전)\n",
    "           # 거울 효과로 사용자가 자연스럽게 인식할 수 있게 함\n",
    "           \n",
    "           # ★ 엣지 검출 효과: 물체의 경계선을 찾아서 스케치처럼 만듦 ★\n",
    "           \n",
    "           # 1단계: 컬러 이미지를 흑백으로 변환함\n",
    "           gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "           # cv2.cvtColor()는 색공간 변환 함수임\n",
    "           # COLOR_BGR2GRAY: BGR(파랑-초록-빨강) → GRAY(흑백)로 변환\n",
    "           # 엣지 검출이 흑백 이미지에서 더 정확하게 작동하는 이유:\n",
    "           #   1. 계산 복잡도 감소: 3채널(RGB) → 1채널(Gray)로 단순화\n",
    "           #   2. 밝기 차이에 집중: 색상 정보는 엣지 검출에 불필요한 노이즈\n",
    "           #   3. 알고리즘 최적화: 대부분의 엣지 검출 알고리즘이 흑백 기준 설계\n",
    "           #   4. 임계값 설정 용이: 하나의 밝기 값만 고려하면 됨\n",
    "           \n",
    "           # 2단계: Canny 엣지 검출 알고리즘 적용\n",
    "           edges = cv2.Canny(gray, 100, 200)\n",
    "           # cv2.Canny()는 가장 정확하고 널리 사용되는 엣지 검출 함수임\n",
    "           # 매개변수 설명:\n",
    "           #   gray: 입력 흑백 이미지 (엣지를 찾을 대상)\n",
    "           #   100: 낮은 임계값 (Low Threshold)\n",
    "           #     - 이 값보다 작은 변화는 엣지가 아님으로 간주\n",
    "           #     - 약한 엣지나 노이즈를 걸러내는 역할\n",
    "           #   200: 높은 임계값 (High Threshold)  \n",
    "           #     - 이 값보다 큰 변화는 확실한 엣지로 간주\n",
    "           #     - 강한 엣지만 확실하게 검출\n",
    "           #   100~200 사이: 이웃 픽셀과의 연결성을 확인해서 결정\n",
    "           #     - 강한 엣지와 연결된 약한 엣지는 유지\n",
    "           #     - 고립된 약한 엣지는 제거\n",
    "           \n",
    "           # Canny 알고리즘의 5단계 처리 과정:\n",
    "           # 1. 가우시안 필터로 노이즈 제거\n",
    "           # 2. 그래디언트 크기와 방향 계산 \n",
    "           # 3. 비최대 억제로 엣지 두께를 1픽셀로 세밀화\n",
    "           # 4. 이중 임계값으로 강한/약한 엣지 구분\n",
    "           # 5. 히스테리시스 추적으로 최종 엣지 연결\n",
    "           \n",
    "           # 임계값 조정 가이드:\n",
    "           #   낮은 값 (50, 100): 더 많은 엣지 검출 (세밀하지만 노이즈 많음)\n",
    "           #   높은 값 (150, 300): 적은 엣지 검출 (깔끔하지만 놓치는 것 많음)\n",
    "           #   (100, 200): 적당한 균형점 (실용적인 기본값)\n",
    "           \n",
    "           # 3단계: 흑백 엣지 이미지를 다시 컬러로 변환\n",
    "           edge_frame = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
    "           # cv2.cvtColor()로 색공간 다시 변환\n",
    "           # COLOR_GRAY2BGR: GRAY(1채널) → BGR(3채널)로 변환\n",
    "           # 변환하는 이유:\n",
    "           #   1. 일관된 데이터 형식: 다른 프레임들과 같은 3채널 형식 유지\n",
    "           #   2. 컬러 텍스트 표시: BGR 형식이어야 컬러 텍스트 추가 가능\n",
    "           #   3. 화면 출력 호환성: OpenCV 창에서 안정적인 표시\n",
    "           # 실제로는 여전히 흑백이지만 3채널로 복제되어 저장됨\n",
    "           # 예: 밝기 100 → (100, 100, 100) BGR 값으로 변환\n",
    "           \n",
    "           # 화면에 텍스트 정보들을 표시함\n",
    "           \n",
    "           # 제목 텍스트 표시\n",
    "           cv2.putText(edge_frame,\n",
    "                       # 엣지 검출이 적용된 이미지에 텍스트 추가\n",
    "                       'Edge Detection',\n",
    "                       # 현재 적용 중인 효과 이름 표시\n",
    "                       (10, 30),\n",
    "                       # 텍스트 위치: 왼쪽 위에서 (10, 30) 픽셀 떨어진 곳\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                       # 가장 일반적이고 읽기 쉬운 기본 폰트\n",
    "                       1,\n",
    "                       # 폰트 크기 1 (기본 크기)\n",
    "                       (255, 255, 255),\n",
    "                       # BGR 색상: (파랑=255, 초록=255, 빨강=255) → 흰색\n",
    "                       # 검은 배경의 엣지 이미지에서 흰색이 가장 잘 보임\n",
    "                       2)\n",
    "                       # 텍스트 두께 2픽셀 (굵고 선명하게)\n",
    "           \n",
    "           # 현재 프레임 번호 표시\n",
    "           cv2.putText(edge_frame, \n",
    "                       f'Frame: {frame_count}',\n",
    "                       # f-string으로 실시간 프레임 번호 삽입\n",
    "                       # 예: \"Frame: 1234\" 형태로 표시\n",
    "                       (10, 70),\n",
    "                       # 첫 번째 텍스트에서 40픽셀 아래 위치\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       0.8,\n",
    "                       # 제목보다 조금 작은 폰트 크기\n",
    "                       (200, 200, 200),\n",
    "                       # BGR 색상: (파랑=200, 초록=200, 빨강=200) → 밝은 회색\n",
    "                       # 엣지 이미지는 대부분 검은색이므로 밝은 회색이 잘 보임\n",
    "                       # 흰색보다 덜 강렬해서 제목과 구분됨\n",
    "                       2)\n",
    "           \n",
    "           # 조작 방법 안내 텍스트\n",
    "           cv2.putText(edge_frame, \n",
    "                       'Press S to save, Q to quit',\n",
    "                       # 키보드 조작 방법을 명확히 안내\n",
    "                       (10, 110),\n",
    "                       # 두 번째 텍스트에서 40픽셀 더 아래\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       0.6,\n",
    "                       # 안내 텍스트이므로 더 작은 폰트 사용\n",
    "                       (150, 150, 150),\n",
    "                       # BGR 색상: (파랑=150, 초록=150, 빨강=150) → 중간 회색\n",
    "                       # 가장 덜 두드러지는 색상으로 안내 정보임을 표현\n",
    "                       # 엣지 이미지에서도 충분히 읽을 수 있는 밝기\n",
    "                       1)\n",
    "                       # 얇은 텍스트 두께 (덜 두드러지게)\n",
    "           \n",
    "           # 처리된 영상을 화면에 표시함\n",
    "           cv2.imshow('Webcam - Edge Detection', edge_frame)\n",
    "           # cv2.imshow()로 엣지 검출이 적용된 영상을 출력\n",
    "           # 창 제목에 'Edge Detection'을 포함해서 현재 효과를 명시\n",
    "           # 스케치나 만화 같은 시각적 효과가 실시간으로 표시됨\n",
    "           \n",
    "           # 키보드 입력을 확인함 (1ms 대기)\n",
    "           key = cv2.waitKey(1) & 0xFF\n",
    "           # cv2.waitKey(1): 1밀리초 동안 키 입력 대기\n",
    "           # & 0xFF: 키 값을 8비트로 제한하는 비트 연산\n",
    "           #   일부 시스템에서 32비트 값이 반환되는 문제 해결\n",
    "           #   마지막 8비트만 사용해서 정확한 키 코드 얻기\n",
    "           \n",
    "           if key == ord('q'):\n",
    "               # ord('q')는 문자 'q'의 ASCII 코드 값 (113)\n",
    "               # 사용자가 'q' 키를 눌렀는지 확인\n",
    "               break\n",
    "               # while 루프를 종료해서 프로그램 끝내기\n",
    "               \n",
    "           elif key == ord('s'):\n",
    "               # ord('s')는 문자 's'의 ASCII 코드 값 (115)\n",
    "               # 사용자가 's' 키를 눌렀는지 확인 (save 기능)\n",
    "               \n",
    "               # 현재 시간을 이용해 고유한 파일명 생성\n",
    "               filename = f'edge_effect_{int(time.time())}.jpg'\n",
    "               # f-string으로 파일명 구성:\n",
    "               #   'edge_effect_': 파일명 접두사 (효과 종류 표시)\n",
    "               #   {int(time.time())}: 현재 시간을 정수로 변환한 타임스탬프\n",
    "               #   '.jpg': 파일 확장자 (JPEG 형식)\n",
    "               # time.time()은 1970년 1월 1일부터 현재까지의 초를 반환\n",
    "               # 타임스탬프로 파일명이 중복되지 않게 보장\n",
    "               \n",
    "               # 엣지 검출 효과가 적용된 이미지를 파일로 저장함\n",
    "               cv2.imwrite(filename, edge_frame)\n",
    "               # cv2.imwrite(파일명, 이미지데이터)로 이미지 저장\n",
    "               # edge_frame: 엣지 검출이 적용된 현재 프레임\n",
    "               # 스케치 같은 예술적 효과가 저장됨\n",
    "               \n",
    "               print(f\"📸 저장: {filename}\")\n",
    "               # 📸 카메라 이모지로 저장 완료를 표시\n",
    "               # f-string으로 저장된 파일명을 사용자에게 알려줌\n",
    "   \n",
    "   finally:\n",
    "       # finally 블록: try 블록이 어떻게 끝나든 반드시 실행\n",
    "       # 정상 종료든 예외 발생이든 리소스 정리는 필수\n",
    "       \n",
    "       cap.release()\n",
    "       # 웹캠 자원을 해제해서 시스템에 반환\n",
    "       # 다른 프로그램에서도 웹캠을 사용할 수 있게 함\n",
    "       # 메모리 누수 방지와 하드웨어 자원 관리\n",
    "       \n",
    "       cv2.destroyAllWindows()\n",
    "       # 모든 OpenCV 창을 닫고 메모리에서 제거\n",
    "       # GUI 자원 해제로 시스템 안정성 확보\n",
    "       \n",
    "       print(f\"✅ 엣지 검출 완료! (총 {frame_count} 프레임)\")\n",
    "       # ✅ 체크마크로 성공적인 완료 표시\n",
    "       # f-string으로 총 처리한 프레임 수를 통계로 제공\n",
    "       # 사용자에게 프로그램 성과와 완료를 동시에 알림\n",
    "\n",
    "# 엣지 검출 효과 함수를 실행함\n",
    "webcam_edge_effect()\n",
    "# 위에서 정의한 함수를 실제로 호출해서 실행\n",
    "# 이 한 줄로 전체 엣지 검출 기능이 시작됨\n",
    "\n",
    "# 💡 이 코드에서 배우는 핵심 개념들:\n",
    "# 1. Canny 엣지 검출 알고리즘의 원리와 매개변수 이해\n",
    "# 2. 색공간 변환의 목적과 방법 (BGR→GRAY→BGR)\n",
    "# 3. 임계값 설정이 결과에 미치는 영향\n",
    "# 4. 컴퓨터 비전에서 전처리의 중요성\n",
    "# 5. 실시간 이미지 분석과 특징 추출 기법\n",
    "# 6. 예술적 효과와 실용적 응용의 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2-6단계: HSV 색상 공간 효과\n",
    "# =============================================================================\n",
    "print(\"📹 2-6단계: HSV 색상 공간 효과\")\n",
    "# 📹 비디오 카메라 이모지로 웹캠 관련 학습임을 표시함\n",
    "# 2-6단계로 세분화해서 단계적 학습 진행을 명확히 구분함\n",
    "# HSV 색상 공간: 색상(Hue), 채도(Saturation), 명도(Value)로 색을 표현하는 방식\n",
    "\n",
    "print(\"=\"*25)\n",
    "# = 문자 25개로 구분선을 만들어서 시각적으로 새로운 섹션임을 표시함\n",
    "\n",
    "def webcam_hsv_effect():\n",
    "   \"\"\"웹캠 HSV 색상 공간 효과\"\"\"\n",
    "   # 독스트링으로 함수의 기능을 간단명료하게 설명함\n",
    "   # HSV 색상 공간: 사람의 색상 인식과 더 유사한 색상 표현 방식\n",
    "   # H(Hue): 색조 - 빨강, 파랑, 초록 등의 기본 색상 (0~179)\n",
    "   # S(Saturation): 채도 - 색의 순수함/진함 정도 (0~255)\n",
    "   # V(Value): 명도 - 색의 밝기 정도 (0~255)\n",
    "   # BGR보다 직관적이고 색상 기반 이미지 처리에 유리함\n",
    "   \n",
    "   cap = cv2.VideoCapture(0)\n",
    "   # cv2.VideoCapture(0)으로 시스템의 첫 번째 카메라에 연결 시도\n",
    "   # 0 = 기본 웹캠, 1 = 두 번째 카메라, 2 = 세 번째 카메라...\n",
    "   # cap 변수에 카메라 객체를 저장해서 이후 모든 카메라 조작에 사용\n",
    "   \n",
    "   if not cap.isOpened():\n",
    "       # cap.isOpened()는 카메라 연결 성공 여부를 확인하는 메서드\n",
    "       # True: 연결 성공, False: 연결 실패\n",
    "       # not으로 부정해서 연결 실패인 경우 조건이 참이 됨\n",
    "       print(\"❌ 웹캠을 열 수 없습니다!\")\n",
    "       # ❌ X표시 이모지로 오류 상황을 명확히 표현함\n",
    "       return\n",
    "       # 함수를 즉시 종료해서 더 이상 진행하지 않음\n",
    "       # 웹캠이 없으면 HSV 효과를 적용할 수 없으므로 안전하게 종료\n",
    "   \n",
    "   cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "   # cv2.CAP_PROP_FRAME_WIDTH 상수로 프레임 너비를 설정\n",
    "   # 640픽셀: 표준 VGA 해상도의 너비로 안정적이고 빠른 처리 가능\n",
    "   \n",
    "   cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "   # cv2.CAP_PROP_FRAME_HEIGHT 상수로 프레임 높이를 설정\n",
    "   # 480픽셀: VGA 해상도의 높이로 640x480 조합이 가장 호환성 좋음\n",
    "   \n",
    "   print(\"🎬 HSV 색상 공간 효과 시작!\")\n",
    "   # 🎬 영화 카메라 이모지로 특수 효과 시작을 표현함\n",
    "   # 사용자에게 HSV 색상 공간 모드가 시작되었음을 알림\n",
    "   \n",
    "   print(\"📱 's' 키로 저장, 'q' 키로 종료\")\n",
    "   # 📱 스마트폰 이모지로 키보드 조작을 연상시킴\n",
    "   # 's' 키: save의 줄임말로 현재 화면 저장\n",
    "   # 'q' 키: quit의 줄임말로 프로그램 종료\n",
    "   # 사용자에게 미리 조작 방법을 명확히 안내함\n",
    "   \n",
    "   frame_count = 0\n",
    "   # 0부터 시작해서 매 프레임마다 1씩 증가시킬 카운터\n",
    "   # 처리 성능 모니터링과 통계 분석에 활용\n",
    "   # 프로그램이 얼마나 많은 영상 데이터를 처리했는지 추적\n",
    "   \n",
    "   try:\n",
    "       # try 블록으로 예외 상황에 대비한 안전장치 설정\n",
    "       # 웹캠 처리 중 다양한 오류가 발생할 수 있으므로 보호 필요\n",
    "       \n",
    "       while True:\n",
    "           # 무한 루프로 실시간 영상 처리 구현\n",
    "           # 웹캠에서 연속적으로 프레임을 받아서 처리하는 기본 패턴\n",
    "           \n",
    "           ret, frame = cap.read()\n",
    "           # cap.read()로 웹캠에서 현재 프레임을 획득\n",
    "           # 튜플 언패킹으로 두 개 값을 동시에 받음:\n",
    "           #   ret: 프레임 읽기 성공 여부 (True/False)\n",
    "           #   frame: 실제 영상 데이터 (numpy 배열)\n",
    "           \n",
    "           if not ret:\n",
    "               # ret이 False면 프레임 읽기 실패\n",
    "               # 카메라 연결 끊김, 하드웨어 문제 등의 원인\n",
    "               break\n",
    "               # while 루프를 즉시 종료해서 더 이상 처리하지 않음\n",
    "           \n",
    "           frame_count += 1\n",
    "           # 성공적으로 프레임을 읽었으므로 카운터 증가\n",
    "           # += 연산자로 기존 값에 1을 더함\n",
    "           \n",
    "           frame = cv2.flip(frame, 1)\n",
    "           # cv2.flip(이미지, 방향)으로 이미지 뒤집기\n",
    "           # 방향 1 = 좌우 반전 (수평 반전)\n",
    "           # 거울 효과로 사용자가 자연스럽게 인식할 수 있게 함\n",
    "           \n",
    "           # ★ HSV 색상 공간 변환: BGR에서 HSV로 색상 체계를 바꿈 ★\n",
    "           hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "           # cv2.cvtColor()는 색공간 변환 함수임\n",
    "           # COLOR_BGR2HSV: BGR(파랑-초록-빨강) → HSV(색조-채도-명도)로 변환\n",
    "           \n",
    "           # HSV 색상 공간의 특징과 장점:\n",
    "           # 1. 직관적 색상 표현:\n",
    "           #    - H(Hue): 0~179 범위로 색조를 나타냄 (빨강=0, 초록=60, 파랑=120)\n",
    "           #    - S(Saturation): 0~255 범위로 색의 순수함 (0=회색, 255=순수색)\n",
    "           #    - V(Value): 0~255 범위로 밝기 (0=검정, 255=최대밝기)\n",
    "           \n",
    "           # 2. 색상 기반 처리에 유리:\n",
    "           #    - 특정 색상 범위 검출이 쉬움 (예: 빨간 물체만 찾기)\n",
    "           #    - 조명 변화에 상대적으로 강함\n",
    "           #    - 색상 필터링과 마스킹에 효과적\n",
    "           \n",
    "           # 3. BGR vs HSV 비교:\n",
    "           #    - BGR: 각 채널이 독립적, 색상 변화 추적 어려움\n",
    "           #    - HSV: 색상 정보가 H 채널에 집중, 직관적 조작 가능\n",
    "           \n",
    "           # 4. 실제 활용 분야:\n",
    "           #    - 색상 기반 객체 검출 (크로마키, 피부색 검출 등)\n",
    "           #    - 이미지 색상 보정 및 향상\n",
    "           #    - 컴퓨터 비전에서 색상 분석\n",
    "           #    - 예술적 색상 효과 생성\n",
    "           \n",
    "           # 변환 결과: 원본과 다른 색감의 이미지가 생성됨\n",
    "           # 각 픽셀의 BGR 값이 HSV 값으로 재해석되어 독특한 시각 효과 발생\n",
    "           \n",
    "           # 정보 표시 (HSV 변환된 이미지에 텍스트 추가)\n",
    "           cv2.putText(hsv_frame, 'HSV Color Space', (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "           # 첫 번째 텍스트: 현재 효과 이름 표시\n",
    "           # 'HSV Color Space': 색상 공간 변환 효과임을 명시\n",
    "           # (10, 30): 텍스트 위치 (왼쪽 위에서 약간 떨어진 곳)\n",
    "           # cv2.FONT_HERSHEY_SIMPLEX: 읽기 쉬운 기본 폰트\n",
    "           # 1: 폰트 크기 (기본 크기)\n",
    "           # (255, 255, 255): BGR 색상으로 흰색 지정\n",
    "           #   HSV 변환된 이미지에서도 흰색이 안전하게 표시됨\n",
    "           # 2: 텍스트 두께 (굵고 선명하게)\n",
    "           \n",
    "           cv2.putText(hsv_frame, f'Frame: {frame_count}', (10, 70), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)\n",
    "           # 두 번째 텍스트: 현재 프레임 번호 표시\n",
    "           # f'Frame: {frame_count}': f-string으로 실시간 프레임 번호 삽입\n",
    "           # (10, 70): 첫 번째 텍스트에서 40픽셀 아래 위치\n",
    "           # 0.8: 제목보다 조금 작은 폰트 크기\n",
    "           # (255, 255, 0): BGR 색상으로 노란색 지정\n",
    "           #   HSV 이미지에서 노란색이 잘 구분되어 보임\n",
    "           \n",
    "           cv2.putText(hsv_frame, 'Press S to save, Q to quit', (10, 110), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 1)\n",
    "           # 세 번째 텍스트: 조작 방법 안내\n",
    "           # 'Press S to save, Q to quit': 키보드 조작 방법 명시\n",
    "           # (10, 110): 두 번째 텍스트에서 40픽셀 더 아래\n",
    "           # 0.6: 안내 텍스트이므로 더 작은 폰트 사용\n",
    "           # (0, 255, 255): BGR 색상으로 하늘색 지정\n",
    "           #   HSV 변환된 배경에서도 잘 보이는 색상 선택\n",
    "           # 1: 얇은 텍스트 두께 (덜 두드러지게)\n",
    "           \n",
    "           cv2.imshow('Webcam - HSV Color Space', hsv_frame)\n",
    "           # cv2.imshow()로 HSV 변환된 영상을 화면에 출력\n",
    "           # 창 제목에 'HSV Color Space'를 포함해서 현재 효과를 명시\n",
    "           # 원본과는 완전히 다른 색감의 독특한 영상이 실시간으로 표시됨\n",
    "           # 빨간색이 청록색으로, 파란색이 주황색으로 나타나는 등 흥미로운 변화\n",
    "           \n",
    "           key = cv2.waitKey(1) & 0xFF\n",
    "           # cv2.waitKey(1): 1밀리초 동안 키 입력 대기\n",
    "           # & 0xFF: 키 값을 8비트로 제한하는 비트 연산\n",
    "           #   일부 시스템에서 32비트 값이 반환되는 문제 해결\n",
    "           #   마지막 8비트만 사용해서 정확한 키 코드 얻기\n",
    "           \n",
    "           if key == ord('q'):\n",
    "               # ord('q')는 문자 'q'의 ASCII 코드 값 (113)\n",
    "               # 사용자가 'q' 키를 눌렀는지 확인\n",
    "               break\n",
    "               # while 루프를 종료해서 프로그램 끝내기\n",
    "               \n",
    "           elif key == ord('s'):\n",
    "               # ord('s')는 문자 's'의 ASCII 코드 값 (115)\n",
    "               # 사용자가 's' 키를 눌렀는지 확인 (save 기능)\n",
    "               \n",
    "               filename = f'hsv_effect_{int(time.time())}.jpg'\n",
    "               # f-string으로 파일명 구성:\n",
    "               #   'hsv_effect_': 파일명 접두사 (효과 종류 표시)\n",
    "               #   {int(time.time())}: 현재 시간을 정수로 변환한 타임스탬프\n",
    "               #   '.jpg': 파일 확장자 (JPEG 형식)\n",
    "               # time.time()은 1970년 1월 1일부터 현재까지의 초를 반환\n",
    "               # 타임스탬프로 파일명이 중복되지 않게 보장\n",
    "               \n",
    "               cv2.imwrite(filename, hsv_frame)\n",
    "               # cv2.imwrite(파일명, 이미지데이터)로 이미지 저장\n",
    "               # hsv_frame: HSV 색상 공간으로 변환된 현재 프레임\n",
    "               # 독특한 색감의 예술적 효과가 저장됨\n",
    "               \n",
    "               print(f\"📸 저장: {filename}\")\n",
    "               # 📸 카메라 이모지로 저장 완료를 표시\n",
    "               # f-string으로 저장된 파일명을 사용자에게 알려줌\n",
    "   \n",
    "   finally:\n",
    "       # finally 블록: try 블록이 어떻게 끝나든 반드시 실행\n",
    "       # 정상 종료든 예외 발생이든 리소스 정리는 필수\n",
    "       \n",
    "       cap.release()\n",
    "       # 웹캠 자원을 해제해서 시스템에 반환\n",
    "       # 다른 프로그램에서도 웹캠을 사용할 수 있게 함\n",
    "       # 메모리 누수 방지와 하드웨어 자원 관리\n",
    "       \n",
    "       cv2.destroyAllWindows()\n",
    "       # 모든 OpenCV 창을 닫고 메모리에서 제거\n",
    "       # GUI 자원 해제로 시스템 안정성 확보\n",
    "       \n",
    "       print(f\"✅ HSV 효과 완료! (총 {frame_count} 프레임)\")\n",
    "       # ✅ 체크마크로 성공적인 완료 표시\n",
    "       # f-string으로 총 처리한 프레임 수를 통계로 제공\n",
    "       # 사용자에게 프로그램 성과와 완료를 동시에 알림\n",
    "\n",
    "# HSV 효과 실행\n",
    "webcam_hsv_effect()\n",
    "# 위에서 정의한 함수를 실제로 호출해서 실행\n",
    "# 이 한 줄로 전체 HSV 색상 공간 변환 기능이 시작됨\n",
    "\n",
    "# 💡 이 코드에서 배우는 핵심 개념들:\n",
    "# 1. HSV 색상 공간의 원리와 BGR과의 차이점\n",
    "# 2. 색상 공간 변환의 목적과 활용 분야\n",
    "# 3. 직관적 색상 표현 방식의 장점 이해\n",
    "# 4. 컴퓨터 비전에서 색상 정보의 중요성\n",
    "# 5. 색상 기반 이미지 처리의 기초 개념\n",
    "# 6. 예술적 효과와 기술적 응용의 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a52f38b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "941c5d67",
   "metadata": {},
   "source": [
    "## 🌈 3단계: 색상과 이미지 변환 실험실\n",
    "\n",
    "### 🎯 목표\n",
    "이미지의 색상을 다양하게 조작하고 변환하는 고급 기법들을 배워보겠습니다. \n",
    "포토샵에서 볼 수 있는 고급 효과들을 코드로 직접 구현해보세요!\n",
    "\n",
    "### 🎨 색상 변환 종류\n",
    "- **HSV**: 색조(Hue), 채도(Saturation), 명도(Value)\n",
    "- **LAB**: 인간의 시각과 유사한 색상 공간\n",
    "- **RGB**: 빨강, 초록, 파랑의 조합\n",
    "- **채널 분리**: 각 색상 성분을 개별적으로 분석\n",
    "\n",
    "### 🔧 이미지 변환 기법\n",
    "- **히스토그램 평활화**: 대비 개선\n",
    "- **감마 보정**: 밝기 조절\n",
    "- **색상 필터링**: 특정 색상만 추출\n",
    "- **노이즈 제거**: 이미지 품질 향상\n",
    "\n",
    "### 💡 실무 활용\n",
    "- 의료 영상 분석에서 특정 조직 강조\n",
    "- 위성 사진에서 식생 분석\n",
    "- 제품 검사에서 결함 발견\n",
    "- 사진 편집에서 색감 보정\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3-1단계: 고급 색상 및 이미지 변환 \n",
    "# =============================================================================\n",
    "\n",
    "print(\"🌈 3-1단계: 색상과 이미지 변환 실험\")\n",
    "# 🌈 무지개 이모지로 다양한 색상 변환을 표현함\n",
    "# 3단계로 단계를 높여서 고급 기법들을 다룸을 명시함\n",
    "# 색상과 이미지 변환: 컴퓨터 비전의 전처리와 분석에 핵심적인 기법들\n",
    "\n",
    "print(\"=\"*30)\n",
    "# = 문자 30개로 구분선을 만들어서 새로운 고급 섹션의 시작을 표시함\n",
    "\n",
    "def advanced_image_processing():\n",
    "   \"\"\"고급 이미지 처리 및 색상 변환 데모\"\"\"\n",
    "   # 독스트링으로 함수의 고급 기능들을 설명함\n",
    "   # 이 함수는 실제 컴퓨터 비전 프로젝트에서 사용되는 핵심 기법들을 포함함:\n",
    "   # - 색상 공간 변환 (HSV, LAB 등)\n",
    "   # - 히스토그램 처리 (대비 향상)\n",
    "   # - 색상 필터링 (특정 색상 검출)\n",
    "   # - 감마 보정 (밝기 조절)\n",
    "   # - 노이즈 제거 (다양한 필터 기법)\n",
    "   \n",
    "   # 웹캠에서 한 프레임 캡처하여 샘플 이미지로 사용\n",
    "   cap = cv2.VideoCapture(0)\n",
    "   # 웹캠을 연결해서 실제 이미지를 캡처할 예정\n",
    "   # 실시간 영상이 아닌 정적 이미지로 다양한 처리 기법을 시연함\n",
    "   \n",
    "   if cap.isOpened():\n",
    "       # 웹캠이 성공적으로 열렸다면 샘플 이미지 캡처 시도\n",
    "       ret, sample_image = cap.read()\n",
    "       # 한 프레임만 읽어서 샘플로 사용함\n",
    "       cap.release()\n",
    "       # 즉시 웹캠 리소스 해제 (한 번만 사용하므로)\n",
    "       \n",
    "       if ret:\n",
    "           # 프레임 읽기가 성공했다면\n",
    "           sample_image = cv2.flip(sample_image, 1)\n",
    "           # 좌우 반전으로 거울 효과 적용 (자연스러운 느낌)\n",
    "           print(\"📸 웹캠에서 샘플 이미지 캡처 성공!\")\n",
    "           # 📸 카메라 이모지로 캡처 성공을 표시함\n",
    "       else:\n",
    "           # 프레임 읽기 실패시 대안으로 테스트 이미지 생성\n",
    "           sample_image = create_test_image()\n",
    "           # 미리 정의된 함수로 색상 테스트용 이미지 만들기\n",
    "           print(\"🎨 테스트 이미지 생성!\")\n",
    "           # 🎨 팔레트 이모지로 인위적 이미지 생성을 표시함\n",
    "   else:\n",
    "       # 웹캠 연결 자체가 실패한 경우\n",
    "       sample_image = create_test_image()\n",
    "       # 테스트 이미지로 대체해서 실습 계속 진행\n",
    "       print(\"🎨 테스트 이미지 생성!\")\n",
    "       # 웹캠이 없어도 학습을 계속할 수 있도록 배려\n",
    "   \n",
    "   # 1. 색상 공간 변환 실험\n",
    "   print(\"\\n🎨 색상 공간 변환 중...\")\n",
    "   # \\n으로 줄바꿈해서 새로운 처리 단계 시작을 표시함\n",
    "   # 🎨 이모지로 색상 관련 작업임을 표현함\n",
    "   \n",
    "   # RGB에서 다양한 색상 공간으로 변환\n",
    "   hsv_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2HSV)\n",
    "   # BGR → HSV 변환: 색조, 채도, 명도로 색상을 표현\n",
    "   # HSV는 인간의 색상 인식과 유사한 직관적 색상 체계\n",
    "   # 색상 기반 객체 검출과 필터링에 매우 유용함\n",
    "   \n",
    "   lab_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2LAB)\n",
    "   # BGR → LAB 변환: CIE LAB 색상 공간으로 변환\n",
    "   # L(밝기), A(적록 축), B(청황 축)로 구성됨\n",
    "   # 인간의 시각적 인식과 가장 유사한 색상 공간\n",
    "   # 색상 보정과 이미지 향상에 효과적임\n",
    "   \n",
    "   gray_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2GRAY)\n",
    "   # BGR → GRAY 변환: 흑백 이미지로 변환\n",
    "   # 컬러 정보를 제거하고 밝기 정보만 유지\n",
    "   # 많은 컴퓨터 비전 알고리즘의 전처리 단계로 사용됨\n",
    "   \n",
    "   # HSV 채널 분리 (색조, 채도, 명도)\n",
    "   h, s, v = cv2.split(hsv_image)\n",
    "   # cv2.split()으로 3채널 이미지를 개별 채널로 분리\n",
    "   # h: Hue (색조) - 0~179 범위의 색상 정보\n",
    "   # s: Saturation (채도) - 0~255 범위의 색상 순수도\n",
    "   # v: Value (명도) - 0~255 범위의 밝기 정보\n",
    "   # 각 채널을 개별적으로 분석하고 조작할 수 있게 됨\n",
    "   \n",
    "   # RGB 채널 분리\n",
    "   b, g, r = cv2.split(sample_image)\n",
    "   # BGR 순서로 파랑, 초록, 빨강 채널을 개별 분리\n",
    "   # 각 색상 성분을 독립적으로 처리할 수 있음\n",
    "   # 특정 색상 채널의 특성 분석이나 보정에 활용\n",
    "   \n",
    "   # 2. 히스토그램 평활화 (대비 개선)\n",
    "   print(\"📊 히스토그램 평활화 적용...\")\n",
    "   # 📊 차트 이모지로 히스토그램 관련 작업임을 표시함\n",
    "   # 히스토그램 평활화: 이미지의 대비를 향상시키는 기법\n",
    "   \n",
    "   # 회색조 이미지에 히스토그램 평활화\n",
    "   equalized_gray = cv2.equalizeHist(gray_image)\n",
    "   # cv2.equalizeHist()는 히스토그램을 균등하게 분포시키는 함수\n",
    "   # 어두운 이미지를 밝게 만들고 대비를 향상시킨다\n",
    "   # 작동 원리:\n",
    "   #   1. 이미지의 밝기 히스토그램 계산\n",
    "   #   2. 누적 분포 함수(CDF) 생성\n",
    "   #   3. CDF를 이용해 픽셀값을 재매핑\n",
    "   #   4. 결과: 전체 밝기 범위를 고르게 활용하는 이미지\n",
    "   \n",
    "   # 컬러 이미지에 CLAHE (적응적 히스토그램 평활화) 적용\n",
    "   clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "   # CLAHE: Contrast Limited Adaptive Histogram Equalization\n",
    "   # 일반 히스토그램 평활화의 문제점(과도한 증폭) 해결\n",
    "   # clipLimit=2.0: 대비 제한값 (과도한 증폭 방지)\n",
    "   # tileGridSize=(8,8): 이미지를 8x8 격자로 나누어 국부적 처리\n",
    "   # 지역적 특성을 고려한 적응적 대비 향상 기법\n",
    "   \n",
    "   # LAB 채널을 리스트로 변환하여 수정 가능하게 만듦\n",
    "   lab_channels = list(cv2.split(lab_image))\n",
    "   # cv2.split() 결과를 리스트로 변환해서 개별 채널 수정 가능\n",
    "   \n",
    "   lab_channels[0] = clahe.apply(lab_channels[0])\n",
    "   # L 채널(밝기)에만 CLAHE 적용\n",
    "   # LAB 색상 공간에서 L은 밝기, A와 B는 색상 정보\n",
    "   # 밝기만 조정하면 색상 왜곡 없이 대비 향상 가능\n",
    "   \n",
    "   enhanced_lab = cv2.merge(lab_channels)\n",
    "   # 수정된 채널들을 다시 하나의 이미지로 합성\n",
    "   \n",
    "   enhanced_color = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)\n",
    "   # LAB → BGR 변환으로 최종 컬러 이미지 생성\n",
    "   # 결과: 색상 왜곡 없이 대비가 향상된 이미지\n",
    "   \n",
    "   # 3. 색상 필터링 (특정 색상 범위 추출)\n",
    "   print(\"🔍 색상 필터링 적용...\")\n",
    "   # 🔍 돋보기 이모지로 특정 색상 찾기 작업을 표현함\n",
    "   # 색상 필터링: HSV 색상 공간에서 특정 색상 범위만 추출\n",
    "   \n",
    "   # 파란색 객체만 추출\n",
    "   lower_blue = np.array([100, 50, 50])\n",
    "   # 파란색의 HSV 하한값 설정\n",
    "   # H=100: 파란색 색조의 시작점 (HSV에서 파란색은 대략 100~130)\n",
    "   # S=50: 최소 채도 (너무 흐린 색상 제외)\n",
    "   # V=50: 최소 명도 (너무 어두운 색상 제외)\n",
    "   \n",
    "   upper_blue = np.array([130, 255, 255])\n",
    "   # 파란색의 HSV 상한값 설정\n",
    "   # H=130: 파란색 색조의 끝점\n",
    "   # S=255: 최대 채도 (모든 채도 포함)\n",
    "   # V=255: 최대 명도 (모든 밝기 포함)\n",
    "   \n",
    "   blue_mask = cv2.inRange(hsv_image, lower_blue, upper_blue)\n",
    "   # cv2.inRange()로 지정된 HSV 범위에 해당하는 픽셀만 추출\n",
    "   # 결과: 파란색 부분은 흰색(255), 나머지는 검은색(0)인 마스크\n",
    "   \n",
    "   blue_filtered = cv2.bitwise_and(sample_image, sample_image, mask=blue_mask)\n",
    "   # cv2.bitwise_and()로 마스크를 적용해서 파란색 부분만 표시\n",
    "   # 파란색이 아닌 부분은 검은색으로 만들어 파란색 객체만 강조\n",
    "   \n",
    "   # 빨간색 객체만 추출 (빨간색은 HSV에서 두 범위로 나뉨)\n",
    "   lower_red1 = np.array([0, 50, 50])\n",
    "   upper_red1 = np.array([10, 255, 255])\n",
    "   # 첫 번째 빨간색 범위: H=0~10 (HSV 원형 스펙트럼의 시작 부분)\n",
    "   \n",
    "   lower_red2 = np.array([170, 50, 50])\n",
    "   upper_red2 = np.array([180, 255, 255])\n",
    "   # 두 번째 빨간색 범위: H=170~180 (HSV 원형 스펙트럼의 끝 부분)\n",
    "   # 빨간색이 HSV 색조 스펙트럼의 양 끝에 위치하기 때문에 두 범위 필요\n",
    "   \n",
    "   red_mask1 = cv2.inRange(hsv_image, lower_red1, upper_red1)\n",
    "   red_mask2 = cv2.inRange(hsv_image, lower_red2, upper_red2)\n",
    "   # 각각의 빨간색 범위에 대해 마스크 생성\n",
    "   \n",
    "   red_mask = cv2.bitwise_or(red_mask1, red_mask2)\n",
    "   # cv2.bitwise_or()로 두 마스크를 결합 (논리합 연산)\n",
    "   # 어느 한 범위에라도 속하면 빨간색으로 인식\n",
    "   \n",
    "   red_filtered = cv2.bitwise_and(sample_image, sample_image, mask=red_mask)\n",
    "   # 최종 빨간색 마스크를 적용해서 빨간색 객체만 추출\n",
    "   \n",
    "   # 4. 감마 보정 (밝기 조절)\n",
    "   print(\"💡 감마 보정 적용...\")\n",
    "   # 💡 전구 이모지로 밝기 조절 작업을 표현함\n",
    "   # 감마 보정: 이미지의 밝기를 비선형적으로 조절하는 기법\n",
    "   \n",
    "   def adjust_gamma(image, gamma=1.0):\n",
    "       \"\"\"감마 보정 함수\"\"\"\n",
    "       # 감마 보정을 수행하는 독립적인 함수 정의\n",
    "       # gamma 값에 따라 이미지 밝기를 조절함\n",
    "       \n",
    "       inv_gamma = 1.0 / gamma\n",
    "       # 역감마 값 계산 (실제 연산에 사용되는 값)\n",
    "       \n",
    "       table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "       # 룩업 테이블(LUT) 생성: 0~255 각 값에 대한 변환값 미리 계산\n",
    "       # 수식: output = 255 * (input/255)^(1/gamma)\n",
    "       # 감마 < 1: 이미지가 밝아짐 (어두운 부분이 더 밝아짐)\n",
    "       # 감마 > 1: 이미지가 어두워짐 (밝은 부분이 더 어두워짐)\n",
    "       # 감마 = 1: 변화 없음 (원본 유지)\n",
    "       \n",
    "       return cv2.LUT(image, table)\n",
    "       # cv2.LUT()로 룩업 테이블을 이미지에 적용\n",
    "       # 모든 픽셀값을 table의 해당 인덱스 값으로 변환\n",
    "       # 매우 빠른 연산 (미리 계산된 값 사용)\n",
    "   \n",
    "   bright_image = adjust_gamma(sample_image, gamma=0.5)\n",
    "   # 감마 0.5로 이미지를 밝게 만듦 (감마 < 1)\n",
    "   # 어두운 영역이 더 많이 밝아져서 세부사항이 잘 보임\n",
    "   \n",
    "   dark_image = adjust_gamma(sample_image, gamma=2.0)\n",
    "   # 감마 2.0으로 이미지를 어둡게 만듦 (감마 > 1)\n",
    "   # 밝은 영역이 더 어두워져서 극적인 효과 연출\n",
    "   \n",
    "   # 5. 노이즈 제거 필터\n",
    "   print(\"🧹 노이즈 제거 필터 적용...\")\n",
    "   # 🧹 빗자루 이모지로 노이즈 청소 작업을 표현함\n",
    "   # 노이즈 제거: 이미지의 원하지 않는 잡음을 제거하는 기법들\n",
    "   \n",
    "   # 가우시안 블러 (부드럽게)\n",
    "   gaussian_blur = cv2.GaussianBlur(sample_image, (15, 15), 0)\n",
    "   # cv2.GaussianBlur()로 가우시안 분포 기반 블러 적용\n",
    "   # (15, 15): 커널 크기 (블러 강도 결정)\n",
    "   # 0: 표준편차 (자동 계산)\n",
    "   # 효과: 전체적으로 부드럽고 자연스러운 흐림\n",
    "   # 단점: 엣지도 함께 흐려짐\n",
    "   \n",
    "   # 양방향 필터 (엣지 보존하면서 노이즈 제거)\n",
    "   bilateral_filter = cv2.bilateralFilter(sample_image, 9, 75, 75)\n",
    "   # cv2.bilateralFilter()는 엣지를 보존하는 스마트한 필터\n",
    "   # 9: 필터 크기 (픽셀 이웃 범위)\n",
    "   # 75: 색상 차이 임계값 (비슷한 색상끼리 블러)\n",
    "   # 75: 공간 거리 임계값 (가까운 픽셀끼리 블러)\n",
    "   # 장점: 노이즈는 제거하면서 엣지는 선명하게 유지\n",
    "   # 용도: 사진 보정, 노이즈 제거에 효과적\n",
    "   \n",
    "   # 미디언 블러 (점 노이즈 제거에 효과적)\n",
    "   median_blur = cv2.medianBlur(sample_image, 5)\n",
    "   # cv2.medianBlur()는 중간값 필터 적용\n",
    "   # 5: 커널 크기 (5x5 영역의 중간값 사용)\n",
    "   # 작동 원리: 각 픽셀을 주변 픽셀들의 중간값으로 대체\n",
    "   # 장점: 소금-후추 노이즈(점 노이즈) 제거에 매우 효과적\n",
    "   # 특징: 엣지를 어느 정도 보존하면서 점 노이즈만 선택적 제거\n",
    "   \n",
    "   # 6. 결과 이미지들을 순서대로 표시\n",
    "   results = [\n",
    "       (sample_image, \"Original Image\"),                                    # 원본 이미지\n",
    "       (hsv_image, \"HSV Color Space\"),                                     # HSV 색상 공간\n",
    "       (lab_image, \"LAB Color Space\"),                                     # LAB 색상 공간\n",
    "       (cv2.cvtColor(gray_image, cv2.COLOR_GRAY2BGR), \"Grayscale\"),       # 흑백 변환\n",
    "       (cv2.cvtColor(equalized_gray, cv2.COLOR_GRAY2BGR), \"Histogram Equalized\"), # 히스토그램 평활화\n",
    "       (enhanced_color, \"CLAHE Enhanced\"),                                 # CLAHE 대비 향상\n",
    "       (cv2.cvtColor(h, cv2.COLOR_GRAY2BGR), \"Hue Channel\"),             # 색조 채널\n",
    "       (cv2.cvtColor(s, cv2.COLOR_GRAY2BGR), \"Saturation Channel\"),      # 채도 채널\n",
    "       (cv2.cvtColor(v, cv2.COLOR_GRAY2BGR), \"Value Channel\"),           # 명도 채널\n",
    "       (blue_filtered, \"Blue Color Filter\"),                              # 파란색 필터\n",
    "       (red_filtered, \"Red Color Filter\"),                               # 빨간색 필터\n",
    "       (bright_image, \"Gamma Bright\"),                                    # 감마 밝게\n",
    "       (dark_image, \"Gamma Dark\"),                                        # 감마 어둡게\n",
    "       (gaussian_blur, \"Gaussian Blur\"),                                  # 가우시안 블러\n",
    "       (bilateral_filter, \"Bilateral Filter\"),                           # 양방향 필터\n",
    "       (median_blur, \"Median Blur\")                                       # 미디언 블러\n",
    "   ]\n",
    "   # 튜플 리스트로 (이미지, 설명) 쌍을 정리함\n",
    "   # 총 16가지 다양한 이미지 처리 결과를 순서대로 보여줄 예정\n",
    "   # 각 처리 기법의 효과를 시각적으로 비교할 수 있게 구성\n",
    "   \n",
    "   print(f\"\\n👀 {len(results)}가지 이미지 처리 결과를 보여드립니다...\")\n",
    "   # 👀 눈 이모지로 시각적 확인을 표현함\n",
    "   # len(results)로 동적으로 총 개수를 표시 (16가지)\n",
    "   \n",
    "   print(\"💡 각 이미지는 3초간 표시됩니다. 아무 키나 누르면 다음으로 넘어갑니다.\")\n",
    "   print(\"📱 's' 키를 누르면 현재 이미지를 저장할 수 있습니다.\")\n",
    "   # 사용자에게 조작 방법을 미리 안내함\n",
    "   # 3초 자동 진행 + 키 입력으로 수동 제어 + 저장 기능 제공\n",
    "   \n",
    "   for i, (img, title) in enumerate(results, 1):\n",
    "       # enumerate(리스트, 1)로 1부터 시작하는 번호와 함께 반복\n",
    "       # i: 현재 순서 번호 (1~16)\n",
    "       # img: 처리된 이미지 데이터\n",
    "       # title: 이미지 설명 텍스트\n",
    "       \n",
    "       print(f\"  📷 {i}/{len(results)}: {title}\")\n",
    "       # 📷 카메라 이모지로 현재 표시 중인 이미지를 표현함\n",
    "       # 진행 상황을 \"현재/전체\" 형태로 명확히 표시\n",
    "       \n",
    "       # 이미지에 제목 표시\n",
    "       display_img = img.copy()\n",
    "       # 원본 이미지를 보존하기 위해 복사본 생성\n",
    "       \n",
    "       cv2.rectangle(display_img, (10, 10), (400, 50), (0, 0, 0), -1)\n",
    "       # 검은색 배경 사각형을 그려서 텍스트 가독성 향상\n",
    "       # (10, 10)에서 (400, 50)까지 검은색으로 채움\n",
    "       \n",
    "       cv2.putText(display_img, title, (15, 35), \n",
    "                  cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "       # 검은 배경 위에 흰색 텍스트로 제목 표시\n",
    "       # (15, 35): 사각형 안쪽 적절한 위치\n",
    "       # 0.8: 읽기 좋은 폰트 크기\n",
    "       # (255, 255, 255): 흰색으로 명확한 가독성\n",
    "       \n",
    "       cv2.imshow(f'OpenCV Image Processing - {title}', display_img)\n",
    "       # 창 제목에 현재 처리 기법 이름 포함\n",
    "       # 사용자가 어떤 기법을 보고 있는지 명확히 인식\n",
    "       \n",
    "       # 키 입력 대기\n",
    "       key = cv2.waitKey(3000)\n",
    "       # 3초 대기 또는 키 입력시 즉시 진행\n",
    "       # 3000ms = 3초로 충분한 관찰 시간 제공\n",
    "       \n",
    "       if key == ord('s'):\n",
    "           # 's' 키가 눌렸다면 현재 이미지 저장\n",
    "           filename = f'image_processing_{title.replace(\" \", \"_\")}_{int(time.time())}.jpg'\n",
    "           # 파일명 생성: 처리기법명 + 타임스탬프\n",
    "           # title.replace(\" \", \"_\"): 공백을 언더스코어로 변경 (파일명 호환성)\n",
    "           # int(time.time()): 중복 방지용 타임스탬프\n",
    "           \n",
    "           cv2.imwrite(filename, img)\n",
    "           # 원본 이미지 저장 (제목 텍스트 제외)\n",
    "           \n",
    "           print(f\"    💾 저장 완료: {filename}\")\n",
    "           # 💾 저장 이모지로 저장 완료를 표시\n",
    "           \n",
    "       elif key != -1:\n",
    "           # 다른 키가 눌렸다면 (s가 아닌 모든 키)\n",
    "           print(f\"    ⏭️ 사용자 입력으로 다음 이미지로...\")\n",
    "           # ⏭️ 다음 버튼 이모지로 건너뛰기 표현\n",
    "       \n",
    "       cv2.destroyAllWindows()\n",
    "       # 현재 창을 닫고 다음 이미지 준비\n",
    "       # 창이 겹치지 않게 깔끔하게 정리\n",
    "   \n",
    "   print(\"✅ 고급 이미지 처리 체험 완료!\")\n",
    "   # ✅ 체크마크로 성공적인 완료 표시\n",
    "   \n",
    "   print(\"📊 처리 결과 요약:\")\n",
    "   print(f\"   🖼️ 총 {len(results)}가지 이미지 변환 기법 적용\")\n",
    "   print(\"   🎨 색상 공간 변환: HSV, LAB, Grayscale\")\n",
    "   print(\"   📈 히스토그램 처리: 평활화, CLAHE\")\n",
    "   print(\"   🎯 색상 필터링: 파란색, 빨간색 추출\")\n",
    "   print(\"   💡 감마 보정: 밝기 조절\")\n",
    "   print(\"   🧹 노이즈 제거: 가우시안, 양방향, 미디언 필터\")\n",
    "   # 📊 차트 이모지로 요약 정보임을 표시\n",
    "   # 카테고리별로 적용된 기법들을 정리해서 학습 내용 복습\n",
    "   # 이모지를 활용해서 각 기법의 특성을 직관적으로 표현\n",
    "\n",
    "def create_test_image():\n",
    "   \"\"\"웹캠이 없을 때 사용할 테스트 이미지 생성\"\"\"\n",
    "   # 웹캠이 없는 환경에서도 실습할 수 있도록 대안 제공\n",
    "   # 다양한 색상과 도형을 포함한 테스트 이미지 생성\n",
    "   \n",
    "   print(\"🎨 다채로운 테스트 이미지 생성 중...\")\n",
    "   # 🎨 팔레트 이모지로 인위적 이미지 생성을 표현함\n",
    "   \n",
    "   test_img = np.zeros((400, 600, 3), dtype=np.uint8)\n",
    "   # 400x600 크기의 검은 캔버스 생성\n",
    "   # 3채널 BGR 형식으로 컬러 이미지 준비\n",
    "   \n",
    "   # 다양한 색상의 도형들을 그려서 색상 처리 테스트용 이미지 생성\n",
    "   cv2.rectangle(test_img, (50, 50), (150, 150), (255, 0, 0), -1)\n",
    "   # 파란색 사각형: BGR(255, 0, 0) - 파란색 필터 테스트용\n",
    "   \n",
    "   cv2.rectangle(test_img, (200, 50), (300, 150), (0, 255, 0), -1)\n",
    "   # 초록색 사각형: BGR(0, 255, 0) - 중간 색상 테스트\n",
    "   \n",
    "   cv2.rectangle(test_img, (350, 50), (450, 150), (0, 0, 255), -1)\n",
    "   # 빨간색 사각형: BGR(0, 0, 255) - 빨간색 필터 테스트용\n",
    "   \n",
    "   cv2.circle(test_img, (125, 250), 50, (255, 255, 0), -1)\n",
    "   # 청록색 원: BGR(255, 255, 0) - 혼합 색상 테스트\n",
    "   \n",
    "   cv2.circle(test_img, (275, 250), 50, (255, 0, 255), -1)\n",
    "   # 자주색 원: BGR(255, 0, 255) - 혼합 색상 테스트\n",
    "   \n",
    "   cv2.circle(test_img, (425, 250), 50, (0, 255, 255), -1)\n",
    "   # 노란색 원: BGR(0, 255, 255) - 혼합 색상 테스트\n",
    "   \n",
    "   # 그라데이션 배경 추가\n",
    "   for y in range(400):\n",
    "       for x in range(600):\n",
    "           # 모든 픽셀에 대해 반복 처리\n",
    "            if test_img[y, x].sum() == 0:\n",
    "               # 픽셀값의 합이 0이면 검은색 부분 (도형이 그려지지 않은 배경)\n",
    "               # sum()으로 BGR 세 채널 값을 모두 더해서 확인\n",
    "               # 0이면 (0,0,0) 검은색, 0이 아니면 이미 색상이 있는 부분\n",
    "               test_img[y, x] = [\n",
    "                   int((x / 600) * 100),  # Blue 채널\n",
    "                   # x 좌표에 비례해서 파란색 강도 결정\n",
    "                   # 왼쪽(x=0)에서 오른쪽(x=600)으로 갈수록 파란색 진해짐\n",
    "                   # 0~100 범위로 제한해서 너무 밝지 않게 조절\n",
    "                   \n",
    "                   int((y / 400) * 100),  # Green 채널\n",
    "                   # y 좌표에 비례해서 초록색 강도 결정\n",
    "                   # 위쪽(y=0)에서 아래쪽(y=400)으로 갈수록 초록색 진해짐\n",
    "                   # 가로와 세로 방향으로 서로 다른 그라데이션 생성\n",
    "                   \n",
    "                   50                      # Red 채널\n",
    "                   # 빨간색은 고정값 50으로 설정\n",
    "                   # 전체적으로 약간의 빨간색 톤을 유지\n",
    "                   # 결과: 복합적인 색상 그라데이션 배경\n",
    "               ]\n",
    "               # 최종 효과: 왼쪽 위는 어둡고, 오른쪽 아래로 갈수록\n",
    "               # 파란색과 초록색이 강해지는 대각선 그라데이션\n",
    "   \n",
    "   cv2.putText(test_img, 'OpenCV Test Image', (150, 350), \n",
    "              cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "   # 테스트 이미지임을 나타내는 제목 텍스트 추가\n",
    "   # (150, 350): 이미지 하단 중앙 부근에 위치\n",
    "   # 1: 적당한 크기의 폰트\n",
    "   # (255, 255, 255): 흰색으로 명확한 가독성\n",
    "   # 2: 굵은 텍스트로 잘 보이게 함\n",
    "   \n",
    "   return test_img\n",
    "   # 완성된 테스트 이미지를 반환함\n",
    "   # 다양한 순수 색상 + 혼합 색상 + 그라데이션 배경이 포함된\n",
    "   # 종합적인 색상 처리 테스트용 이미지\n",
    "\n",
    "# 고급 이미지 처리 함수 실행\n",
    "advanced_image_processing()\n",
    "# 위에서 정의한 함수를 실제로 호출해서 실행\n",
    "# 이 한 줄로 전체 고급 이미지 처리 체험이 시작됨\n",
    "\n",
    "# 💡 이 코드에서 배우는 핵심 개념들:\n",
    "# 1. 다양한 색상 공간의 특성과 활용법 (BGR, HSV, LAB, GRAY)\n",
    "# 2. 히스토그램 분석과 대비 향상 기법 (평활화, CLAHE)\n",
    "# 3. 색상 기반 객체 검출과 필터링 방법\n",
    "# 4. 감마 보정을 통한 비선형 밝기 조절\n",
    "# 5. 다양한 노이즈 제거 필터의 특성과 용도\n",
    "# 6. 실제 컴퓨터 비전 프로젝트에서 사용되는 전처리 기법들\n",
    "# 7. 이미지 품질 향상과 특징 추출을 위한 종합적 접근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c799b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3-2단계: 웹캠 실시간 효과 적용  \n",
    "# =============================================================================\n",
    "\n",
    "print(\"📹 3-2단계: 웹캠 실시간 마법\")\n",
    "# 📹 비디오 카메라 이모지로 웹캠을 사용한 실시간 처리임을 표현함\n",
    "# \"실시간 마법\"이라는 표현으로 다양한 효과들의 신기함을 강조함\n",
    "# 2단계로 표시해서 이전 단계보다 발전된 내용임을 명시함\n",
    "\n",
    "print(\"=\"*25)\n",
    "# = 문자 25개로 구분선을 만들어서 새로운 섹션의 시작을 표시함\n",
    "\n",
    "def apply_realtime_effects():\n",
    "   \"\"\"웹캠 실시간 효과 적용 함수 (개선된 버전)\"\"\"\n",
    "   # 독스트링으로 함수의 기능을 설명함\n",
    "   # \"개선된 버전\"이라고 명시해서 이전보다 더 안정적이고 기능이 많음을 표현\n",
    "   # 실시간 효과: 웹캠에서 받은 영상에 즉시 다양한 이미지 처리 효과를 적용\n",
    "   # 사용자가 키보드로 효과를 실시간으로 바꿀 수 있는 인터랙티브한 프로그램\n",
    "   \n",
    "   print(\"🔍 웹캠 연결 및 초기화 중...\")\n",
    "   # 🔍 돋보기 이모지로 웹캠을 찾고 연결하는 과정임을 표현함\n",
    "   # 사용자에게 현재 진행 상황을 명확히 알려줌\n",
    "   \n",
    "   # ★ 웹캠 연결 시도: 여러 번호를 차례로 시도해서 안정성을 높임 ★\n",
    "   cap = cv2.VideoCapture(0)\n",
    "   # cv2.VideoCapture(0)으로 첫 번째 카메라(보통 내장 웹캠) 연결 시도\n",
    "   # 0번부터 시작해서 가장 일반적인 웹캠 번호를 먼저 확인\n",
    "   \n",
    "   if not cap.isOpened():\n",
    "       # cap.isOpened()로 웹캠 연결 성공 여부 확인\n",
    "       # False면 0번 웹캠 연결 실패를 의미함\n",
    "       print(\"❌ 0번 웹캠을 열 수 없습니다! 다른 번호 시도 중...\")\n",
    "       # ❌ X 표시로 실패를 명확히 표현하고 대안을 제시함\n",
    "       \n",
    "       # 1번부터 4번까지 차례로 시도함\n",
    "       for i in range(1, 5):\n",
    "           # range(1, 5)는 1, 2, 3, 4를 순서대로 반환함\n",
    "           # 여러 카메라가 연결된 시스템에서 사용 가능한 카메라 찾기\n",
    "           cap = cv2.VideoCapture(i)\n",
    "           # i번 카메라 연결 시도 (1번, 2번, 3번, 4번 순서로)\n",
    "           if cap.isOpened():\n",
    "               # 연결에 성공하면 즉시 반복문 종료\n",
    "               print(f\"✅ {i}번 웹캠 연결 성공!\")\n",
    "               # ✅ 체크마크로 성공을 표시하고 몇 번 웹캠인지 알려줌\n",
    "               break\n",
    "               # for 루프를 즉시 종료해서 더 이상 시도하지 않음\n",
    "       else:\n",
    "           # for문이 break 없이 끝나면 실행되는 else 블록\n",
    "           # 1~4번 모든 카메라 연결 시도가 실패했다는 의미\n",
    "           print(\"❌ 사용 가능한 웹캠을 찾을 수 없습니다!\")\n",
    "           # 모든 시도가 실패했음을 사용자에게 알림\n",
    "           return\n",
    "           # 함수를 즉시 종료해서 더 이상 진행하지 않음\n",
    "   else:\n",
    "       # 0번 웹캠 연결이 성공한 경우\n",
    "       print(\"✅ 0번 웹캠 연결 성공!\")\n",
    "       # 기본 웹캠이 정상적으로 작동함을 확인\n",
    "   \n",
    "   # ★ 웹캠 초기화 대기: 하드웨어가 안정화될 시간을 줌 ★\n",
    "   print(\"⏳ 웹캠 초기화 대기 중... (3초)\")\n",
    "   # ⏳ 모래시계 이모지로 대기 시간임을 표현함\n",
    "   time.sleep(3)\n",
    "   # 3초 동안 프로그램 실행을 중단함\n",
    "   # 웹캠 하드웨어가 완전히 초기화되고 안정화될 시간을 제공\n",
    "   # 급하게 시작하면 초기 몇 프레임이 불안정할 수 있음\n",
    "   \n",
    "   # ★ 웹캠 설정 최적화: 안정적인 화질과 속도를 위한 설정 ★\n",
    "   print(\"🔧 웹캠 설정 적용 중...\")\n",
    "   # 🔧 렌치 이모지로 설정 조정 작업임을 표현함\n",
    "   \n",
    "   # 해상도 설정 (640x480은 대부분의 웹캠에서 안정적으로 지원됨)\n",
    "   cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "   # cv2.CAP_PROP_FRAME_WIDTH 상수로 프레임 너비를 640픽셀로 설정\n",
    "   # 640픽셀: VGA 표준 해상도로 호환성이 매우 좋음\n",
    "   \n",
    "   cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "   # cv2.CAP_PROP_FRAME_HEIGHT 상수로 프레임 높이를 480픽셀로 설정\n",
    "   # 480픽셀: 640x480 VGA 해상도 완성\n",
    "   \n",
    "   cap.set(cv2.CAP_PROP_FPS, 15)\n",
    "   # cv2.CAP_PROP_FPS로 초당 프레임 수를 15로 제한\n",
    "   # 15fps: 실시간 처리에는 충분하면서도 시스템 부하를 줄임\n",
    "   # 30fps보다 낮춰서 안정성을 높이고 CPU 사용량 감소\n",
    "   \n",
    "   cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "   # cv2.CAP_PROP_BUFFERSIZE로 내부 버퍼 크기를 1로 설정\n",
    "   # 버퍼 크기 1: 최신 프레임만 유지해서 지연 시간 최소화\n",
    "   # 실시간 처리에서는 지연보다 최신성이 더 중요함\n",
    "   \n",
    "   # ★ 비디오 코덱 설정: MJPG 형식으로 압축하여 전송 속도 향상 ★\n",
    "   try:\n",
    "       # try 블록으로 코덱 설정 실패에 대비함\n",
    "       cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'))\n",
    "       # FOURCC: Four Character Code (4글자 코드)로 비디오 코덱 지정\n",
    "       # MJPG: Motion JPEG 코덱\n",
    "       #   - 각 프레임을 개별적으로 JPEG 압축\n",
    "       #   - 압축률이 좋아서 데이터 전송량 감소\n",
    "       #   - 실시간 처리에 적합한 코덱\n",
    "   except:\n",
    "       # 코덱 설정에 실패해도 프로그램은 계속 진행\n",
    "       pass\n",
    "       # 일부 웹캠에서는 MJPG를 지원하지 않을 수 있음\n",
    "       # 설정 실패해도 기본 코덱으로 동작하므로 문제없음\n",
    "   \n",
    "   # ★ 실제 적용된 설정 확인: 요청한 설정이 실제로 적용됐는지 확인 ★\n",
    "   actual_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "   # cap.get()으로 실제 적용된 프레임 너비를 가져옴\n",
    "   # int()로 정수 변환 (get()은 float을 반환하므로)\n",
    "   \n",
    "   actual_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "   # 실제 적용된 프레임 높이 확인\n",
    "   \n",
    "   actual_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "   # 실제 적용된 FPS 확인\n",
    "   \n",
    "   print(f\"📐 웹캠 설정: {actual_width}x{actual_height} @ {actual_fps}FPS\")\n",
    "   # 📐 자 이모지로 측정/설정 정보임을 표현함\n",
    "   # f-string으로 실제 적용된 설정값들을 사용자에게 알려줌\n",
    "   # 요청한 설정과 다를 수 있으므로 실제 값을 확인하는 것이 중요함\n",
    "   \n",
    "   # ★ 웹캠 웜업: 여러 번 시도해서 안정적인 연결 확인 ★\n",
    "   print(\"🔄 웹캠 웜업 중...\")\n",
    "   # 🔄 새로고침 이모지로 반복 시도 과정임을 표현함\n",
    "   # 웜업: 웹캠이 안정적으로 작동할 수 있도록 미리 테스트하는 과정\n",
    "   \n",
    "   for i in range(10):\n",
    "       # 최대 10번까지 프레임 읽기 시도\n",
    "       ret, frame = cap.read()\n",
    "       # 웹캠에서 프레임 읽기 시도\n",
    "       if ret:\n",
    "           # 프레임 읽기에 성공하면\n",
    "           print(f\"✅ {i+1}번째 시도에서 프레임 읽기 성공!\")\n",
    "           # 몇 번째 시도에서 성공했는지 알려줌\n",
    "           break\n",
    "           # 성공하면 즉시 웜업 과정 종료\n",
    "       else:\n",
    "           # 프레임 읽기에 실패하면\n",
    "           print(f\"⚠️ {i+1}번째 시도 실패... 재시도 중\")\n",
    "           # ⚠️ 경고 이모지로 실패를 표시하고 재시도함을 알림\n",
    "           time.sleep(0.5)\n",
    "           # 0.5초 대기 후 재시도 (너무 빨리 시도하면 같은 오류 반복)\n",
    "   else:\n",
    "       # for문이 break 없이 끝나면 실행 (10번 모두 실패)\n",
    "       print(\"❌ 10번 시도 후에도 프레임을 읽을 수 없습니다!\")\n",
    "       print(\"💡 가능한 해결 방법:\")\n",
    "       print(\"   1. 다른 프로그램에서 웹캠 사용 중인지 확인\")\n",
    "       print(\"   2. 웹캠 드라이버 업데이트\")\n",
    "       print(\"   3. 컴퓨터 재시작 후 재시도\")\n",
    "       print(\"   4. 다른 웹캠 사용\")\n",
    "       # 💡 전구 이모지로 도움말임을 표시하고 구체적인 해결 방법 제시\n",
    "       # 사용자가 스스로 문제를 해결할 수 있도록 친절한 안내 제공\n",
    "       cap.release()\n",
    "       # 웹캠 자원을 해제해서 다른 프로그램이 사용할 수 있게 함\n",
    "       return\n",
    "       # 함수를 종료해서 더 이상 진행하지 않음\n",
    "   \n",
    "   # ★ 변수 초기화: 프로그램 실행에 필요한 변수들 설정 ★\n",
    "   current_effect = 1\n",
    "   # 현재 선택된 효과 번호를 1(원본)로 초기화\n",
    "   # 1~6까지의 숫자로 서로 다른 효과를 구분함\n",
    "   \n",
    "   frame_count = 0\n",
    "   # 처리한 프레임 개수를 세는 카운터를 0으로 초기화\n",
    "   # 성능 모니터링과 진행 상황 표시에 사용\n",
    "   \n",
    "   last_frame = None\n",
    "   # 마지막으로 성공한 프레임을 저장할 변수를 None으로 초기화\n",
    "   # 웹캠 읽기 실패 시 백업용으로 사용할 예정\n",
    "   \n",
    "   print(\"\\n🎬 실시간 효과 적용 시작!\")\n",
    "   # 🎬 영화 카메라 이모지로 본격적인 촬영 시작을 표현함\n",
    "   print(\"=\"*30)\n",
    "   print(\"📱 조작 방법:\")\n",
    "   print(\"   1~6: 효과 변경\")\n",
    "   print(\"   s: 스크린샷 저장\") \n",
    "   print(\"   q: 종료\")\n",
    "   print(\"=\"*30)\n",
    "   # 📱 스마트폰 이모지로 조작 방법임을 표시함\n",
    "   # 구분선과 함께 사용법을 명확히 안내해서 사용자 편의성 향상\n",
    "   \n",
    "   try:\n",
    "       # try 블록으로 메인 루프에서 발생할 수 있는 모든 오류에 대비\n",
    "       consecutive_failures = 0\n",
    "       # 연속으로 실패한 횟수를 세는 변수를 0으로 초기화\n",
    "       # 너무 많이 실패하면 프로그램을 안전하게 종료하기 위함\n",
    "       \n",
    "       while True:\n",
    "           # 무한 루프로 실시간 영상 처리 구현\n",
    "           # 사용자가 'q'를 누르거나 오류가 발생할 때까지 계속 실행\n",
    "           \n",
    "           # ★ 웹캠에서 한 프레임 읽기 ★\n",
    "           ret, frame = cap.read()\n",
    "           # cap.read()로 웹캠에서 현재 프레임 획득 시도\n",
    "           # ret: 읽기 성공 여부 (True/False)\n",
    "           # frame: 실제 영상 데이터 (numpy 배열)\n",
    "           \n",
    "           if not ret:\n",
    "               # 프레임 읽기에 실패한 경우의 처리\n",
    "               consecutive_failures += 1\n",
    "               # 연속 실패 횟수를 1 증가시킴\n",
    "               print(f\"⚠️ 프레임 읽기 실패 #{consecutive_failures}\")\n",
    "               # 몇 번째 실패인지 명확히 표시\n",
    "               \n",
    "               if consecutive_failures > 10:\n",
    "                   # 10번 연속 실패하면 심각한 문제로 판단\n",
    "                   print(\"❌ 10번 연속 실패로 종료합니다.\")\n",
    "                   break\n",
    "                   # while 루프를 종료해서 프로그램 안전하게 종료\n",
    "               \n",
    "               # ★ 백업 프레임 사용: 이전에 성공한 프레임이 있으면 그것을 사용 ★\n",
    "               if last_frame is not None:\n",
    "                   # 이전에 성공적으로 읽은 프레임이 있다면\n",
    "                   frame = last_frame.copy()\n",
    "                   # 백업 프레임을 복사해서 사용 (copy()로 독립적인 복사본 생성)\n",
    "                   ret = True\n",
    "                   # 성공으로 처리해서 계속 진행할 수 있게 함\n",
    "               else:\n",
    "                   # 백업 프레임도 없다면\n",
    "                   time.sleep(0.1)\n",
    "                   # 0.1초 대기해서 시스템에 여유를 줌\n",
    "                   continue\n",
    "                   # 현재 반복을 건너뛰고 다음 반복으로 이동\n",
    "           else:\n",
    "               # 프레임 읽기에 성공한 경우\n",
    "               consecutive_failures = 0\n",
    "               # 실패 카운터를 0으로 리셋 (연속 실패 기록 초기화)\n",
    "               last_frame = frame.copy()\n",
    "               # 성공한 프레임을 백업으로 저장 (나중에 실패 시 사용)\n",
    "           \n",
    "           frame_count += 1\n",
    "           # 처리한 프레임 개수를 1 증가시킴\n",
    "           # 성공적으로 처리된 프레임만 카운트\n",
    "           \n",
    "           # ★ 좌우 반전: 거울처럼 보이게 만듦 ★\n",
    "           frame = cv2.flip(frame, 1)\n",
    "           # cv2.flip(이미지, 1)로 좌우 반전 적용\n",
    "           # 1: 수평 반전 (거울 효과)\n",
    "           # 사용자가 자연스럽게 느낄 수 있도록 셀카 모드와 같은 효과\n",
    "           \n",
    "           # ★ 선택된 효과 적용: 사용자가 선택한 효과를 프레임에 적용 ★\n",
    "           try:\n",
    "               # 효과 처리 중 발생할 수 있는 오류에 대비한 내부 try 블록\n",
    "               if current_effect == 1:\n",
    "                   # 효과 1: 원본 그대로 유지\n",
    "                   processed_frame = frame.copy()\n",
    "                   # 원본을 복사해서 수정 없이 사용\n",
    "                   effect_name = \"Original\"\n",
    "                   # 현재 효과 이름을 저장 (화면 표시용)\n",
    "               \n",
    "               elif current_effect == 2:\n",
    "                   # 효과 2: 회색조 (흑백) 변환\n",
    "                   processed_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                   # BGR → GRAY 색상 공간 변환 (컬러 → 흑백)\n",
    "                   processed_frame = cv2.cvtColor(processed_frame, cv2.COLOR_GRAY2BGR)\n",
    "                   # GRAY → BGR 변환 (다시 3채널로 만들어서 텍스트 표시 가능)\n",
    "                   effect_name = \"Grayscale\"\n",
    "               \n",
    "               elif current_effect == 3:\n",
    "                   # 효과 3: 색상 반전 (네거티브 효과)\n",
    "                   processed_frame = 255 - frame\n",
    "                   # 모든 픽셀값을 255에서 빼서 색상 반전\n",
    "                   # 검은색(0) → 흰색(255), 흰색(255) → 검은색(0)\n",
    "                   effect_name = \"Negative\"\n",
    "               \n",
    "               elif current_effect == 4:\n",
    "                   # 효과 4: 블러 (흐림) 효과\n",
    "                   processed_frame = cv2.GaussianBlur(frame, (15, 15), 0)\n",
    "                   # 가우시안 블러로 이미지를 부드럽게 흐리게 만듦\n",
    "                   # (15, 15): 커널 크기 (블러 강도)\n",
    "                   # 0: 표준편차 자동 계산\n",
    "                   effect_name = \"Blur\"\n",
    "               \n",
    "               elif current_effect == 5:\n",
    "                   # 효과 5: 엣지 검출 (윤곽선 추출)\n",
    "                   gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                   # 먼저 흑백으로 변환 (엣지 검출은 흑백에서 더 정확)\n",
    "                   edges = cv2.Canny(gray, 100, 200)\n",
    "                   # Canny 엣지 검출 알고리즘 적용\n",
    "                   # 100, 200: 낮은/높은 임계값\n",
    "                   processed_frame = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
    "                   # 다시 3채널로 변환 (텍스트 표시 위해)\n",
    "                   effect_name = \"Edge Detection\"\n",
    "               \n",
    "               elif current_effect == 6:\n",
    "                   # 효과 6: HSV 색상 공간 변환\n",
    "                   processed_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "                   # BGR → HSV 색상 공간 변환\n",
    "                   # 독특한 색감의 예술적 효과 생성\n",
    "                   effect_name = \"HSV Color Space\"\n",
    "               \n",
    "               else:\n",
    "                   # 예상치 못한 효과 번호인 경우 안전장치\n",
    "                   processed_frame = frame.copy()\n",
    "                   # 원본으로 대체해서 오류 방지\n",
    "                   effect_name = \"Original\"\n",
    "               \n",
    "           except Exception as e:\n",
    "               # 효과 처리 중 오류 발생 시의 처리\n",
    "               print(f\"⚠️ 효과 처리 오류: {e}\")\n",
    "               # 구체적인 오류 내용을 출력해서 디버깅에 도움\n",
    "               processed_frame = frame.copy()\n",
    "               # 원본으로 대체해서 프로그램이 중단되지 않게 함\n",
    "               effect_name = \"Error - Using Original\"\n",
    "               # 오류 상황임을 명시하는 이름 설정\n",
    "           \n",
    "           # ★ UI 요소 그리기: 화면에 정보를 표시하기 위한 박스와 텍스트 ★\n",
    "           \n",
    "           # 정보 표시용 검은색 배경 박스 그리기\n",
    "           cv2.rectangle(processed_frame,\n",
    "                        (5, 5),        # 시작점 좌표 (왼쪽 위)\n",
    "                        (500, 100),    # 끝점 좌표 (오른쪽 아래)\n",
    "                        (0, 0, 0),     # 색상 (검은색)\n",
    "                        -1)            # 두께 (-1은 내부를 채움)\n",
    "           # 텍스트의 가독성을 높이기 위한 어두운 배경 생성\n",
    "           \n",
    "           # 정보 박스 테두리 (초록색)\n",
    "           cv2.rectangle(processed_frame, (5, 5), (500, 100), (0, 255, 0), 2)\n",
    "           # 같은 위치에 초록색 테두리 추가\n",
    "           # 2픽셀 두께로 박스를 명확히 구분\n",
    "           \n",
    "           # ★ 텍스트 정보 표시: 현재 상태를 사용자에게 알려줌 ★\n",
    "           \n",
    "           # 현재 적용중인 효과 이름 표시\n",
    "           cv2.putText(processed_frame, \n",
    "                      f'Effect: {effect_name}',\n",
    "                      # f-string으로 현재 효과 이름 삽입\n",
    "                      (10, 30),\n",
    "                      # 텍스트 위치 (박스 안쪽 적절한 위치)\n",
    "                      cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                      # 읽기 쉬운 기본 폰트\n",
    "                      0.7,\n",
    "                      # 적당한 크기의 폰트\n",
    "                      (0, 255, 0),\n",
    "                      # 초록색 (박스 테두리와 일치)\n",
    "                      2)\n",
    "                      # 굵은 텍스트로 명확하게 표시\n",
    "           \n",
    "           # 프레임 번호와 실패 횟수 표시\n",
    "           cv2.putText(processed_frame, \n",
    "                      f'Frame: {frame_count} | Failures: {consecutive_failures}',\n",
    "                      # 처리된 프레임 수와 연속 실패 횟수를 함께 표시\n",
    "                      (10, 55),\n",
    "                      # 첫 번째 텍스트 아래 위치\n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                      0.5,\n",
    "                      # 더 작은 폰트 크기 (부가 정보이므로)\n",
    "                      (255, 255, 255),\n",
    "                      # 흰색으로 잘 보이게 표시\n",
    "                      1)\n",
    "                      # 얇은 텍스트 두께\n",
    "           \n",
    "           # 조작 방법 안내\n",
    "           cv2.putText(processed_frame, \n",
    "                      'Keys: 1-6(effects) s(save) q(quit)',\n",
    "                      # 키보드 조작 방법을 간단히 요약\n",
    "                      (10, 80),\n",
    "                      # 세 번째 줄 위치\n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                      0.5,\n",
    "                      # 작은 폰트 크기\n",
    "                      (255, 255, 255),\n",
    "                      # 흰색\n",
    "                      1)\n",
    "                      # 얇은 두께\n",
    "           \n",
    "           # ★ 화면에 최종 결과 표시 ★\n",
    "           cv2.imshow('OpenCV Real-time Effects', processed_frame)\n",
    "           # cv2.imshow()로 처리된 프레임을 화면에 출력\n",
    "           # 창 제목에 프로그램 이름을 명시해서 식별 가능\n",
    "           \n",
    "           # ★ 키보드 입력 처리: 사용자의 명령을 받아서 처리 ★\n",
    "           key = cv2.waitKey(30) & 0xFF\n",
    "           # cv2.waitKey(30): 30밀리초 동안 키 입력 대기\n",
    "           # 30ms는 약 33fps에 해당하는 적절한 반응 속도\n",
    "           # & 0xFF: 키 값을 8비트로 제한하는 비트 연산\n",
    "           \n",
    "           if key == ord('q'):\n",
    "               # ord('q')로 'q' 키의 ASCII 코드와 비교\n",
    "               print(\"👋 사용자가 종료를 선택했습니다.\")\n",
    "               # 👋 손흔들기 이모지로 작별 인사\n",
    "               break\n",
    "               # while 루프 종료로 프로그램 끝내기\n",
    "               \n",
    "           elif key == ord('1'):\n",
    "               # '1' 키: 원본 효과로 변경\n",
    "               current_effect = 1\n",
    "               print(f\"🎭 효과 변경: Original\")\n",
    "               # 🎭 마스크 이모지로 효과 변경을 표현\n",
    "               \n",
    "           elif key == ord('2'):\n",
    "               # '2' 키: 회색조 효과로 변경\n",
    "               current_effect = 2\n",
    "               print(f\"🎭 효과 변경: Grayscale\")\n",
    "               \n",
    "           elif key == ord('3'):\n",
    "               # '3' 키: 네거티브 효과로 변경\n",
    "               current_effect = 3\n",
    "               print(f\"🎭 효과 변경: Negative\")\n",
    "               \n",
    "           elif key == ord('4'):\n",
    "               # '4' 키: 블러 효과로 변경\n",
    "               current_effect = 4\n",
    "               print(f\"🎭 효과 변경: Blur\")\n",
    "               \n",
    "           elif key == ord('5'):\n",
    "               # '5' 키: 엣지 검출 효과로 변경\n",
    "               current_effect = 5\n",
    "               print(f\"🎭 효과 변경: Edge Detection\")\n",
    "               \n",
    "           elif key == ord('6'):\n",
    "               # '6' 키: HSV 색상 공간 효과로 변경\n",
    "               current_effect = 6\n",
    "               print(f\"🎭 효과 변경: HSV Color Space\")\n",
    "               \n",
    "           elif key == ord('s'):\n",
    "               # 's' 키: 스크린샷 저장 기능\n",
    "               filename = f'opencv_effect_{effect_name}_{int(time.time())}.jpg'\n",
    "               # 파일명 생성: 효과이름 + 타임스탬프로 중복 방지\n",
    "               # effect_name: 현재 적용된 효과 이름\n",
    "               # int(time.time()): 현재 시간을 정수로 변환한 고유값\n",
    "               \n",
    "               cv2.imwrite(filename, processed_frame)\n",
    "               # cv2.imwrite()로 처리된 프레임을 파일로 저장\n",
    "               print(f\"📸 저장 완료: {filename}\")\n",
    "               # 📸 카메라 이모지로 저장 완료 알림\n",
    "           \n",
    "           # ★ 진행 상황 표시: 50프레임마다 처리 현황을 알려줌 ★\n",
    "           if frame_count % 50 == 0:\n",
    "               # % 연산자로 50으로 나눈 나머지가 0인지 확인\n",
    "               # 50, 100, 150, 200... 프레임마다 실행됨\n",
    "               # 너무 자주 출력하면 콘솔이 복잡해지므로 적당한 간격 유지\n",
    "               print(f\"📊 처리된 프레임: {frame_count}\")\n",
    "               # 📊 차트 이모지로 통계 정보임을 표시\n",
    "               # 사용자에게 프로그램이 정상적으로 작동하고 있음을 알려줌\n",
    "               # 성능 모니터링과 진행 상황 파악에 도움\n",
    "   \n",
    "   except KeyboardInterrupt:\n",
    "       # KeyboardInterrupt: 사용자가 Ctrl+C를 눌러서 강제 종료한 경우\n",
    "       print(\"\\n⚠️ 키보드 인터럽트로 종료됩니다.\")\n",
    "       # \\n으로 줄바꿈해서 깔끔하게 메시지 출력\n",
    "       # ⚠️ 경고 이모지로 비정상 종료가 아닌 의도적 중단임을 표시\n",
    "   \n",
    "   except Exception as e:\n",
    "       # Exception: 예상치 못한 모든 종류의 오류를 포괄적으로 처리\n",
    "       print(f\"❌ 예상치 못한 오류 발생: {e}\")\n",
    "       # ❌ X 표시로 오류임을 명확히 표시\n",
    "       # f-string으로 구체적인 오류 내용을 출력해서 디버깅에 도움\n",
    "       # 오류가 발생해도 프로그램이 비정상 종료되지 않고 깔끔하게 정리됨\n",
    "   \n",
    "   finally:\n",
    "       # finally 블록: try 블록이 어떤 방식으로 끝나든 반드시 실행되는 부분\n",
    "       # 정상 종료, 오류 발생, 강제 중단 등 모든 경우에 리소스 정리 보장\n",
    "       cap.release()\n",
    "       # 웹캠 자원을 해제해서 시스템에 반환\n",
    "       # 다른 프로그램에서도 웹캠을 사용할 수 있게 함\n",
    "       # 메모리 누수 방지와 하드웨어 자원 관리를 위해 필수\n",
    "       \n",
    "       cv2.destroyAllWindows()\n",
    "       # 열린 모든 OpenCV 창을 닫고 메모리에서 제거\n",
    "       # GUI 자원 해제로 시스템 안정성 확보\n",
    "       # 창이 남아있으면 시스템 자원을 계속 사용하므로 정리 필요\n",
    "       \n",
    "       print(f\"✅ 실시간 효과 체험 완료! (총 {frame_count} 프레임 처리)\")\n",
    "       # ✅ 체크마크로 성공적인 완료 표시\n",
    "       # f-string으로 총 처리한 프레임 수를 최종 통계로 제공\n",
    "       # 사용자에게 프로그램이 얼마나 많은 데이터를 처리했는지 알려줌\n",
    "\n",
    "# ★ 메인 실행부: 웹캠 실시간 효과 함수를 호출함 ★\n",
    "print(\"🚀 웹캠 실시간 효과 체험을 시작합니다...\")\n",
    "# 🚀 로켓 이모지로 프로그램 시작의 역동성을 표현함\n",
    "# 사용자에게 곧 시작될 체험에 대한 기대감을 조성함\n",
    "\n",
    "apply_realtime_effects()\n",
    "# 위에서 정의한 함수를 실제로 호출해서 실행\n",
    "# 이 한 줄로 전체 실시간 효과 시스템이 작동 시작\n",
    "# 함수 호출을 통해 웹캠 연결부터 효과 적용까지 모든 과정이 진행됨\n",
    "\n",
    "# 💡 이 코드에서 배우는 핵심 개념들:\n",
    "# 1. 실시간 영상 처리의 기본 구조와 안정성 확보 방법\n",
    "# 2. 웹캠 하드웨어의 초기화와 최적화 설정 기법\n",
    "# 3. 다양한 이미지 처리 효과의 실시간 적용 방법\n",
    "# 4. 사용자 인터랙션 처리 (키보드 입력과 실시간 반응)\n",
    "# 5. 오류 처리와 복구 전략 (백업 프레임, 재시도 로직)\n",
    "# 6. 리소스 관리와 안전한 프로그램 종료 방법\n",
    "# 7. 실무에서 사용되는 견고한 실시간 시스템 설계 원칙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29f4319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3-3단계: 웹캠 실시간 효과 적용  \n",
    "# =============================================================================\n",
    "\n",
    "print(\"📹 3-3단계: 웹캠 실시간 마법\")\n",
    "print(\"=\"*25)\n",
    "\n",
    "def apply_realtime_effects():\n",
    "    \"\"\"웹캠 실시간 효과 적용 함수 (개선된 버전)\"\"\"\n",
    "    \n",
    "    print(\"🔍 웹캠 연결 및 초기화 중...\")\n",
    "    \n",
    "    # ★ 웹캠 연결 시도: 여러 번호를 차례로 시도해서 안정성을 높임 ★\n",
    "    cap = cv2.VideoCapture(0)  # 0번 카메라(기본 웹캠) 연결 시도\n",
    "    \n",
    "    if not cap.isOpened():  # 0번 카메라가 안 열리면\n",
    "        print(\"❌ 0번 웹캠을 열 수 없습니다! 다른 번호 시도 중...\")\n",
    "        \n",
    "        # 1번부터 4번까지 차례로 시도함\n",
    "        for i in range(1, 5):\n",
    "            cap = cv2.VideoCapture(i)  # i번 카메라 연결 시도\n",
    "            if cap.isOpened():  # 연결에 성공하면\n",
    "                print(f\"✅ {i}번 웹캠 연결 성공!\")\n",
    "                break  # 반복문 종료\n",
    "        else:  # for문이 break 없이 끝나면 (모든 카메라 연결 실패)\n",
    "            print(\"❌ 사용 가능한 웹캠을 찾을 수 없습니다!\")\n",
    "            return  # 함수 종료\n",
    "    else:\n",
    "        print(\"✅ 0번 웹캠 연결 성공!\")\n",
    "    \n",
    "    # ★ 웹캠 초기화 대기: 하드웨어가 안정화될 시간을 줌 ★\n",
    "    print(\"⏳ 웹캠 초기화 대기 중... (3초)\")\n",
    "    time.sleep(3)  # 3초 동안 대기 (웹캠이 완전히 초기화될 때까지)\n",
    "    \n",
    "    # ★ 웹캠 설정 최적화: 안정적인 화질과 속도를 위한 설정 ★\n",
    "    print(\"🔧 웹캠 설정 적용 중...\")\n",
    "    \n",
    "    # 해상도 설정 (640x480은 대부분의 웹캠에서 안정적으로 지원됨)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)   # 가로 640픽셀\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)  # 세로 480픽셀\n",
    "    cap.set(cv2.CAP_PROP_FPS, 15)            # 초당 15프레임 (낮춰서 안정성 높임)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)      # 버퍼 크기를 1로 설정 (지연 최소화)\n",
    "    \n",
    "    # ★ 비디오 코덱 설정: MJPG 형식으로 압축하여 전송 속도 향상 ★\n",
    "    try:\n",
    "        # MJPG 코덱 설정 (Motion JPEG - 압축률이 좋음)\n",
    "        cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'))\n",
    "    except:\n",
    "        pass  # 설정에 실패해도 계속 진행\n",
    "    \n",
    "    # ★ 실제 적용된 설정 확인: 요청한 설정이 실제로 적용됐는지 확인 ★\n",
    "    actual_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))   # 실제 가로 해상도\n",
    "    actual_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # 실제 세로 해상도\n",
    "    actual_fps = int(cap.get(cv2.CAP_PROP_FPS))             # 실제 프레임레이트\n",
    "    print(f\"📐 웹캠 설정: {actual_width}x{actual_height} @ {actual_fps}FPS\")\n",
    "    \n",
    "    # ★ 웹캠 웜업: 여러 번 시도해서 안정적인 연결 확인 ★\n",
    "    print(\"🔄 웹캠 웜업 중...\")\n",
    "    for i in range(10):  # 최대 10번 시도\n",
    "        ret, frame = cap.read()  # 프레임 읽기 시도\n",
    "        if ret:  # 성공하면\n",
    "            print(f\"✅ {i+1}번째 시도에서 프레임 읽기 성공!\")\n",
    "            break  # 반복문 종료\n",
    "        else:  # 실패하면\n",
    "            print(f\"⚠️ {i+1}번째 시도 실패... 재시도 중\")\n",
    "            time.sleep(0.5)  # 0.5초 대기 후 재시도\n",
    "    else:  # 10번 모두 실패하면\n",
    "        print(\"❌ 10번 시도 후에도 프레임을 읽을 수 없습니다!\")\n",
    "        print(\"💡 가능한 해결 방법:\")\n",
    "        print(\"   1. 다른 프로그램에서 웹캠 사용 중인지 확인\")\n",
    "        print(\"   2. 웹캠 드라이버 업데이트\")\n",
    "        print(\"   3. 컴퓨터 재시작 후 재시도\")\n",
    "        print(\"   4. 다른 웹캠 사용\")\n",
    "        cap.release()  # 웹캠 자원 해제\n",
    "        return  # 함수 종료\n",
    "    \n",
    "    # ★ 변수 초기화: 프로그램 실행에 필요한 변수들 설정 ★\n",
    "    current_effect = 1        # 현재 선택된 효과 번호 (1=원본)\n",
    "    frame_count = 0          # 처리한 프레임 개수\n",
    "    last_frame = None        # 마지막으로 성공한 프레임을 저장 (오류 대비용)\n",
    "    \n",
    "    print(\"\\n🎬 실시간 효과 적용 시작!\")\n",
    "    print(\"=\"*30)\n",
    "    print(\"📱 조작 방법:\")\n",
    "    print(\"   1~6: 효과 변경\")\n",
    "    print(\"   s: 스크린샷 저장\") \n",
    "    print(\"   q: 종료\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    try:  # 오류 발생 시 안전하게 종료하기 위한 try문\n",
    "        consecutive_failures = 0  # 연속으로 실패한 횟수를 세는 변수\n",
    "        \n",
    "        while True:  # 무한 반복문으로 실시간 처리\n",
    "            \n",
    "            # ★ 웹캠에서 한 프레임 읽기 ★\n",
    "            ret, frame = cap.read()\n",
    "            # ret: 읽기 성공 여부 (True/False)\n",
    "            # frame: 실제 영상 데이터\n",
    "            \n",
    "            if not ret:  # 프레임 읽기에 실패했다면\n",
    "                consecutive_failures += 1  # 실패 횟수 증가\n",
    "                print(f\"⚠️ 프레임 읽기 실패 #{consecutive_failures}\")\n",
    "                \n",
    "                if consecutive_failures > 10:  # 10번 연속 실패하면\n",
    "                    print(\"❌ 10번 연속 실패로 종료합니다.\")\n",
    "                    break  # 전체 반복문 종료\n",
    "                \n",
    "                # ★ 백업 프레임 사용: 이전에 성공한 프레임이 있으면 그것을 사용 ★\n",
    "                if last_frame is not None:\n",
    "                    frame = last_frame.copy()  # 마지막 성공 프레임 복사\n",
    "                    ret = True  # 성공으로 처리\n",
    "                else:\n",
    "                    time.sleep(0.1)  # 0.1초 대기\n",
    "                    continue  # 다음 반복으로 건너뜀\n",
    "            else:\n",
    "                consecutive_failures = 0      # 성공하면 실패 카운터 리셋\n",
    "                last_frame = frame.copy()     # 성공한 프레임을 백업으로 저장\n",
    "            \n",
    "            frame_count += 1  # 처리한 프레임 개수 증가\n",
    "            \n",
    "            # ★ 좌우 반전: 거울처럼 보이게 만듦 ★\n",
    "            frame = cv2.flip(frame, 1)  # 1은 좌우 반전을 의미\n",
    "            \n",
    "            # ★ 선택된 효과 적용: 사용자가 선택한 효과를 프레임에 적용 ★\n",
    "            try:\n",
    "                if current_effect == 1:  # 효과 1: 원본 그대로\n",
    "                    processed_frame = frame.copy()  # 원본 복사\n",
    "                    effect_name = \"Original\"\n",
    "                \n",
    "                elif current_effect == 2:  # 효과 2: 회색조 변환\n",
    "                    # 컬러 → 흑백 → 다시 컬러(3채널)로 변환\n",
    "                    processed_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                    processed_frame = cv2.cvtColor(processed_frame, cv2.COLOR_GRAY2BGR)\n",
    "                    effect_name = \"Grayscale\"\n",
    "                \n",
    "                elif current_effect == 3:  # 효과 3: 색상 반전 (네거티브)\n",
    "                    processed_frame = 255 - frame  # 모든 픽셀값을 255에서 뺌\n",
    "                    effect_name = \"Negative\"\n",
    "                \n",
    "                elif current_effect == 4:  # 효과 4: 블러 효과\n",
    "                    # 가우시안 블러로 이미지를 부드럽게 흐리게 만듦\n",
    "                    processed_frame = cv2.GaussianBlur(frame, (15, 15), 0)\n",
    "                    effect_name = \"Blur\"\n",
    "                \n",
    "                elif current_effect == 5:  # 효과 5: 엣지 검출\n",
    "                    # 물체의 경계선만 추출해서 스케치처럼 만듦\n",
    "                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # 흑백 변환\n",
    "                    edges = cv2.Canny(gray, 100, 200)              # 엣지 검출\n",
    "                    processed_frame = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)  # 다시 컬러로\n",
    "                    effect_name = \"Edge Detection\"\n",
    "                \n",
    "                elif current_effect == 6:  # 효과 6: HSV 색상 공간\n",
    "                    # BGR(파랑-초록-빨강) → HSV(색조-채도-명도)로 변환\n",
    "                    processed_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "                    effect_name = \"HSV Color Space\"\n",
    "                \n",
    "                else:  # 예상치 못한 번호면 원본 사용\n",
    "                    processed_frame = frame.copy()\n",
    "                    effect_name = \"Original\"\n",
    "                \n",
    "            except Exception as e:  # 효과 처리 중 오류 발생 시\n",
    "                print(f\"⚠️ 효과 처리 오류: {e}\")\n",
    "                processed_frame = frame.copy()  # 원본으로 대체\n",
    "                effect_name = \"Error - Using Original\"\n",
    "            \n",
    "            # ★ UI 요소 그리기: 화면에 정보를 표시하기 위한 박스와 텍스트 ★\n",
    "            \n",
    "            # 정보 표시용 검은색 배경 박스 그리기\n",
    "            cv2.rectangle(processed_frame,  # 그릴 이미지\n",
    "                         (5, 5),           # 시작점 (x=5, y=5)\n",
    "                         (500, 100),       # 끝점 (x=500, y=100)\n",
    "                         (0, 0, 0),        # 색상 (검은색)\n",
    "                         -1)               # 두께 (-1은 내부 채우기)\n",
    "            \n",
    "            # 정보 박스 테두리 (초록색)\n",
    "            cv2.rectangle(processed_frame, (5, 5), (500, 100), (0, 255, 0), 2)\n",
    "            \n",
    "            # ★ 텍스트 정보 표시: 현재 상태를 사용자에게 알려줌 ★\n",
    "            \n",
    "            # 현재 적용중인 효과 이름 표시\n",
    "            cv2.putText(processed_frame, \n",
    "                       f'Effect: {effect_name}',      # 표시할 텍스트\n",
    "                       (10, 30),                     # 위치\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX,     # 폰트\n",
    "                       0.7,                          # 크기\n",
    "                       (0, 255, 0),                  # 색상 (초록)\n",
    "                       2)                            # 두께\n",
    "            \n",
    "            # 프레임 번호와 실패 횟수 표시\n",
    "            cv2.putText(processed_frame, \n",
    "                       f'Frame: {frame_count} | Failures: {consecutive_failures}', \n",
    "                       (10, 55), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       0.5,                          # 작은 크기\n",
    "                       (255, 255, 255),              # 흰색\n",
    "                       1)\n",
    "            \n",
    "            # 조작 방법 안내\n",
    "            cv2.putText(processed_frame, \n",
    "                       'Keys: 1-6(effects) s(save) q(quit)', \n",
    "                       (10, 80), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       0.5, \n",
    "                       (255, 255, 255), \n",
    "                       1)\n",
    "            \n",
    "            # ★ 화면에 최종 결과 표시 ★\n",
    "            cv2.imshow('OpenCV Real-time Effects', processed_frame)\n",
    "            \n",
    "            # ★ 키보드 입력 처리: 사용자의 명령을 받아서 처리 ★\n",
    "            key = cv2.waitKey(30) & 0xFF  # 30ms 대기하며 키 입력 확인\n",
    "            # & 0xFF는 키 값을 8비트로 제한하는 비트 연산\n",
    "            \n",
    "            if key == ord('q'):      # 'q' 키: 종료\n",
    "                print(\"👋 사용자가 종료를 선택했습니다.\")\n",
    "                break\n",
    "            elif key == ord('1'):    # '1' 키: 원본 효과\n",
    "                current_effect = 1\n",
    "                print(f\"🎭 효과 변경: Original\")\n",
    "            elif key == ord('2'):    # '2' 키: 회색조 효과\n",
    "                current_effect = 2\n",
    "                print(f\"🎭 효과 변경: Grayscale\")\n",
    "            elif key == ord('3'):    # '3' 키: 네거티브 효과\n",
    "                current_effect = 3\n",
    "                print(f\"🎭 효과 변경: Negative\")\n",
    "            elif key == ord('4'):    # '4' 키: 블러 효과\n",
    "                current_effect = 4\n",
    "                print(f\"🎭 효과 변경: Blur\")\n",
    "            elif key == ord('5'):    # '5' 키: 엣지 검출 효과\n",
    "                current_effect = 5\n",
    "                print(f\"🎭 효과 변경: Edge Detection\")\n",
    "            elif key == ord('6'):    # '6' 키: HSV 색상 공간 효과\n",
    "                current_effect = 6\n",
    "                print(f\"🎭 효과 변경: HSV Color Space\")\n",
    "            elif key == ord('s'):    # 's' 키: 스크린샷 저장\n",
    "                # 현재 시간을 포함한 고유 파일명 생성\n",
    "                filename = f'opencv_effect_{effect_name}_{int(time.time())}.jpg'\n",
    "                cv2.imwrite(filename, processed_frame)  # 파일로 저장\n",
    "                print(f\"📸 저장 완료: {filename}\")\n",
    "            \n",
    "            # ★ 진행 상황 표시: 50프레임마다 처리 현황을 알려줌 ★\n",
    "            if frame_count % 50 == 0:\n",
    "                print(f\"📊 처리된 프레임: {frame_count}\")\n",
    "    \n",
    "    except KeyboardInterrupt:  # Ctrl+C로 강제 종료 시\n",
    "        print(\"\\n⚠️ 키보드 인터럽트로 종료됩니다.\")\n",
    "    \n",
    "    except Exception as e:     # 예상치 못한 오류 발생 시\n",
    "        print(f\"❌ 예상치 못한 오류 발생: {e}\")\n",
    "    \n",
    "    finally:  # 어떤 상황에서든 반드시 실행되는 정리 코드\n",
    "        cap.release()              # 웹캠 자원 해제 (다른 프로그램이 사용할 수 있게)\n",
    "        cv2.destroyAllWindows()    # 모든 OpenCV 창 닫기\n",
    "        print(f\"✅ 실시간 효과 체험 완료! (총 {frame_count} 프레임 처리)\")\n",
    "\n",
    "# ★ 메인 실행부: 웹캠 실시간 효과 함수를 호출함 ★\n",
    "print(\"🚀 웹캠 실시간 효과 체험을 시작합니다...\")\n",
    "apply_realtime_effects()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909ca577",
   "metadata": {},
   "source": [
    "## 👤 4단계: 얼굴 인식 마법사 되기\n",
    "\n",
    "### 🎯 목표\n",
    "OpenCV의 내장 얼굴 인식 기능을 사용하여 실시간으로 얼굴을 찾고 \n",
    "재미있는 효과를 적용해보겠습니다!\n",
    "\n",
    "### 🧠 얼굴 인식 원리\n",
    "- **Haar Cascade**: 기계학습 기반 객체 검출 방법\n",
    "- **특징점 검출**: 눈, 코, 입 등의 특징적인 패턴 인식\n",
    "- **다단계 검출**: 여러 단계를 거쳐 정확도 향상\n",
    "- **실시간 처리**: 웹캠 영상에서 즉시 얼굴 감지\n",
    "\n",
    "### 🎭 구현할 기능\n",
    "- 실시간 얼굴 검출\n",
    "- 얼굴 주변에 사각형 그리기\n",
    "- 검출된 얼굴 개수 표시\n",
    "- 얼굴 영역에만 특별 효과 적용\n",
    "- 얼굴 크기와 위치 정보 표시\n",
    "\n",
    "### 💡 실제 활용 사례\n",
    "- 스마트폰 잠금 해제\n",
    "- 사진 자동 태그 기능\n",
    "- 화상 회의 배경 블러\n",
    "- 보안 시스템 출입 제어\n",
    "- AR 필터 앱의 기반 기술\n",
    "\n",
    "### ⚠️ 참고사항\n",
    "얼굴 인식은 조명과 각도에 영향을 받을 수 있습니다. \n",
    "정면을 바라보고 충분한 조명에서 테스트해보세요!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4단계: 실시간 얼굴 인식  \n",
    "# =============================================================================\n",
    "\n",
    "# ★ 필수 라이브러리 임포트: 컴퓨터 비전과 시간 처리를 위한 모듈들 ★\n",
    "import cv2   # OpenCV 라이브러리: 컴퓨터 비전의 핵심 도구\n",
    "# cv2는 Open Source Computer Vision Library의 파이썬 바인딩\n",
    "# 이미지 처리, 영상 처리, 머신러닝 기반 객체 검출 등을 제공함\n",
    "# Haar Cascade, HOG, DNN 등 다양한 검출 알고리즘이 내장되어 있음\n",
    "\n",
    "import time  # 시간 관련 함수들을 제공하는 표준 라이브러리\n",
    "# time.time(): 현재 시간을 초 단위로 반환 (고유한 파일명 생성에 사용)\n",
    "# 파일 저장 시 중복 방지를 위해 타임스탬프를 파일명에 포함\n",
    "\n",
    "# ★ 프로그램 시작 메시지 출력: 사용자에게 현재 단계 안내 ★\n",
    "print(\"👤 4단계: 얼굴 인식 마법사\")  # 이모지와 함께 친근한 메시지 출력\n",
    "print(\"=\"*23)  # 구분선 출력 (= 문자를 23개 반복)\n",
    "# \"*23\"은 문자열 반복 연산자: \"=\"를 23번 반복해서 시각적 구분선 생성\n",
    "\n",
    "def face_detection_demo():\n",
    "    \"\"\"실시간 얼굴 인식 데모\"\"\"\n",
    "    # 독스트링(docstring): 함수의 목적과 기능을 설명하는 문서화 문자열\n",
    "    # 함수 정의 바로 아래에 삼중 따옴표로 작성하는 파이썬 관례\n",
    "    # help() 함수나 IDE에서 함수 정보를 볼 때 이 내용이 표시됨\n",
    "    \n",
    "    # ★★★ Haar Cascade 분류기 로드: 미리 훈련된 얼굴 검출 모델을 가져옴 ★★★\n",
    "    try:  # 예외 처리 시작: 파일 로드 실패에 대비한 안전장치\n",
    "        # try-except 구문: 오류가 발생할 수 있는 코드를 안전하게 실행\n",
    "        # 파일이 없거나 손상된 경우를 대비해서 사용함\n",
    "        \n",
    "        # ★ 얼굴 검출용 분류기 로드 (OpenCV에 기본 포함된 모델) ★\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        # cv2.CascadeClassifier: Haar Cascade 분류기를 로드하는 클래스\n",
    "        # cv2.data.haarcascades: OpenCV에서 제공하는 기본 모델 파일 경로\n",
    "        # 'haarcascade_frontalface_default.xml': 정면 얼굴 검출용 모델 파일\n",
    "        # 이 모델은 수천 개의 얼굴/비얼굴 이미지로 훈련된 머신러닝 모델임\n",
    "        \n",
    "        # ★ 눈 검출용 분류기 로드 ★\n",
    "        eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "        # 'haarcascade_eye.xml': 눈 검출 전용 모델 파일\n",
    "        # 얼굴 검출 후 얼굴 내에서 눈을 찾기 위해 사용함\n",
    "        # 얼굴보다 훨씬 작고 세밀한 특징을 검출해야 하므로 별도 모델 필요\n",
    "        \n",
    "        # ★ 대안 눈 검출 모델도 시도 (안경 착용자용) ★\n",
    "        try:  # 중첩된 try-except: 대안 모델 로드 시도\n",
    "            # 안경이나 선글라스를 착용한 사람의 눈도 검출할 수 있는 향상된 모델\n",
    "            eye_cascade_alt = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye_tree_eyeglasses.xml')\n",
    "            # 'haarcascade_eye_tree_eyeglasses.xml': 안경 착용자 눈 검출용 모델\n",
    "            # tree 방식: 더 복잡한 결정 트리를 사용해서 정확도가 높음\n",
    "            # eyeglasses: 안경이 있어도 눈을 검출할 수 있도록 특별히 훈련됨\n",
    "            \n",
    "            print(\"✅ 안경 착용자용 눈 검출 모델도 로드됨!\")  # 성공 메시지 출력\n",
    "            # 이모지 ✅: 성공을 시각적으로 표현해서 사용자가 쉽게 인식할 수 있음\n",
    "        except:  # 대안 모델 로드 실패 시\n",
    "            eye_cascade_alt = None  # None으로 설정해서 나중에 사용 여부 판단\n",
    "            # None: 파이썬에서 \"값이 없음\"을 나타내는 특별한 객체\n",
    "            # 대안 모델이 없어도 기본 모델로 계속 진행할 수 있도록 함\n",
    "        \n",
    "        print(\"✅ 얼굴 검출 모델 로드 성공!\")  # 전체적인 성공 메시지\n",
    "        # 기본 모델들이 성공적으로 로드되었음을 사용자에게 알림\n",
    "        \n",
    "    except:  # 기본 모델 로드 실패 시 (심각한 오류)\n",
    "        print(\"❌ 얼굴 검출 모델을 찾을 수 없습니다!\")  # 오류 메시지 출력\n",
    "        # 이모지 ❌: 실패를 시각적으로 표현\n",
    "        # OpenCV 설치가 잘못되었거나 파일이 손상된 경우 발생할 수 있음\n",
    "        return  # 함수를 즉시 종료함\n",
    "        # return: 함수 실행을 중단하고 호출한 곳으로 돌아감\n",
    "        # 모델이 없으면 얼굴 검출이 불가능하므로 프로그램을 계속할 수 없음\n",
    "    \n",
    "# ★★★ 웹캠 연결 및 초기 설정: 카메라 장치와 통신 설정 ★★★\n",
    "    cap = cv2.VideoCapture(0)  # 0번 카메라(기본 웹캠) 연결 시도\n",
    "    # cv2.VideoCapture: OpenCV의 비디오 캡처 클래스\n",
    "    # 웹캠, 비디오 파일, IP 카메라 등 다양한 영상 소스에서 프레임을 읽어올 수 있음\n",
    "    # 매개변수 0: 시스템의 기본 카메라 장치 번호\n",
    "    # - 0: 첫 번째 카메라 (보통 내장 웹캠)\n",
    "    # - 1: 두 번째 카메라 (외장 USB 카메라 등)\n",
    "    # - 2, 3, ...: 추가 카메라 장치들\n",
    "    \n",
    "    # ★ 웹캠 연결 상태 확인: 하드웨어 접근 가능 여부 검증 ★\n",
    "    if not cap.isOpened():  # 카메라 연결 실패 시\n",
    "        # isOpened(): 카메라가 성공적으로 열렸는지 확인하는 메서드\n",
    "        # True: 카메라 사용 가능, False: 카메라 사용 불가\n",
    "        # 실패 원인: 카메라가 없음, 다른 프로그램에서 사용 중, 권한 없음, 드라이버 문제\n",
    "        print(\"❌ 웹캠을 열 수 없습니다!\")  # 사용자에게 명확한 오류 메시지 제공\n",
    "        return  # 함수 즉시 종료 (카메라 없이는 얼굴 인식 불가능)\n",
    "        # 조기 반환(early return): 필수 조건이 만족되지 않으면 더 이상 진행하지 않음\n",
    "    \n",
    "    # ★ 웹캠 해상도 설정: 영상 품질과 처리 속도의 균형점 찾기 ★\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 800)   # 가로 800픽셀로 설정\n",
    "    # cv2.CAP_PROP_FRAME_WIDTH: 프레임 너비를 설정하는 상수\n",
    "    # 800픽셀: 적당한 해상도 (너무 높으면 처리 속도 저하, 너무 낮으면 검출 정확도 감소)\n",
    "    # set() 메서드: 카메라 속성을 변경하는 함수\n",
    "    # 실제 설정 여부는 카메라 하드웨어에 따라 달라질 수 있음\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 600)  # 세로 600픽셀로 설정\n",
    "    # cv2.CAP_PROP_FRAME_HEIGHT: 프레임 높이를 설정하는 상수\n",
    "    # 600픽셀: 800x600 해상도로 4:3 비율 유지\n",
    "    # 16:9 비율보다 4:3이 얼굴 검출에 더 적합함 (얼굴이 세로로 긴 형태)\n",
    "    \n",
    "    # ★★ 통계 변수 초기화: 프로그램 성능과 결과를 추적하기 위한 카운터들 ★★\n",
    "    face_count_total = 0  # 총 검출된 얼굴 수 (누적값)\n",
    "    # 프로그램 시작부터 지금까지 발견한 모든 얼굴의 개수\n",
    "    # 매 프레임마다 검출된 얼굴 수를 계속 더해감\n",
    "    # 통계 분석 및 성능 평가에 사용됨\n",
    "    \n",
    "    frame_count = 0       # 처리된 프레임 수\n",
    "    # 웹캠에서 읽어온 총 프레임(영상의 한 장면) 개수\n",
    "    # 평균 검출율 계산에 사용: 총 얼굴 수 ÷ 총 프레임 수\n",
    "    # 프로그램이 얼마나 많은 영상을 처리했는지 나타내는 지표\n",
    "    \n",
    "    # ★ 사용자 안내 메시지 출력: 프로그램 사용법과 상태 알림 ★\n",
    "    print(\"🎬 실시간 얼굴 인식 시작!\")  # 시작 알림\n",
    "    # 이모지 🎬: 영상/카메라와 관련된 직관적인 아이콘\n",
    "    # 사용자가 프로그램이 실제로 시작되었음을 명확히 인식할 수 있음\n",
    "    \n",
    "    print(\"👤 얼굴을 카메라 앞에 위치시켜보세요\")  # 행동 가이드\n",
    "    # 이모지 👤: 사람/얼굴을 나타내는 아이콘\n",
    "    # 구체적인 행동 지시로 사용자가 무엇을 해야 하는지 명확히 제시\n",
    "    \n",
    "    print(\"📱 's'키로 저장, 'q'키로 종료\")  # 조작 방법 안내\n",
    "    # 이모지 📱: 키보드/조작과 관련된 아이콘\n",
    "    # 핵심 조작 방법을 간단명료하게 설명\n",
    "    # s키: screenshot/save의 줄임말, q키: quit의 줄임말\n",
    "    \n",
    "    # ★★★ 메인 루프: 실시간 영상 처리의 핵심 반복 구조 ★★★\n",
    "    while True:  # 무한 반복문으로 연속적인 프레임 처리\n",
    "        # while True: 조건이 항상 참이므로 무한히 반복됨\n",
    "        # 실시간 영상 처리의 기본 패턴: 계속해서 새로운 프레임을 받아서 처리\n",
    "        # break 문을 만나기 전까지 계속 실행됨\n",
    "        \n",
    "        # ★ 웹캠에서 프레임 읽기: 한 장면의 이미지 데이터 획득 ★\n",
    "        ret, frame = cap.read()  # 카메라에서 현재 프레임을 읽어옴\n",
    "        # cap.read(): 카메라에서 다음 프레임을 읽는 메서드\n",
    "        # 반환값 두 개:\n",
    "        #   ret (return): 프레임 읽기 성공 여부 (True/False)\n",
    "        #   frame: 실제 이미지 데이터 (numpy 배열 형태)\n",
    "        # 튜플 언패킹: 두 개의 반환값을 각각 다른 변수에 할당\n",
    "        \n",
    "        if not ret:  # 프레임 읽기 실패 시\n",
    "            # ret이 False인 경우: 카메라 연결 끊김, 카메라 오류, 비디오 파일 끝 등\n",
    "            break  # while 루프를 즉시 종료\n",
    "            # break: 가장 가까운 반복문을 빠져나감\n",
    "            # 카메라 문제 시 프로그램이 무한 대기하지 않도록 안전장치 역할\n",
    "        \n",
    "        # ★ 거울 효과를 위해 좌우 반전: 사용자 경험 개선 ★\n",
    "        frame = cv2.flip(frame, 1)  # 이미지를 좌우로 뒤집음\n",
    "        # cv2.flip(): 이미지를 뒤집는 함수\n",
    "        # 두 번째 매개변수 1: 좌우 반전 (horizontal flip)\n",
    "        #   0: 상하 반전 (vertical flip)\n",
    "        #   1: 좌우 반전 (horizontal flip)  \n",
    "        #   -1: 상하좌우 모두 반전 (both)\n",
    "        # 거울 효과: 사용자가 자연스럽게 느끼도록 함 (셀카 모드)\n",
    "        \n",
    "        frame_count += 1  # 처리된 프레임 수를 1 증가\n",
    "        # += 연산자: frame_count = frame_count + 1과 동일\n",
    "        # 매 프레임마다 카운터를 증가시켜서 총 처리량 추적\n",
    "        \n",
    "        # ★ 얼굴 검출을 위해 흑백으로 변환: 전처리 과정 ★\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # cv2.cvtColor(): 색공간 변환 함수\n",
    "        # COLOR_BGR2GRAY: BGR(파랑-초록-빨강) → 그레이스케일 변환\n",
    "        # 흑백 변환 이유:\n",
    "        #   1. 처리 속도 향상 (3채널 → 1채널로 데이터량 1/3 감소)\n",
    "        #   2. Haar Cascade는 명암 차이를 이용하므로 색상 정보 불필요\n",
    "        #   3. 조명 변화에 더 강건함 (색상 노이즈 제거)\n",
    "        \n",
    "        # ★★ 얼굴 검출 실행: Haar Cascade 알고리즘으로 얼굴 위치 찾기 ★★\n",
    "        faces = face_cascade.detectMultiScale(\n",
    "            # detectMultiScale(): 다양한 크기의 객체를 검출하는 핵심 함수\n",
    "            # 이미지 피라미드를 만들어서 여러 스케일에서 검출 시도\n",
    "            # 반환값: [(x, y, w, h), ...] 형태의 리스트 (검출된 얼굴들의 사각형 좌표)\n",
    "            \n",
    "            gray,                # 입력 이미지 (흑백으로 변환된 프레임)\n",
    "            # 첫 번째 매개변수: 검출을 수행할 대상 이미지\n",
    "            \n",
    "            scaleFactor=1.08,    # 이미지 피라미드에서 크기 축소 비율\n",
    "            # 1.08: 매번 8%씩 이미지를 축소하면서 검출\n",
    "            # 값이 작을수록 더 정밀하게 검출하지만 처리 시간 증가\n",
    "            # 값이 클수록 빠르지만 얼굴을 놓칠 가능성 증가\n",
    "            # 1.08은 오검출 방지를 위해 약간 높게 설정 (안정성 우선)\n",
    "            \n",
    "            minNeighbors=6,      # 최소 이웃 검출 횟수 (거짓 양성 제거)\n",
    "            # 같은 위치에서 최소 6번 이상 검출되어야 유효한 얼굴로 판정\n",
    "            # 값이 클수록 더 엄격하게 검출 (오검출 감소, 놓치는 경우 증가)\n",
    "            # 6은 이웃 조건을 강화해서 잘못된 검출을 줄임\n",
    "            \n",
    "            minSize=(80, 80),    # 최소 얼굴 크기 (픽셀 단위)\n",
    "            # 80x80 픽셀보다 작은 검출 결과는 무시\n",
    "            # 너무 작은 검출은 노이즈일 가능성이 높음\n",
    "            # 실제 얼굴보다 작은 검출 결과 제거\n",
    "            \n",
    "            maxSize=(300, 300),  # 최대 얼굴 크기 제한\n",
    "            # 300x300 픽셀보다 큰 검출 결과는 무시\n",
    "            # 너무 큰 검출은 오검출일 가능성이 높음\n",
    "            # 화면 해상도 800x600에서 적절한 상한선 설정\n",
    "            \n",
    "            flags=cv2.CASCADE_SCALE_IMAGE  # 검출 알고리즘 플래그\n",
    "            # CASCADE_SCALE_IMAGE: 이미지 크기를 조절하며 검출 (일반적 방법)\n",
    "            # 다른 옵션: CASCADE_DO_CANNY_PRUNING (Canny 엣지 검출로 사전 필터링)\n",
    "        )\n",
    "        \n",
    "        # ★ 현재 프레임의 검출 결과 통계 업데이트 ★\n",
    "        current_faces = len(faces)  # 현재 프레임에서 검출된 얼굴 개수\n",
    "        # len(): 리스트의 길이(원소 개수)를 반환하는 내장 함수\n",
    "        # faces 리스트의 원소 개수 = 검출된 얼굴의 개수\n",
    "        \n",
    "        face_count_total += current_faces  # 누적 얼굴 수에 현재 검출 수 추가\n",
    "        # 전체 통계에 현재 프레임 결과를 반영\n",
    "        # 프로그램 종료 시 평균 검출율 계산에 사용됨\n",
    "        \n",
    "# ★★★ 검출된 각 얼굴에 대해 상세 처리: 개별 얼굴마다 심층 분석 수행 ★★★\n",
    "        for i, (x, y, w, h) in enumerate(faces):\n",
    "            # for 루프: 검출된 모든 얼굴에 대해 순차적으로 처리\n",
    "            # enumerate(): 리스트의 인덱스와 값을 동시에 반환하는 내장 함수\n",
    "            #   예: [(0, face1), (1, face2), (2, face3)] 형태로 반환\n",
    "            # i: 얼굴 순서 번호 (0부터 시작)\n",
    "            # (x, y, w, h): 얼굴 사각형 좌표 정보를 튜플 언패킹\n",
    "            #   x, y: 얼굴 사각형의 왼쪽 위 모서리 좌표 (픽셀 단위)\n",
    "            #   w, h: 얼굴 사각형의 너비(width)와 높이(height) (픽셀 단위)\n",
    "            \n",
    "            print(f\"  얼굴 {i+1} 검출됨: 위치=({x},{y}), 크기={w}x{h}\")\n",
    "            # f-string: Python 3.6+에서 지원하는 포맷된 문자열 리터럴\n",
    "            # {i+1}: i는 0부터 시작하므로 +1해서 1부터 표시 (사용자 친화적)\n",
    "            # 디버깅과 모니터링을 위한 콘솔 출력\n",
    "            # 실시간으로 얼굴 검출 현황을 파악할 수 있음\n",
    "            \n",
    "            # ★ 얼굴 주변에 녹색 사각형 그리기: 검출 결과 시각화 ★\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "            # cv2.rectangle(): 사각형을 그리는 OpenCV 함수\n",
    "            # 매개변수 분석:\n",
    "            #   frame: 그림을 그릴 대상 이미지 (원본 프레임)\n",
    "            #   (x, y): 사각형의 시작점 좌표 (왼쪽 위 모서리)\n",
    "            #   (x+w, y+h): 사각형의 끝점 좌표 (오른쪽 아래 모서리)\n",
    "            #     x+w: 시작점 x + 너비 = 오른쪽 끝 x좌표\n",
    "            #     y+h: 시작점 y + 높이 = 아래쪽 끝 y좌표\n",
    "            #   (0, 255, 0): 색상값 (BGR 순서로 녹색)\n",
    "            #     B(파랑)=0, G(초록)=255, R(빨강)=0 → 순수한 녹색\n",
    "            #   3: 선의 두께 (픽셀 단위), 굵은 선으로 명확하게 표시\n",
    "            \n",
    "            # ★ 얼굴 번호 표시: 여러 얼굴 구분을 위한 라벨링 ★\n",
    "            cv2.putText(frame, f'Face {i+1}', (x, y-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            # cv2.putText(): 이미지에 텍스트를 그리는 함수\n",
    "            # 매개변수 상세 분석:\n",
    "            #   frame: 텍스트를 그릴 이미지\n",
    "            #   f'Face {i+1}': 표시할 텍스트 (Face 1, Face 2, ...)\n",
    "            #   (x, y-10): 텍스트 위치 좌표\n",
    "            #     x: 얼굴 사각형과 같은 x 위치 (정렬됨)\n",
    "            #     y-10: 얼굴 사각형 위쪽 10픽셀 지점 (겹치지 않게)\n",
    "            #   cv2.FONT_HERSHEY_SIMPLEX: 폰트 종류\n",
    "            #     HERSHEY_SIMPLEX: OpenCV에서 가장 일반적인 기본 폰트\n",
    "            #     선명하고 읽기 쉬운 sans-serif 계열 폰트\n",
    "            #   0.7: 폰트 크기 (스케일 팩터)\n",
    "            #     1.0이 기본 크기, 0.7은 약간 작게 표시\n",
    "            #   (0, 255, 0): 텍스트 색상 (사각형과 동일한 녹색)\n",
    "            #   2: 텍스트 두께 (픽셀 단위), 두꺼운 글씨로 가독성 향상\n",
    "            \n",
    "            # ★ 얼굴 크기 정보 표시: 디버깅 및 분석을 위한 메타데이터 ★\n",
    "            cv2.putText(frame, f'{w}x{h}', (x, y+h+20), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)\n",
    "            # 얼굴 크기 정보를 \"너비x높이\" 형태로 표시\n",
    "            # 매개변수 분석:\n",
    "            #   f'{w}x{h}': 너비와 높이를 \"가로x세로\" 형태로 표시 (예: \"120x140\")\n",
    "            #   (x, y+h+20): 텍스트 위치\n",
    "            #     x: 얼굴 사각형과 같은 x 위치\n",
    "            #     y+h+20: 얼굴 사각형 아래쪽 20픽셀 지점\n",
    "            #   0.5: 더 작은 폰트 크기 (부가 정보이므로)\n",
    "            #   (255, 255, 0): 노란색 (BGR: 파랑=255, 초록=255, 빨강=0)\n",
    "            #     얼굴 테두리(녹색)와 구분되는 색상 사용\n",
    "            #   1: 얇은 텍스트 두께 (세부 정보이므로 덜 두드러지게)\n",
    "            \n",
    "            # ★ 얼굴 영역에서 눈 검출을 위한 ROI 설정: 관심 영역 추출 ★\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            # ROI (Region of Interest): 관심 영역, 전체 이미지에서 특정 부분만 추출\n",
    "            # 배열 슬라이싱: numpy 배열에서 특정 영역을 잘라내는 방법\n",
    "            #   gray[y:y+h, x:x+w]: 2차원 배열에서 사각형 영역 추출\n",
    "            #   [행_시작:행_끝, 열_시작:열_끝] 형태\n",
    "            #   y:y+h: 세로 방향으로 y부터 y+h까지 (얼굴 높이만큼)\n",
    "            #   x:x+w: 가로 방향으로 x부터 x+w까지 (얼굴 너비만큼)\n",
    "            # 전체 이미지에서 얼굴 부분만 추출해서 눈 검출 범위를 제한\n",
    "            # 이렇게 하면 검출 속도 향상 + 오검출 감소 효과\n",
    "            \n",
    "            # ★★ 해부학적 비율 기반 눈 영역 정의: 인체공학 데이터 활용한 정밀 위치 예측 ★★\n",
    "            # 일반적인 얼굴 비율 (레오나르도 다빈치의 인체 비례, 현대 해부학 연구 결과):\n",
    "            # - 눈은 얼굴 높이의 1/4 ~ 1/2 지점에 위치\n",
    "            # - 두 눈 사이 거리 ≈ 한 눈의 폭\n",
    "            # - 눈 폭 : 얼굴 폭 ≈ 1 : 5\n",
    "            # - 눈높이선이 얼굴을 황금비로 분할\n",
    "            \n",
    "            # ★ 눈이 위치하는 세로 영역 계산: 수직 좌표 범위 설정 ★\n",
    "            eye_region_top = int(h * 0.25)     # 얼굴 상단에서 25% 지점\n",
    "            # h * 0.25: 얼굴 높이의 25% 계산\n",
    "            # 이 지점은 보통 이마와 눈썹 사이, 눈의 상단부에 해당\n",
    "            # int(): 소수점을 버리고 정수로 변환 (픽셀 좌표는 정수여야 함)\n",
    "            # 25%를 선택한 이유: 이마, 머리카락 영역을 제외하고 눈이 시작되는 지점\n",
    "            \n",
    "            eye_region_bottom = int(h * 0.55)  # 얼굴 상단에서 55% 지점\n",
    "            # h * 0.55: 얼굴 높이의 55% 계산\n",
    "            # 이 지점은 보통 코 중간 부분, 눈의 하단부에 해당\n",
    "            # 55%를 선택한 이유: 코, 입 영역을 제외하고 눈이 끝나는 지점\n",
    "            # 25%~55% 범위: 얼굴 높이의 30%에 해당하는 눈 영역\n",
    "            \n",
    "            eye_region_height = eye_region_bottom - eye_region_top\n",
    "            # 실제 눈 검출 영역의 높이 계산\n",
    "            # 나중에 detectMultiScale의 maxSize 제한에 사용됨\n",
    "            # 너무 큰 검출 결과(얼굴 전체만한 크기)를 방지\n",
    "            \n",
    "            # ★ 왼쪽 눈 영역 정의 (화면상 오른쪽 - 거울 반전 고려) ★\n",
    "            # 주의: 웹캠은 cv2.flip(frame, 1)로 좌우 반전되어 있음\n",
    "            # 따라서 사용자의 실제 왼쪽 눈이 화면에서는 오른쪽에 나타남\n",
    "            left_eye_left = int(w * 0.15)      # 얼굴 너비의 15% 지점에서 시작\n",
    "            # w * 0.15: 얼굴 너비의 15% 계산\n",
    "            # 15%를 선택한 이유:\n",
    "            #   - 얼굴 가장자리(0%)는 머리카락, 귀 영역일 가능성\n",
    "            #   - 적당히 안쪽으로 들어온 지점부터 눈 검출 시작\n",
    "            #   - 얼굴 윤곽선의 오차를 고려한 여유 공간\n",
    "            \n",
    "            left_eye_right = int(w * 0.45)     # 얼굴 너비의 45% 지점까지\n",
    "            # w * 0.45: 얼굴 너비의 45% 계산\n",
    "            # 45%를 선택한 이유:\n",
    "            #   - 얼굴 중앙(50%) 근처까지 포함\n",
    "            #   - 코 영역과 약간 겹치도록 해서 눈을 놓치지 않게 함\n",
    "            #   - 15%~45% = 30% 너비로 충분한 검출 공간 확보\n",
    "            \n",
    "            left_eye_width = left_eye_right - left_eye_left\n",
    "            # 왼쪽 눈 검출 영역의 실제 너비 계산\n",
    "            # detectMultiScale의 maxSize 제한에 사용됨\n",
    "            # 영역을 벗어나는 큰 검출 결과를 방지\n",
    "            \n",
    "            # ★ 오른쪽 눈 영역 정의 (화면상 왼쪽 - 거울 반전 고려) ★\n",
    "            right_eye_left = int(w * 0.55)     # 얼굴 너비의 55% 지점에서 시작\n",
    "            # w * 0.55: 얼굴 너비의 55% 계산\n",
    "            # 55%를 선택한 이유:\n",
    "            #   - 얼굴 중앙(50%)을 약간 넘어선 지점부터 시작\n",
    "            #   - 왼쪽 눈 영역(~45%)과 약간 겹치도록 설정\n",
    "            #   - 코 영역을 포함해서 놓치는 눈이 없도록 함\n",
    "            \n",
    "            right_eye_right = int(w * 0.85)    # 얼굴 너비의 85% 지점까지\n",
    "            # w * 0.85: 얼굴 너비의 85% 계산\n",
    "            # 85%를 선택한 이유:\n",
    "            #   - 얼굴 가장자리(100%)는 머리카락, 귀 영역 제외\n",
    "            #   - 적당한 여유를 두고 안쪽에서 검출 종료\n",
    "            #   - 55%~85% = 30% 너비로 왼쪽과 동일한 크기\n",
    "            \n",
    "            right_eye_width = right_eye_right - right_eye_left\n",
    "            # 오른쪽 눈 검출 영역의 실제 너비 계산\n",
    "            # 왼쪽 눈과 동일한 크기(30%)로 균형 맞춤\n",
    "            # 좌우 대칭적인 검출 조건 제공\n",
    "            \n",
    "            # ★ 각 눈 영역에서 개별적으로 눈 검출: 분할 정복 전략 ★\n",
    "            detected_eyes = []  # 검출된 눈 정보를 저장할 빈 리스트 초기화\n",
    "            # 리스트 초기화: 각 얼굴마다 새로운 눈 검출 결과 저장\n",
    "            # 나중에 딕셔너리 형태로 눈 정보 추가: {'position': 'left', 'coords': (x,y,w,h), ...}\n",
    "            # 분할 정복: 전체 얼굴에서 한번에 검출하지 않고 좌우로 나누어 개별 검출\n",
    "            # 이렇게 하면 검출 정확도 향상 + 왼쪽/오른쪽 눈 구분 가능\n",
    "            \n",
    "# ★★★ 왼쪽 눈 영역에서 검출: 좌측 눈 전용 ROI에서 정밀 검출 수행 ★★★\n",
    "            left_eye_roi = roi_gray[eye_region_top:eye_region_bottom, \n",
    "                                   left_eye_left:left_eye_right]\n",
    "            # 2차원 배열 슬라이싱으로 왼쪽 눈 예상 영역만 추출\n",
    "            # roi_gray: 전체 얼굴의 흑백 이미지 (이미 추출된 얼굴 ROI)\n",
    "            # [eye_region_top:eye_region_bottom, left_eye_left:left_eye_right]:\n",
    "            #   세로: eye_region_top(25%) ~ eye_region_bottom(55%) 범위\n",
    "            #   가로: left_eye_left(15%) ~ left_eye_right(45%) 범위\n",
    "            # 결과: 얼굴에서 왼쪽 눈이 있을 것으로 예상되는 직사각형 영역\n",
    "            # 이렇게 영역을 제한하면 검출 속도 ↑, 오검출 확률 ↓\n",
    "            \n",
    "            # ★ 추출한 ROI 크기 검증: 의미있는 검출이 가능한지 확인 ★\n",
    "            if left_eye_roi.shape[0] > 10 and left_eye_roi.shape[1] > 10:\n",
    "                # shape[0]: 이미지의 높이 (행의 개수)\n",
    "                # shape[1]: 이미지의 너비 (열의 개수)\n",
    "                # 10픽셀 임계값: 너무 작은 영역에서는 의미있는 검출 불가능\n",
    "                # and 연산자: 높이와 너비 모두 10픽셀 이상이어야 함\n",
    "                # 이 조건을 만족해야 detectMultiScale 실행\n",
    "                \n",
    "                # ★ 왼쪽 눈 영역에서 Haar Cascade 검출 실행 ★\n",
    "                left_eyes = eye_cascade.detectMultiScale(\n",
    "                    # detectMultiScale: 다중 스케일 객체 검출 함수\n",
    "                    # 이미지 피라미드를 만들어서 다양한 크기의 눈을 검출\n",
    "                    \n",
    "                    left_eye_roi,        # 입력 이미지: 왼쪽 눈 예상 영역만\n",
    "                    # 전체 얼굴이 아닌 작은 영역에서 검출하므로 속도 향상\n",
    "                    \n",
    "                    scaleFactor=1.02,    # 이미지 축소 비율 (매우 세밀한 검출)\n",
    "                    # 1.02: 매번 2%씩 이미지를 축소하며 검출\n",
    "                    # 얼굴 검출(1.08)보다 더 세밀함: 눈은 얼굴보다 훨씬 작고 정교한 객체\n",
    "                    # 작은 값 = 더 정밀한 검출, 더 많은 후보 검사 = 높은 정확도\n",
    "                    \n",
    "                    minNeighbors=1,      # 최소 이웃 검출 횟수 (매우 관대한 조건)\n",
    "                    # 1: 한 번만 검출되어도 유효한 눈으로 판정\n",
    "                    # 얼굴 검출(6)보다 훨씬 관대함: 눈은 작아서 검출이 어려우므로\n",
    "                    # 너무 엄격하면 실제 눈을 놓칠 가능성이 높음\n",
    "                    \n",
    "                    minSize=(8, 6),      # 최소 눈 크기 (가로 8픽셀, 세로 6픽셀)\n",
    "                    # 8x6: 매우 작은 크기까지 검출 허용\n",
    "                    # 원거리에 있거나 작은 얼굴의 눈도 검출할 수 있도록\n",
    "                    # 가로 > 세로: 눈의 일반적인 형태 (타원형) 반영\n",
    "                    \n",
    "                    maxSize=(left_eye_width, eye_region_height),  # 최대 크기 제한\n",
    "                    # 검출 영역 크기를 넘어서는 결과는 오검출로 판정\n",
    "                    # left_eye_width: 왼쪽 눈 영역의 너비 (얼굴 너비의 30%)\n",
    "                    # eye_region_height: 눈 영역의 높이 (얼굴 높이의 30%)\n",
    "                    # 이보다 큰 검출은 얼굴 전체를 눈으로 잘못 인식한 경우\n",
    "                    \n",
    "                    flags=cv2.CASCADE_SCALE_IMAGE  # 검출 알고리즘 플래그\n",
    "                    # CASCADE_SCALE_IMAGE: 이미지 크기를 조절하며 검출 (표준 방법)\n",
    "                    # 다른 옵션들보다 안정적이고 일반적으로 사용됨\n",
    "                )\n",
    "                \n",
    "                # ★ 검출 결과 처리: 여러 후보 중 최적의 눈 선택 ★\n",
    "                if len(left_eyes) > 0:  # 하나 이상의 눈이 검출된 경우\n",
    "                    # len(left_eyes): 검출된 눈 후보의 개수\n",
    "                    # 0개: 검출 실패, 1개 이상: 검출 성공\n",
    "                    \n",
    "                    # ★ 면적이 가장 큰 검출 결과를 최종 눈으로 선택 ★\n",
    "                    best_left_eye = max(left_eyes, key=lambda e: e[2] * e[3])\n",
    "                    # max(): 리스트에서 최대값을 찾는 내장 함수\n",
    "                    # key 매개변수: 비교 기준을 정의하는 함수\n",
    "                    # lambda e: e[2] * e[3]: 익명 함수로 면적 계산\n",
    "                    #   e: 각 검출 결과 (x, y, w, h) 튜플\n",
    "                    #   e[2]: 너비(width), e[3]: 높이(height)\n",
    "                    #   e[2] * e[3]: 너비 × 높이 = 면적\n",
    "                    # 면적이 큰 검출 = 더 확실한 눈일 가능성이 높음\n",
    "                    \n",
    "                    ex, ey, ew, eh = best_left_eye  # 최고 후보의 좌표 정보 추출\n",
    "                    # 튜플 언패킹: (x, y, w, h) → 각각의 변수로 분리\n",
    "                    # ex, ey: 왼쪽 눈 영역 내에서의 상대 좌표\n",
    "                    # ew, eh: 검출된 눈의 너비와 높이\n",
    "                    # 주의: 이 좌표는 left_eye_roi 기준의 상대 좌표임\n",
    "                    \n",
    "                    # ★ 전체 얼굴 좌표계로 변환: 상대 좌표 → 절대 좌표 ★\n",
    "                    absolute_coords = (left_eye_left + ex, eye_region_top + ey, ew, eh)\n",
    "                    # 좌표계 변환 공식:\n",
    "                    #   절대_x = 영역_시작_x + 상대_x\n",
    "                    #   절대_y = 영역_시작_y + 상대_y\n",
    "                    # left_eye_left + ex: 왼쪽 눈 영역 시작점 + 영역 내 상대 x좌표\n",
    "                    # eye_region_top + ey: 눈 영역 시작점 + 영역 내 상대 y좌표\n",
    "                    # ew, eh: 크기는 그대로 유지 (절대 크기이므로)\n",
    "                    # 결과: 전체 얼굴 이미지에서의 실제 눈 위치\n",
    "                    \n",
    "                    # ★ 검출된 왼쪽 눈 정보를 딕셔너리로 저장 ★\n",
    "                    detected_eyes.append({\n",
    "                        # append(): 리스트 끝에 새로운 원소 추가\n",
    "                        # 딕셔너리: 키-값 쌍으로 구조화된 데이터 저장\n",
    "                        \n",
    "                        'position': 'left',          # 눈의 위치 식별자\n",
    "                        # 문자열로 왼쪽 눈임을 명시\n",
    "                        # 나중에 색상, 라벨 등을 다르게 처리할 때 사용\n",
    "                        \n",
    "                        'coords': absolute_coords,   # 전체 좌표계에서의 위치와 크기\n",
    "                        # 변환된 절대 좌표 (x, y, w, h) 튜플\n",
    "                        # 전체 얼굴 이미지에서 그림을 그릴 때 사용\n",
    "                        \n",
    "                        'confidence': len(left_eyes) # 검출 신뢰도 (검출된 개수)\n",
    "                        # 검출된 후보의 개수를 신뢰도로 사용\n",
    "                        # 많이 검출될수록 더 확실한 눈일 가능성이 높음\n",
    "                        # 예: 3개 검출 > 1개 검출 (신뢰도 높음)\n",
    "                    })\n",
    "            \n",
    "            # ★★★ 오른쪽 눈 영역에서 검출: 우측 눈 전용 ROI에서 정밀 검출 수행 ★★★\n",
    "            # 왼쪽 눈과 동일한 과정을 오른쪽 눈 영역에서 반복\n",
    "            right_eye_roi = roi_gray[eye_region_top:eye_region_bottom, \n",
    "                                    right_eye_left:right_eye_right]\n",
    "            # 2차원 배열 슬라이싱으로 오른쪽 눈 예상 영역만 추출\n",
    "            # [eye_region_top:eye_region_bottom, right_eye_left:right_eye_right]:\n",
    "            #   세로: 동일한 눈 높이 범위 (25%~55%)\n",
    "            #   가로: right_eye_left(55%) ~ right_eye_right(85%) 범위\n",
    "            # 왼쪽과 대칭적으로 오른쪽 눈 영역 설정\n",
    "            \n",
    "            # ★ 추출한 ROI 크기 검증 (왼쪽과 동일한 검증 과정) ★\n",
    "            if right_eye_roi.shape[0] > 10 and right_eye_roi.shape[1] > 10:\n",
    "                # 동일한 10픽셀 임계값 적용\n",
    "                # 높이와 너비 모두 충분한 크기인지 확인\n",
    "                \n",
    "                # ★ 오른쪽 눈 영역에서 Haar Cascade 검출 실행 ★\n",
    "                right_eyes = eye_cascade.detectMultiScale(\n",
    "                    # 왼쪽 눈과 동일한 파라미터 사용 (일관성 유지)\n",
    "                    \n",
    "                    right_eye_roi,       # 입력 이미지: 오른쪽 눈 예상 영역만\n",
    "                    scaleFactor=1.02,    # 동일한 세밀한 검출 조건\n",
    "                    minNeighbors=1,      # 동일한 관대한 조건\n",
    "                    minSize=(8, 6),      # 동일한 최소 크기\n",
    "                    maxSize=(right_eye_width, eye_region_height),  # 오른쪽 영역 크기로 제한\n",
    "                    # right_eye_width: 오른쪽 눈 영역의 너비 (왼쪽과 동일한 30%)\n",
    "                    flags=cv2.CASCADE_SCALE_IMAGE\n",
    "                )\n",
    "                \n",
    "                # ★ 검출 결과 처리 (왼쪽 눈과 동일한 과정) ★\n",
    "                if len(right_eyes) > 0:  # 하나 이상의 눈이 검출된 경우\n",
    "                    \n",
    "                    # ★ 면적이 가장 큰 검출 결과를 최종 눈으로 선택 ★\n",
    "                    best_right_eye = max(right_eyes, key=lambda e: e[2] * e[3])\n",
    "                    # 동일한 면적 기준 선택 알고리즘\n",
    "                    # 가장 큰 검출 결과 = 가장 확실한 오른쪽 눈\n",
    "                    \n",
    "                    ex, ey, ew, eh = best_right_eye  # 최고 후보의 좌표 정보 추출\n",
    "                    # 오른쪽 눈 영역 내에서의 상대 좌표\n",
    "                    # 왼쪽과 동일한 언패킹 과정\n",
    "                    \n",
    "                    # ★ 전체 얼굴 좌표계로 변환 ★\n",
    "                    absolute_coords = (right_eye_left + ex, eye_region_top + ey, ew, eh)\n",
    "                    # 좌표계 변환 공식 (오른쪽 눈용):\n",
    "                    #   절대_x = right_eye_left + ex (오른쪽 영역 시작점 + 상대 x)\n",
    "                    #   절대_y = eye_region_top + ey (동일한 눈 높이 + 상대 y)\n",
    "                    # right_eye_left: 오른쪽 눈 영역의 시작 x좌표 (55% 지점)\n",
    "                    \n",
    "                    # ★ 검출된 오른쪽 눈 정보를 딕셔너리로 저장 ★\n",
    "                    detected_eyes.append({\n",
    "                        # 왼쪽 눈과 동일한 구조의 딕셔너리\n",
    "                        \n",
    "                        'position': 'right',         # 눈의 위치 식별자 (오른쪽)\n",
    "                        # 왼쪽('left')과 구분되는 식별자\n",
    "                        # 시각적 표시 시 다른 색상/라벨 사용 근거\n",
    "                        \n",
    "                        'coords': absolute_coords,   # 전체 좌표계에서의 위치와 크기\n",
    "                        # 변환된 절대 좌표 (전체 얼굴 기준)\n",
    "                        \n",
    "                        'confidence': len(right_eyes) # 검출 신뢰도 (검출된 개수)\n",
    "                        # 오른쪽 눈에서 검출된 후보 개수\n",
    "                        # 왼쪽과 독립적인 신뢰도 측정\n",
    "                    })\n",
    "            \n",
    "            # 이 시점에서 detected_eyes 리스트에는\n",
    "            # 0개 (양쪽 눈 모두 검출 실패)\n",
    "            # 1개 (한쪽 눈만 검출 성공) \n",
    "            # 2개 (양쪽 눈 모두 검출 성공) \n",
    "            # 의 눈 정보가 저장되어 있음\n",
    "            \n",
    "# ★★★ 눈 영역 가이드 박스 표시: 검출 과정의 시각적 가이드 제공 ★★★\n",
    "            # 목적: 사용자가 알고리즘이 어느 영역에서 눈을 찾고 있는지 직관적으로 이해\n",
    "            # 효과: 디버깅 도움 + 교육적 가치 + 사용자의 얼굴 위치 조정 가이드\n",
    "            \n",
    "            # ★ 왼쪽 눈 영역 박스 그리기 (연한 파란색 테두리) ★\n",
    "            cv2.rectangle(frame, \n",
    "                         # 왼쪽 눈 검출 영역을 전체 프레임에서 시각적으로 표시\n",
    "                         \n",
    "                         (x + left_eye_left, y + eye_region_top),    # 시작점 좌표\n",
    "                         # x + left_eye_left: 얼굴 x좌표 + 왼쪽 눈 영역 시작점\n",
    "                         #   = 전체 프레임에서 왼쪽 눈 영역의 실제 x좌표\n",
    "                         # y + eye_region_top: 얼굴 y좌표 + 눈 영역 상단\n",
    "                         #   = 전체 프레임에서 눈 영역의 실제 y좌표\n",
    "                         \n",
    "                         (x + left_eye_right, y + eye_region_bottom), # 끝점 좌표\n",
    "                         # x + left_eye_right: 얼굴 x좌표 + 왼쪽 눈 영역 끝점\n",
    "                         # y + eye_region_bottom: 얼굴 y좌표 + 눈 영역 하단\n",
    "                         # 결과: 왼쪽 눈 검출 영역의 완전한 사각형\n",
    "                         \n",
    "                         (255, 200, 100),    # 색상 (BGR 순서로 연한 파란색)\n",
    "                         # B=255 (파랑 최대), G=200 (초록 중간), R=100 (빨강 약간)\n",
    "                         # 결과: 연한 하늘색/청록색 계열\n",
    "                         # 너무 진하지 않게 해서 얼굴을 가리지 않음\n",
    "                         # 왼쪽 눈 영역임을 색상으로 구분\n",
    "                         \n",
    "                         1)               # 테두리 두께 1픽셀\n",
    "                         # 가이드 라인이므로 얇게 그어서 방해되지 않게 함\n",
    "                         # 굵으면 실제 검출 결과와 혼동될 수 있음\n",
    "            \n",
    "            # ★ 왼쪽 눈 영역 라벨 텍스트 표시 ★\n",
    "            cv2.putText(frame, 'L-EYE',     # 표시할 텍스트 (Left Eye의 줄임말)\n",
    "                       # 간단명료한 라벨로 영역 구분\n",
    "                       \n",
    "                       (x + left_eye_left, y + eye_region_top - 5), # 텍스트 위치\n",
    "                       # x + left_eye_left: 박스의 왼쪽 끝과 정렬\n",
    "                       # y + eye_region_top - 5: 박스 위쪽 5픽셀 지점\n",
    "                       #   박스와 겹치지 않고 바로 위에 표시\n",
    "                       \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX,  # 폰트 종류 (기본 폰트)\n",
    "                       0.3,                       # 폰트 크기 (매우 작게)\n",
    "                       # 가이드 정보이므로 작은 폰트 사용 (방해 최소화)\n",
    "                       \n",
    "                       (255, 200, 100),           # 텍스트 색상 (박스와 동일)\n",
    "                       # 박스와 같은 색상으로 통일성 유지\n",
    "                       \n",
    "                       1)                         # 텍스트 두께 1픽셀\n",
    "                       # 얇은 글씨로 깔끔하게 표시\n",
    "            \n",
    "            # ★ 오른쪽 눈 영역 박스 그리기 (연한 초록색 테두리) ★\n",
    "            cv2.rectangle(frame, \n",
    "                         # 오른쪽 눈 검출 영역을 전체 프레임에서 시각적으로 표시\n",
    "                         \n",
    "                         (x + right_eye_left, y + eye_region_top),     # 시작점 좌표\n",
    "                         # x + right_eye_left: 얼굴 x좌표 + 오른쪽 눈 영역 시작점\n",
    "                         # y + eye_region_top: 왼쪽과 동일한 눈 높이 (대칭성)\n",
    "                         \n",
    "                         (x + right_eye_right, y + eye_region_bottom), # 끝점 좌표\n",
    "                         # x + right_eye_right: 얼굴 x좌표 + 오른쪽 눈 영역 끝점\n",
    "                         # y + eye_region_bottom: 왼쪽과 동일한 눈 높이\n",
    "                         \n",
    "                         (100, 255, 200),    # 색상 (BGR 순서로 연한 초록색)\n",
    "                         # B=100 (파랑 약간), G=255 (초록 최대), R=200 (빨강 중간)\n",
    "                         # 결과: 연한 민트색/청록색 계열\n",
    "                         # 왼쪽(파란계열)과 구분되는 색상 사용\n",
    "                         # 오른쪽 눈 영역임을 색상으로 구분\n",
    "                         \n",
    "                         1)               # 테두리 두께 1픽셀 (왼쪽과 동일)\n",
    "            \n",
    "            # ★ 오른쪽 눈 영역 라벨 텍스트 표시 ★\n",
    "            cv2.putText(frame, 'R-EYE',     # 표시할 텍스트 (Right Eye의 줄임말)\n",
    "                       # 왼쪽('L-EYE')과 대칭적인 라벨\n",
    "                       \n",
    "                       (x + right_eye_left, y + eye_region_top - 5), # 텍스트 위치\n",
    "                       # x + right_eye_left: 오른쪽 박스의 왼쪽 끝과 정렬\n",
    "                       # y + eye_region_top - 5: 왼쪽과 동일한 높이\n",
    "                       \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX,  # 동일한 폰트\n",
    "                       0.3,                       # 동일한 작은 크기\n",
    "                       (100, 255, 200),           # 텍스트 색상 (박스와 동일)\n",
    "                       1)                         # 동일한 두께\n",
    "            \n",
    "            # ★★★ 검출된 눈에 시각적 표시: 실제 검출 결과의 정밀한 시각화 ★★★\n",
    "            eye_count = len(detected_eyes)  # 검출된 눈의 총 개수\n",
    "            # len(): 리스트 길이 = 검출 성공한 눈의 개수\n",
    "            # 0: 양쪽 눈 모두 검출 실패\n",
    "            # 1: 한쪽 눈만 검출 성공  \n",
    "            # 2: 양쪽 눈 모두 검출 성공\n",
    "            \n",
    "            # ★ 검출된 각 눈에 대해 개별 시각적 처리 ★\n",
    "            for eye_data in detected_eyes:\n",
    "                # for 루프: 검출된 모든 눈 (0~2개)에 대해 순차 처리\n",
    "                # eye_data: 각 눈의 정보가 담긴 딕셔너리\n",
    "                #   {'position': 'left'/'right', 'coords': (x,y,w,h), 'confidence': 숫자}\n",
    "                \n",
    "                # ★ 딕셔너리에서 눈 정보 추출 ★\n",
    "                ex, ey, ew, eh = eye_data['coords']  # 눈의 좌표와 크기 정보\n",
    "                # 튜플 언패킹: (x, y, w, h) → 각각의 변수로 분리\n",
    "                # ex, ey: 전체 얼굴에서의 눈 위치 (이미 절대 좌표로 변환됨)\n",
    "                # ew, eh: 검출된 눈의 너비와 높이\n",
    "                \n",
    "                position = eye_data['position']      # 눈의 위치 ('left' 또는 'right')\n",
    "                # 문자열로 저장된 눈의 위치 정보\n",
    "                # 색상과 라벨을 다르게 처리하기 위한 구분자\n",
    "                \n",
    "                confidence = eye_data['confidence']  # 검출 신뢰도 (검출된 개수)\n",
    "                # 해당 눈에서 발견된 후보의 총 개수\n",
    "                # 높을수록 더 확실한 검출 결과\n",
    "                \n",
    "                # ★ 눈의 중심점 계산: 정확한 눈 중심 좌표 산출 ★\n",
    "                center = (x + ex + ew//2, y + ey + eh//2)\n",
    "                # 중심점 공식: (시작점 + 크기÷2)\n",
    "                # x + ex + ew//2: 전체 프레임 x좌표 + 눈 x좌표 + 눈 너비의 절반\n",
    "                # y + ey + eh//2: 전체 프레임 y좌표 + 눈 y좌표 + 눈 높이의 절반\n",
    "                # //: 정수 나눗셈 연산자 (소수점 버림)\n",
    "                # 결과: 눈의 정확한 중심점 좌표 (전체 프레임 기준)\n",
    "                \n",
    "                # ★ 위치에 따라 다른 색상과 라벨 사용: 시각적 구분 ★\n",
    "                if position == 'left':      # 왼쪽 눈인 경우\n",
    "                    color = (255, 0, 0)     # BGR 순서로 순수한 파란색\n",
    "                    # B=255 (파랑 최대), G=0, R=0\n",
    "                    # 왼쪽 눈을 파란색으로 표시 (국제적 관례)\n",
    "                    \n",
    "                    eye_label = 'L'         # 라벨: L (Left의 줄임말)\n",
    "                    # 간단명료한 한 글자 라벨\n",
    "                    \n",
    "                elif position == 'right':   # 오른쪽 눈인 경우\n",
    "                    color = (0, 255, 0)     # BGR 순서로 순수한 초록색\n",
    "                    # B=0, G=255 (초록 최대), R=0\n",
    "                    # 오른쪽 눈을 초록색으로 표시\n",
    "                    # 파란색과 명확히 구분되는 색상\n",
    "                    \n",
    "                    eye_label = 'R'         # 라벨: R (Right의 줄임말)\n",
    "                    \n",
    "                else:                       # 예상치 못한 경우 (디버깅용)\n",
    "                    color = (0, 255, 255)   # BGR 순서로 노란색\n",
    "                    # B=0, G=255, R=255 → 노란색\n",
    "                    # 오류나 예외 상황을 나타내는 경고색\n",
    "                    \n",
    "                    eye_label = '?'         # 라벨: 물음표 (알 수 없는 위치)\n",
    "                    # 예상치 못한 position 값에 대한 표시\n",
    "                \n",
    "                # ★ 눈 주변에 사각형 그리기: 검출된 눈 영역의 정확한 테두리 ★\n",
    "                cv2.rectangle(frame,\n",
    "                             # 검출된 눈의 실제 경계를 사각형으로 표시\n",
    "                             \n",
    "                             (x + ex, y + ey),           # 사각형 시작점 (왼쪽 위)\n",
    "                             # x + ex: 전체 프레임에서 눈의 실제 x좌표\n",
    "                             # y + ey: 전체 프레임에서 눈의 실제 y좌표\n",
    "                             \n",
    "                             (x + ex + ew, y + ey + eh), # 사각형 끝점 (오른쪽 아래)\n",
    "                             # x + ex + ew: 눈의 오른쪽 끝 x좌표\n",
    "                             # y + ey + eh: 눈의 아래쪽 끝 y좌표\n",
    "                             \n",
    "                             color,      # 테두리 색상 (위치에 따라 파란색/초록색)\n",
    "                             2)          # 테두리 두께 2픽셀\n",
    "                             # 가이드 박스(1픽셀)보다 굵게 해서 실제 결과임을 강조\n",
    "                \n",
    "                # ★ 눈 라벨과 신뢰도 정보 표시: 검출 메타데이터 시각화 ★\n",
    "                cv2.putText(frame, f'{eye_label}({confidence})', \n",
    "                           # f-string: 라벨과 신뢰도를 결합한 텍스트\n",
    "                           # 예: 'L(3)', 'R(2)' 형태로 표시\n",
    "                           # 괄호 안 숫자: 해당 영역에서 검출된 후보 개수\n",
    "                           \n",
    "                           (x + ex, y + ey - 5),       # 텍스트 위치\n",
    "                           # x + ex: 눈 사각형의 왼쪽 끝과 정렬\n",
    "                           # y + ey - 5: 눈 사각형 위쪽 5픽셀 지점\n",
    "                           #   사각형과 겹치지 않게 배치\n",
    "                           \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX,   # 폰트 종류\n",
    "                           0.4,                        # 폰트 크기 (중간 크기)\n",
    "                           # 가이드 텍스트(0.3)보다 약간 크게 (중요 정보)\n",
    "                           \n",
    "                           color,                      # 텍스트 색상 (사각형과 동일)\n",
    "                           # 색상 통일로 시각적 일관성 유지\n",
    "                           \n",
    "                           1)                          # 텍스트 두께 1픽셀\n",
    "                \n",
    "                # ★ 눈 중심에 작은 원 표시: 정확한 중심점 시각화 ★\n",
    "                cv2.circle(frame,       # 그림을 그릴 이미지\n",
    "                          center,       # 원의 중심점 (위에서 계산한 눈 중심)\n",
    "                          3,            # 원의 반지름 3픽셀\n",
    "                          # 작은 크기로 해서 눈을 가리지 않으면서도 명확히 표시\n",
    "                          \n",
    "                          color,        # 원의 색상 (사각형, 텍스트와 동일)\n",
    "                          -1)           # 두께 (-1은 내부를 채움, 실심원)\n",
    "                          # 속이 찬 원으로 그려서 중심점을 명확히 표시\n",
    "                          # 테두리만 있는 원보다 시각적으로 더 눈에 띔\n",
    "            \n",
    "\n",
    "# ★★★ 검출된 눈 개수와 상태 표시: 3단계 평가 시스템으로 검출 성과 시각화 ★★★\n",
    "            # 목적: 사용자에게 눈 검출 성공/실패 상태를 직관적으로 알려줌\n",
    "            # 방법: 검출된 눈의 개수에 따라 색상과 아이콘을 다르게 표시\n",
    "            \n",
    "# ★★★ 검출된 눈 개수와 상태 표시: 3단계 평가 시스템으로 검출 성과 시각화 ★★★\n",
    "            # 목적: 사용자에게 눈 검출 성공/실패 상태를 직관적으로 알려줌\n",
    "            # 방법: 검출된 눈의 개수에 따라 색상과 아이콘을 다르게 표시\n",
    "            \n",
    "            if eye_count >= 2:              # 양쪽 눈 모두 검출된 경우 (최상의 결과)\n",
    "                # eye_count >= 2: 2개 이상의 눈이 검출됨 (이상적인 상태)\n",
    "                # 드물게 3개 이상 검출되는 경우도 있음 (오검출 포함)\n",
    "                \n",
    "                eye_status = f'Eyes: {eye_count} ✓'    # 성공 메시지 구성\n",
    "                # f-string: 동적으로 검출 개수 삽입\n",
    "                # ✓ (체크 마크): 유니코드 문자로 성공을 시각적으로 표현\n",
    "                # 예: \"Eyes: 2 ✓\" 형태로 표시\n",
    "                \n",
    "                eye_color = (0, 255, 0)                # BGR 순서로 초록색\n",
    "                # B=0, G=255 (최대), R=0 → 순수한 초록색\n",
    "                # 초록색 = 성공, 안전, 정상 상태를 나타내는 국제적 색상 코드\n",
    "                # 사용자가 직관적으로 \"좋은 상태\"로 인식\n",
    "                \n",
    "            elif eye_count == 1:            # 한쪽 눈만 검출된 경우 (부분 성공)\n",
    "                # 정확히 1개만 검출: 완전 실패는 아니지만 이상적이지도 않음\n",
    "                # 가능한 원인: 각도 문제, 조명 문제, 한쪽 눈 가림 등\n",
    "                \n",
    "                eye_status = f'Eyes: {eye_count} ⚠'     # 경고 메시지 구성\n",
    "                # ⚠ (경고 마크): 유니코드 문자로 주의/경고를 시각적으로 표현\n",
    "                # 예: \"Eyes: 1 ⚠\" 형태로 표시\n",
    "                # 완전 실패는 아니지만 개선이 필요한 상태임을 알림\n",
    "                \n",
    "                eye_color = (0, 255, 255)              # BGR 순서로 노란색\n",
    "                # B=0, G=255, R=255 → 노란색 (초록+빨강)\n",
    "                # 노란색 = 주의, 경고, 부분적 문제를 나타내는 색상\n",
    "                # 빨간색(위험)과 초록색(안전) 사이의 중간 상태\n",
    "                \n",
    "            else:                           # 눈이 전혀 검출되지 않은 경우 (완전 실패)\n",
    "                # eye_count == 0: 양쪽 눈 모두 검출 실패\n",
    "                # 가능한 원인: 얼굴 각도, 조명 부족, 가림, 거리 문제 등\n",
    "                \n",
    "                eye_status = f'Eyes: {eye_count} ✗'     # 실패 메시지 구성\n",
    "                # ✗ (X 마크): 유니코드 문자로 실패/오류를 시각적으로 표현\n",
    "                # 예: \"Eyes: 0 ✗\" 형태로 표시\n",
    "                # 명확한 실패 상태임을 알림\n",
    "                \n",
    "                eye_color = (0, 0, 255)                # BGR 순서로 빨간색\n",
    "                # B=0, G=0, R=255 (최대) → 순수한 빨간색\n",
    "                # 빨간색 = 위험, 오류, 실패를 나타내는 국제적 색상 코드\n",
    "                # 사용자의 즉각적인 주의를 끌어서 문제 해결 유도\n",
    "            \n",
    "            # ★ 눈 검출 상태를 얼굴 아래쪽에 표시 ★\n",
    "            cv2.putText(frame, eye_status,  # 위에서 결정된 상태 메시지 표시\n",
    "                       # eye_status: \"Eyes: 숫자 아이콘\" 형태의 문자열\n",
    "                       \n",
    "                       (x, y+h+40),        # 텍스트 위치 계산\n",
    "                       # x: 얼굴 사각형의 왼쪽 끝과 정렬 (일관성 유지)\n",
    "                       # y+h+40: 얼굴 사각형 아래쪽 40픽셀 지점\n",
    "                       #   h는 얼굴 높이이므로 y+h = 얼굴 사각형 하단\n",
    "                       #   +40으로 충분한 여백 확보 (다른 정보와 겹치지 않게)\n",
    "                       \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX,  # 폰트 종류 (표준 폰트)\n",
    "                       0.5,                       # 폰트 크기 (중간 크기)\n",
    "                       # 너무 크면 화면을 가리고, 너무 작으면 읽기 어려움\n",
    "                       # 0.5는 가독성과 공간 효율성의 균형점\n",
    "                       \n",
    "                       eye_color,                 # 텍스트 색상 (상태에 따라 결정)\n",
    "                       # 초록색(성공) / 노란색(부분성공) / 빨간색(실패)\n",
    "                       # 색상으로 상태를 즉시 파악 가능\n",
    "                       \n",
    "                       1)                         # 텍스트 두께 1픽셀\n",
    "                       # 적당한 두께로 선명하게 표시\n",
    "            \n",
    "            # ★★★ 얼굴 강조 효과: 검출된 얼굴을 시각적으로 돋보이게 만드는 후처리 ★★★\n",
    "            # 조건: 얼굴이 정확히 하나만 있을 때만 적용\n",
    "            # 이유: 여러 얼굴이 있으면 어느 것을 강조할지 애매하고, 화면이 복잡해짐\n",
    "            if current_faces == 1:         # 얼굴이 정확히 하나만 검출된 경우\n",
    "                # current_faces: 현재 프레임에서 검출된 전체 얼굴 수\n",
    "                # == 1: 정확히 하나 (0개나 2개 이상은 효과 적용 안함)\n",
    "                \n",
    "                # ★ 1단계: 얼굴 영역만 추출 ★\n",
    "                face_roi = frame[y:y+h, x:x+w]  # 얼굴 부분만 잘라냄\n",
    "                # 배열 슬라이싱: 전체 프레임에서 얼굴 사각형 영역만 추출\n",
    "                # [y:y+h, x:x+w]: 세로 y~y+h, 가로 x~x+w 범위\n",
    "                # 결과: 얼굴만 포함된 작은 이미지 (3차원 numpy 배열)\n",
    "                \n",
    "                # ★ 2단계: 밝기 향상 효과 적용 ★\n",
    "                brightened = cv2.addWeighted(face_roi, 1.2, face_roi, 0, 10)\n",
    "                # cv2.addWeighted(): 두 이미지를 가중 합산하는 함수\n",
    "                # 공식: 결과 = (이미지1 × 가중치1) + (이미지2 × 가중치2) + 추가값\n",
    "                # 매개변수 분석:\n",
    "                #   face_roi: 첫 번째 이미지 (원본 얼굴)\n",
    "                #   1.2: 첫 번째 이미지 가중치 (120% 밝기)\n",
    "                #     1.0보다 크므로 원본보다 20% 더 밝게 만듦\n",
    "                #   face_roi: 두 번째 이미지 (동일한 얼굴)\n",
    "                #   0: 두 번째 이미지 가중치 (사용하지 않음)\n",
    "                #     실제로는 첫 번째 이미지만 1.2배 적용\n",
    "                #   10: 모든 픽셀에 추가할 밝기 값\n",
    "                #     전체적으로 10만큼 더 밝게 만들어 강조 효과\n",
    "                # 결과: 원본보다 밝고 선명한 얼굴 이미지\n",
    "                \n",
    "                # ★ 3단계: 처리된 얼굴을 원본 프레임에 다시 적용 ★\n",
    "                frame[y:y+h, x:x+w] = brightened  # 밝게 처리된 얼굴로 교체\n",
    "                # 배열 대입: 원본 프레임의 얼굴 부분을 새로운 이미지로 덮어씀\n",
    "                # 결과: 얼굴 부분만 밝아지고 배경은 그대로 유지\n",
    "                # 효과: 얼굴이 화면에서 더 돋보이게 됨\n",
    "        \n",
    "        # ★★★ 화면에 실시간 정보 표시: 사용자에게 현재 상태와 통계 제공 ★★★\n",
    "        # 목적: 프로그램 동작 상태, 성능 지표, 사용법을 한눈에 파악\n",
    "        \n",
    "        # ★ 표시할 정보 텍스트들을 리스트로 구성 ★\n",
    "        info_texts = [\n",
    "            # 각 정보를 문자열로 준비, 나중에 순서대로 화면에 표시\n",
    "            \n",
    "            f'Faces Detected: {current_faces}',        # 현재 프레임의 얼굴 검출 수\n",
    "            # f-string: 동적으로 현재 검출된 얼굴 개수 표시\n",
    "            # 실시간으로 변하는 값 (0, 1, 2, ... 등)\n",
    "            \n",
    "            f'Frame: {frame_count}',                  # 처리한 총 프레임 번호\n",
    "            # 프로그램 시작부터 지금까지 처리한 프레임의 순번\n",
    "            # 성능 모니터링 및 디버깅에 유용\n",
    "            \n",
    "            f'Total Faces Found: {face_count_total}',  # 누적 얼굴 검출 수\n",
    "            # 프로그램 시작부터 지금까지 발견한 모든 얼굴의 총합\n",
    "            # 평균 검출율 계산의 기초 데이터\n",
    "            \n",
    "            'Press: s(save), q(quit)'                 # 사용자 조작 방법 안내\n",
    "            # 정적 텍스트: 프로그램 사용법 상시 표시\n",
    "            # s키: 스크린샷 저장, q키: 프로그램 종료\n",
    "        ]\n",
    "        \n",
    "        # ★ 정보 표시용 배경 박스 그리기: 텍스트 가독성 향상 ★\n",
    "        cv2.rectangle(frame, (10, 10), (300, 120), (0, 0, 0), -1)\n",
    "        # 검은색 배경 사각형으로 텍스트 뒤에 깔림\n",
    "        # (10, 10): 시작점 (화면 왼쪽 위에서 약간 안쪽)\n",
    "        # (300, 120): 끝점 (가로 290픽셀, 세로 110픽셀 크기)\n",
    "        # (0, 0, 0): 검은색 (BGR 모두 0)\n",
    "        # -1: 내부를 채움 (실심 사각형)\n",
    "        # 효과: 배경과 텍스트 사이의 대비 향상으로 가독성 증대\n",
    "        \n",
    "        cv2.rectangle(frame, (10, 10), (300, 120), (255, 255, 255), 2)\n",
    "        # 흰색 테두리로 정보 영역을 명확히 구분\n",
    "        # (255, 255, 255): 흰색 (BGR 모두 최대값)\n",
    "        # 2: 테두리 두께 2픽셀 (적당히 굵어서 명확함)\n",
    "        # 효과: 정보 영역의 경계를 시각적으로 구분\n",
    "        \n",
    "        # ★ 정보 텍스트들을 순서대로 화면에 표시 ★\n",
    "        for i, text in enumerate(info_texts):\n",
    "            # enumerate(): 인덱스와 값을 동시에 반환\n",
    "            # i: 텍스트 순서 (0, 1, 2, 3)\n",
    "            # text: 실제 표시할 문자열\n",
    "            \n",
    "            # ★ 얼굴 검출 상태에 따라 텍스트 색상 결정 ★\n",
    "            color = (0, 255, 0) if current_faces > 0 else (0, 0, 255)\n",
    "            # 삼항 연산자 (조건부 표현식): 조건 ? 참값 : 거짓값\n",
    "            # current_faces > 0: 얼굴이 하나라도 검출된 경우\n",
    "            #   (0, 255, 0): 초록색 → 정상 동작 중\n",
    "            # else: 얼굴이 전혀 검출되지 않은 경우  \n",
    "            #   (0, 0, 255): 빨간색 → 문제 상황 알림\n",
    "            # 효과: 색상으로 시스템 상태를 즉시 파악 가능\n",
    "            \n",
    "            cv2.putText(frame, text,        # 표시할 텍스트\n",
    "                       (15, 35 + i * 20),   # 텍스트 위치 계산\n",
    "                       # x=15: 배경 박스 왼쪽에서 5픽셀 안쪽 (여백)\n",
    "                       # y=35 + i * 20: 첫 번째는 35픽셀, 이후 20픽셀씩 아래로\n",
    "                       #   i=0: y=35, i=1: y=55, i=2: y=75, i=3: y=95\n",
    "                       #   각 줄 사이에 20픽셀 간격으로 깔끔하게 정렬\n",
    "                       \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX,  # 폰트 종류\n",
    "                       0.5,                       # 폰트 크기 (읽기 좋은 중간 크기)\n",
    "                       color,                     # 텍스트 색상 (상태에 따라 초록/빨강)\n",
    "                       1)                         # 텍스트 두께 1픽셀\n",
    "        \n",
    "        # ★ 얼굴이 없을 때 중앙에 안내 메시지 표시 ★\n",
    "        if current_faces == 0:          # 얼굴이 전혀 검출되지 않은 경우\n",
    "            # 사용자에게 명확한 행동 지침 제공\n",
    "            \n",
    "            cv2.putText(frame, 'Please show your face to camera', \n",
    "                       # 친근하고 명확한 안내 메시지\n",
    "                       # 사용자가 무엇을 해야 하는지 구체적으로 알려줌\n",
    "                       \n",
    "                       (frame.shape[1]//2 - 200, frame.shape[0]//2), \n",
    "                       # 화면 중앙에 위치 계산\n",
    "                       # frame.shape[1]: 프레임 너비 (예: 800픽셀)\n",
    "                       # frame.shape[0]: 프레임 높이 (예: 600픽셀)\n",
    "                       # //2: 정수 나눗셈으로 중앙점 계산\n",
    "                       # -200: 텍스트 길이를 고려해서 왼쪽으로 200픽셀 이동\n",
    "                       #   텍스트가 중앙에서 시작하면 오른쪽으로 치우쳐 보임\n",
    "                       # 결과: 텍스트의 중심이 화면 중앙에 오도록 조정\n",
    "                       \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX,  # 폰트 종류\n",
    "                       1,                         # 큰 폰트 크기 (주목도 향상)\n",
    "                       # 중요한 안내 메시지이므로 다른 텍스트보다 크게 표시\n",
    "                       \n",
    "                       (0, 0, 255),              # 빨간색 (주의 환기)\n",
    "                       # 사용자의 즉각적인 주의를 끌기 위한 경고색\n",
    "                       \n",
    "                       2)                        # 두꺼운 텍스트 (2픽셀)\n",
    "                       # 굵은 글씨로 메시지를 더욱 강조\n",
    "        \n",
    "        # ★ 최종 처리된 프레임을 화면에 표시 ★\n",
    "        cv2.imshow('OpenCV Face Detection Magic', frame)\n",
    "        # cv2.imshow(): OpenCV 창에 이미지를 표시하는 함수\n",
    "        # 'OpenCV Face Detection Magic': 창의 제목 (사용자 친화적)\n",
    "        # frame: 모든 처리가 완료된 최종 이미지\n",
    "        # 효과: 사용자가 실시간으로 검출 결과를 확인할 수 있음\n",
    "        \n",
    "# ★ 최종 처리된 프레임을 화면에 표시 ★\n",
    "        cv2.imshow('OpenCV Face Detection Magic', frame)\n",
    "        # cv2.imshow()는 OpenCV에서 이미지를 화면에 보여주는 함수임\n",
    "        # 첫 번째 매개변수 'OpenCV Face Detection Magic'은 창의 제목으로 표시됨\n",
    "        # 두 번째 매개변수 frame은 화면에 보여줄 이미지 데이터임\n",
    "        # 얼굴 검출 결과가 그려진 최종 이미지를 실시간으로 화면에 출력함\n",
    "        # 사용자가 웹캠 화면과 얼굴 인식 결과를 동시에 볼 수 있게 해줌\n",
    "        \n",
    "        # 키보드 입력 처리 - 사용자가 프로그램을 제어할 수 있게 함\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        # cv2.waitKey(1)은 1밀리초 동안 키보드 입력을 기다림\n",
    "        # 1밀리초는 매우 짧은 시간이라 거의 즉시 다음 코드로 넘어감\n",
    "        # 키가 눌리면 해당 키의 ASCII 코드를 반환함\n",
    "        # & 0xFF는 비트 연산으로 키 값을 정확히 추출하기 위함\n",
    "        # key 변수에 눌린 키의 정보가 저장됨\n",
    "        \n",
    "        if key == ord('q'):\n",
    "            # ord('q')는 문자 'q'의 ASCII 코드 값을 반환함 (113)\n",
    "            # 사용자가 'q' 키를 누르면 이 조건이 참이 됨\n",
    "            # 'q'는 quit의 줄임말로 프로그램 종료를 의미함\n",
    "            break\n",
    "            # break는 반복문(while)을 즉시 빠져나감\n",
    "            # 프로그램이 완전히 종료되는 효과를 가져옴\n",
    "            \n",
    "        elif key == ord('s'):\n",
    "            # ord('s')는 문자 's'의 ASCII 코드 값을 반환함 (115)\n",
    "            # 사용자가 's' 키를 누르면 이 조건이 참이 됨\n",
    "            # 's'는 save의 줄임말로 현재 화면을 저장한다는 의미임\n",
    "            \n",
    "            filename = f'face_detection_{current_faces}faces_{int(time.time())}.jpg'\n",
    "            # f-string을 사용해서 파일 이름을 동적으로 생성함\n",
    "            # 'face_detection_'은 파일명의 시작 부분임\n",
    "            # {current_faces}는 현재 검출된 얼굴 개수가 들어감\n",
    "            # 'faces_'는 얼굴 개수 뒤에 붙는 설명 텍스트임\n",
    "            # {int(time.time())}는 현재 시간을 초 단위 정수로 변환한 값임\n",
    "            # time.time()은 1970년 1월 1일부터 현재까지의 초를 반환함\n",
    "            # 이렇게 하면 파일명이 중복되지 않아 덮어쓰기를 방지함\n",
    "            # 최종 파일명 예시: 'face_detection_2faces_1640995200.jpg'\n",
    "            \n",
    "            cv2.imwrite(filename, frame)\n",
    "            # cv2.imwrite()는 이미지를 파일로 저장하는 함수임\n",
    "            # 첫 번째 매개변수는 저장할 파일명임\n",
    "            # 두 번째 매개변수는 저장할 이미지 데이터임\n",
    "            # 현재 화면에 보이는 얼굴 인식 결과를 JPG 파일로 저장함\n",
    "            \n",
    "            print(f\"📸 얼굴 인식 결과 저장: {filename}\")\n",
    "            # 사용자에게 파일이 성공적으로 저장되었음을 알려줌\n",
    "            # 저장된 파일명도 함께 표시해서 어떤 파일인지 확인할 수 있게 함\n",
    "\n",
    "    # ★ 정리 및 결과 요약 ★\n",
    "    cap.release()\n",
    "    # cap.release()는 웹캠 연결을 해제하는 함수임\n",
    "    # 웹캠 리소스를 다른 프로그램이 사용할 수 있도록 반환함\n",
    "    # 이 과정을 거치지 않으면 웹캠이 계속 사용 중인 상태가 됨\n",
    "    # 컴퓨터 자원을 절약하고 다른 프로그램과의 충돌을 방지함\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    # OpenCV로 생성된 모든 창을 닫는 함수임\n",
    "    # 'OpenCV Face Detection Magic' 창이 화면에서 사라짐\n",
    "    # 메모리에서 창 관련 데이터를 완전히 제거함\n",
    "    # 프로그램 종료 시 깔끔하게 정리하는 역할을 함\n",
    "    \n",
    "    avg_faces = face_count_total / frame_count if frame_count > 0 else 0\n",
    "    # 전체 프로그램 실행 동안의 평균 얼굴 개수를 계산함\n",
    "    # face_count_total은 지금까지 검출된 모든 얼굴의 총합임\n",
    "    # frame_count는 처리된 프레임(화면)의 총 개수임\n",
    "    # 나누기 연산으로 프레임당 평균 얼굴 개수를 구함\n",
    "    # if frame_count > 0은 0으로 나누는 오류를 방지하는 조건임\n",
    "    # frame_count가 0이면 0을 반환해서 오류를 막음\n",
    "    \n",
    "    print(f\"✅ 얼굴 인식 체험 완료!\")\n",
    "    # 사용자에게 프로그램이 정상적으로 완료되었음을 알려줌\n",
    "    # 체크마크 이모지로 성공적인 완료를 시각적으로 표현함\n",
    "    \n",
    "    print(f\"📊 총 {frame_count} 프레임 처리, 평균 {avg_faces:.1f}개 얼굴 검출\")\n",
    "    # 프로그램 실행 결과에 대한 통계 정보를 출력함\n",
    "    # frame_count는 처리된 총 프레임 수를 보여줌\n",
    "    # avg_faces:.1f는 평균 얼굴 개수를 소수점 첫째 자리까지 표시함\n",
    "    # 사용자가 얼마나 많은 데이터를 처리했는지 알 수 있게 함\n",
    "\n",
    "# 얼굴 인식 데모 실행\n",
    "face_detection_demo()\n",
    "# 위에서 정의한 face_detection_demo 함수를 실행함\n",
    "# 이 한 줄로 전체 얼굴 인식 프로그램이 시작됨\n",
    "# 함수 호출을 통해 웹캠 시작부터 얼굴 검출까지 모든 과정이 진행됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c8878a",
   "metadata": {},
   "source": [
    "## 📸 5단계: 나만의 미니 포토 에디터 만들기\n",
    "\n",
    "### 🎯 목표\n",
    "지금까지 배운 모든 OpenCV 기법을 종합하여 \n",
    "완전히 동작하는 미니 포토 에디터를 만들어보겠습니다!\n",
    "\n",
    "### 🛠️ 포함된 기능들\n",
    "- **실시간 프리뷰**: 웹캠으로 실시간 확인\n",
    "- **다양한 필터**: 흑백, 블러, 샤픈, 빈티지 등\n",
    "- **색상 조절**: 밝기, 대비, 채도 조정\n",
    "- **특수 효과**: 엣지 검출, 카툰 효과, 유화 효과\n",
    "- **저장 기능**: 다양한 포맷으로 저장\n",
    "- **사용자 인터페이스**: 직관적인 키보드 조작\n",
    "\n",
    "### 🎮 조작 방법\n",
    "**필터 효과**\n",
    "- **1**: 원본\n",
    "- **2**: 흑백 (모노크롬)\n",
    "- **3**: 세피아 (빈티지)\n",
    "- **4**: 블러 (부드럽게)\n",
    "- **5**: 샤픈 (선명하게)\n",
    "- **6**: 엣지 (윤곽선)\n",
    "- **7**: 카툰 효과\n",
    "- **8**: 유화 효과\n",
    "\n",
    "**실시간 조정**\n",
    "- **+/-**: 밝기 조절\n",
    "- **[/]**: 대비 조절  \n",
    "- **;/'**: 채도 조절\n",
    "- **r**: 모든 설정 리셋\n",
    "- **s**: 현재 화면 저장\n",
    "- **q**: 종료\n",
    "\n",
    "### 💡 확장 아이디어\n",
    "이 미니 에디터를 기반으로:\n",
    "- 더 많은 필터 추가\n",
    "- 마우스 조작으로 부분 편집\n",
    "- 여러 이미지 합성 기능\n",
    "- 동영상 편집 기능\n",
    "- 소셜 미디어 연동\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c396a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5단계: 미니 포토 에디터 구현\n",
    "# =============================================================================\n",
    "\n",
    "print(\"📸 5단계: 미니 포토 에디터\")\n",
    "# 📸 카메라 이모지로 사진 편집 프로그램임을 표현함\n",
    "# 5단계로 표시해서 이전 단계들보다 더 고급이고 복합적인 기능임을 명시함\n",
    "# 미니 포토 에디터: 실제 사진 편집 프로그램의 핵심 기능들을 간단하게 구현\n",
    "\n",
    "print(\"=\"*22)\n",
    "# = 문자 22개로 구분선을 만들어서 새로운 고급 섹션의 시작을 표시함\n",
    "\n",
    "class MiniPhotoEditor:\n",
    "   \"\"\"미니 포토 에디터 클래스\"\"\"\n",
    "   # 클래스 정의: 객체지향 프로그래밍의 핵심 개념\n",
    "   # 포토 에디터의 모든 기능과 데이터를 하나의 클래스로 묶어서 관리\n",
    "   # 클래스를 사용하는 이유:\n",
    "   #   1. 코드 구조화: 관련 기능들을 논리적으로 그룹화\n",
    "   #   2. 데이터 캡슐화: 설정값들을 객체 내부에서 안전하게 관리\n",
    "   #   3. 재사용성: 여러 에디터 인스턴스를 독립적으로 생성 가능\n",
    "   #   4. 유지보수성: 기능 추가나 수정이 용이함\n",
    "   \n",
    "   def __init__(self):\n",
    "       \"\"\"에디터 초기화\"\"\"\n",
    "       # __init__ 메서드: 클래스의 생성자 함수\n",
    "       # 객체가 생성될 때 자동으로 호출되어 초기 설정을 담당함\n",
    "       # self: 현재 객체 자신을 가리키는 참조 변수\n",
    "       \n",
    "       self.brightness = 0\n",
    "       # 밝기 조절값을 0으로 초기화 (-100 ~ +100 범위)\n",
    "       # 0: 원본 밝기 유지, 양수: 밝게, 음수: 어둡게\n",
    "       # self.을 붙여서 객체의 인스턴스 변수로 설정\n",
    "       \n",
    "       self.contrast = 1.0\n",
    "       # 대비 조절값을 1.0으로 초기화 (0.5 ~ 3.0 범위)\n",
    "       # 1.0: 원본 대비 유지, 1.0 초과: 대비 증가, 1.0 미만: 대비 감소\n",
    "       \n",
    "       self.saturation = 1.0\n",
    "       # 채도 조절값을 1.0으로 초기화 (0.0 ~ 2.0 범위)\n",
    "       # 1.0: 원본 채도 유지, 1.0 초과: 채도 증가, 1.0 미만: 채도 감소\n",
    "       # 0.0: 완전 무채색(흑백), 2.0: 매우 선명한 색상\n",
    "       \n",
    "       self.current_filter = 1\n",
    "       # 현재 적용된 필터 번호를 1(원본)로 초기화\n",
    "       # 1~8까지의 숫자로 서로 다른 필터를 구분함\n",
    "       \n",
    "       self.saved_count = 0\n",
    "       # 저장된 이미지 수를 0으로 초기화\n",
    "       # 사용자가 's' 키를 눌러 저장할 때마다 증가\n",
    "       # 통계 정보와 파일명 생성에 활용\n",
    "       \n",
    "       # 필터 이름 딕셔너리\n",
    "       self.filter_names = {\n",
    "           1: \"Original\",        # 원본 (필터 없음)\n",
    "           2: \"Grayscale\",       # 흑백 변환\n",
    "           3: \"Sepia\",           # 세피아 톤 (빈티지 느낌)\n",
    "           4: \"Blur\",            # 블러 (흐림 효과)\n",
    "           5: \"Sharpen\",         # 샤프닝 (선명하게)\n",
    "           6: \"Edge Detection\",  # 엣지 검출 (윤곽선 추출)\n",
    "           7: \"Cartoon\",         # 카툰 효과\n",
    "           8: \"Oil Painting\"     # 유화 효과\n",
    "       }\n",
    "       # 딕셔너리로 필터 번호와 이름을 매핑\n",
    "       # 사용자 인터페이스에서 현재 필터 이름을 표시할 때 사용\n",
    "       # 번호 대신 의미있는 이름으로 사용자 경험 향상\n",
    "   \n",
    "   def adjust_brightness_contrast(self, image, brightness=0, contrast=1.0):\n",
    "       \"\"\"밝기와 대비 조절\"\"\"\n",
    "       # 밝기와 대비를 동시에 조절하는 메서드\n",
    "       # 매개변수:\n",
    "       #   image: 조절할 원본 이미지\n",
    "       #   brightness: 밝기 조절값 (기본값 0)\n",
    "       #   contrast: 대비 조절값 (기본값 1.0)\n",
    "       \n",
    "       # OpenCV 공식: new_image = α * image + β\n",
    "       # α는 대비(contrast): 픽셀값에 곱해지는 계수\n",
    "       # β는 밝기(brightness): 픽셀값에 더해지는 상수\n",
    "       # 이 공식으로 선형 변환을 통해 밝기와 대비를 동시에 조절\n",
    "       \n",
    "       adjusted = cv2.convertScaleAbs(image, alpha=contrast, beta=brightness)\n",
    "       # cv2.convertScaleAbs(): 스케일링과 절댓값 변환을 동시에 수행\n",
    "       # alpha=contrast: 대비 조절 (곱셈 계수)\n",
    "       # beta=brightness: 밝기 조절 (덧셈 상수)\n",
    "       # 자동으로 0~255 범위로 클리핑되어 오버플로우 방지\n",
    "       \n",
    "       return adjusted\n",
    "       # 조절된 이미지를 반환\n",
    "   \n",
    "   def adjust_saturation(self, image, saturation=1.0):\n",
    "       \"\"\"채도 조절\"\"\"\n",
    "       # 채도만 독립적으로 조절하는 메서드\n",
    "       # HSV 색상 공간을 이용해서 색상과 밝기는 유지하고 채도만 변경\n",
    "       \n",
    "       # BGR을 HSV로 변환\n",
    "       hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV).astype(np.float32)\n",
    "       # BGR → HSV 색상 공간 변환\n",
    "       # astype(np.float32): 정밀한 계산을 위해 부동소수점으로 변환\n",
    "       # HSV에서 S(Saturation) 채널이 채도를 담당함\n",
    "       \n",
    "       # S(채도) 채널에만 조절값 적용\n",
    "       hsv[:, :, 1] *= saturation\n",
    "       # [:, :, 1]: 모든 픽셀의 S(채도) 채널 선택\n",
    "       # saturation 값을 곱해서 채도 조절\n",
    "       # 1.0 초과: 채도 증가 (더 선명한 색상)\n",
    "       # 1.0 미만: 채도 감소 (더 흐린 색상)\n",
    "       \n",
    "       hsv[:, :, 1] = np.clip(hsv[:, :, 1], 0, 255)\n",
    "       # np.clip()으로 값의 범위를 0~255로 제한\n",
    "       # 채도 증가 시 255를 초과하지 않도록 보장\n",
    "       # 채도 감소 시 0 미만으로 내려가지 않도록 보장\n",
    "       \n",
    "       # 다시 BGR로 변환\n",
    "       hsv = hsv.astype(np.uint8)\n",
    "       # 정수형으로 다시 변환 (OpenCV 이미지 표준 형식)\n",
    "       \n",
    "       adjusted = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "       # HSV → BGR 색상 공간 변환으로 최종 결과 생성\n",
    "       \n",
    "       return adjusted\n",
    "       # 채도가 조절된 이미지를 반환\n",
    "   \n",
    "   def apply_sepia_filter(self, image):\n",
    "       \"\"\"세피아 필터 (빈티지 느낌)\"\"\"\n",
    "       # 세피아 톤: 오래된 사진의 갈색빛 느낌을 재현하는 필터\n",
    "       # 따뜻하고 향수를 불러일으키는 빈티지 효과\n",
    "       \n",
    "       # 세피아 변환 행렬\n",
    "       sepia_kernel = np.array([[0.272, 0.534, 0.131],\n",
    "                               [0.349, 0.686, 0.168],\n",
    "                               [0.393, 0.769, 0.189]])\n",
    "       # 3x3 변환 행렬로 BGR 각 채널의 가중합을 계산\n",
    "       # 각 행은 새로운 B, G, R 값을 계산하는 공식\n",
    "       # 예: 새로운 B = 0.272*B + 0.534*G + 0.131*R\n",
    "       # 이 계수들은 자연스러운 세피아 톤을 만들기 위해 최적화된 값\n",
    "       \n",
    "       sepia_image = cv2.transform(image, sepia_kernel)\n",
    "       # cv2.transform()으로 변환 행렬을 이미지에 적용\n",
    "       # 모든 픽셀에 대해 행렬 곱셈을 수행해서 색상 변환\n",
    "       \n",
    "       sepia_image = np.clip(sepia_image, 0, 255)\n",
    "       # 계산 결과가 0~255 범위를 벗어날 수 있으므로 클리핑\n",
    "       \n",
    "       return sepia_image.astype(np.uint8)\n",
    "       # 정수형으로 변환해서 표준 이미지 형식으로 반환\n",
    "   \n",
    "   def apply_sharpen_filter(self, image):\n",
    "       \"\"\"샤프닝 필터 (선명하게)\"\"\"\n",
    "       # 샤프닝: 이미지의 경계선을 강조해서 더 선명하게 만드는 필터\n",
    "       # 흐릿한 이미지를 개선하거나 세부사항을 강조할 때 사용\n",
    "       \n",
    "       # 샤프닝 커널\n",
    "       sharpen_kernel = np.array([[-1, -1, -1],\n",
    "                                 [-1,  9, -1],\n",
    "                                 [-1, -1, -1]])\n",
    "       # 3x3 컨볼루션 커널 (필터 마스크)\n",
    "       # 중앙값 9: 현재 픽셀을 강조\n",
    "       # 주변값 -1: 주변 픽셀들을 빼서 차이를 증폭\n",
    "       # 결과: 경계선에서 명암 차이가 더 크게 나타남\n",
    "       # 전체 합이 1이므로 전체 밝기는 유지됨\n",
    "       \n",
    "       sharpened = cv2.filter2D(image, -1, sharpen_kernel)\n",
    "       # cv2.filter2D()로 커널을 이미지에 적용\n",
    "       # -1: 출력 이미지의 깊이를 입력과 동일하게 유지\n",
    "       # 각 픽셀에 대해 3x3 영역과 커널의 곱셈 합을 계산\n",
    "       \n",
    "       return sharpened\n",
    "       # 선명하게 처리된 이미지를 반환\n",
    "   \n",
    "   def apply_cartoon_filter(self, image):\n",
    "       \"\"\"카툰 효과 필터\"\"\"\n",
    "       # 카툰 효과: 실제 사진을 만화 같은 느낌으로 변환하는 필터\n",
    "       # 색상을 단순화하고 경계선을 강조해서 일러스트 같은 효과 생성\n",
    "       \n",
    "       # 1. 양방향 필터로 부드럽게 만들기\n",
    "       bilateral = cv2.bilateralFilter(image, 15, 40, 40)\n",
    "       # cv2.bilateralFilter(): 엣지는 보존하면서 노이즈만 제거하는 스마트 필터\n",
    "       # 15: 필터 크기 (처리할 이웃 픽셀 범위)\n",
    "       # 40, 40: 색상 차이와 공간 거리 임계값\n",
    "       # 효과: 평면적인 영역은 매끄럽게, 경계선은 선명하게 유지\n",
    "       \n",
    "       # 2. 엣지 검출\n",
    "       gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "       # 엣지 검출을 위해 흑백으로 변환\n",
    "       \n",
    "       gray_blur = cv2.medianBlur(gray, 3)\n",
    "       # 미디언 블러로 노이즈 제거 (엣지 검출 정확도 향상)\n",
    "       \n",
    "       edges = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "                                    cv2.THRESH_BINARY, 7, 7)\n",
    "       # 적응적 임계값으로 엣지 검출\n",
    "       # 지역별로 다른 임계값을 사용해서 조명 변화에 강함\n",
    "       # 7, 7: 블록 크기와 상수값 (미세 조정 매개변수)\n",
    "       \n",
    "       # 3. 엣지를 3채널로 변환\n",
    "       edges = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
    "       # 흑백 엣지를 3채널로 변환해서 컬러 이미지와 합성 가능하게 함\n",
    "       \n",
    "       # 4. 부드러운 이미지와 엣지 결합\n",
    "       cartoon = cv2.bitwise_and(bilateral, edges)\n",
    "       # 비트 AND 연산으로 두 이미지 결합\n",
    "       # 엣지가 있는 부분만 컬러가 남고 나머지는 검게 됨\n",
    "       # 결과: 만화책의 선화 같은 효과\n",
    "       \n",
    "       return cartoon\n",
    "       # 카툰 효과가 적용된 이미지를 반환\n",
    "   \n",
    "   def apply_oil_painting_filter(self, image):\n",
    "       \"\"\"유화 효과 필터\"\"\"\n",
    "       # 유화 효과: 디지털 사진을 전통 유화 그림 같은 느낌으로 변환\n",
    "       # 붓터치와 색상 혼합 효과를 시뮬레이션\n",
    "       \n",
    "       # OpenCV의 엣지 보존 필터를 여러 번 적용\n",
    "       oil_painting = image.copy()\n",
    "       # 원본을 복사해서 단계별 처리\n",
    "       \n",
    "       # 여러 번의 양방향 필터 적용\n",
    "       for _ in range(3):\n",
    "           # 3번 반복해서 점진적으로 부드럽게 만듦\n",
    "           oil_painting = cv2.bilateralFilter(oil_painting, 9, 200, 200)\n",
    "           # 각 단계마다 양방향 필터 적용\n",
    "           # 9: 작은 커널로 세밀한 처리\n",
    "           # 200, 200: 높은 임계값으로 강한 평활화\n",
    "           # 반복할수록 유화의 붓터치 같은 효과 증가\n",
    "       \n",
    "       # 색상 양자화 (색상 수 줄이기)\n",
    "       data = oil_painting.reshape((-1, 3))\n",
    "       # 이미지를 1차원 배열로 변환 (각 픽셀이 하나의 점)\n",
    "       # -1: 자동으로 픽셀 수 계산, 3: BGR 3채널\n",
    "       \n",
    "       data = np.float32(data)\n",
    "       # k-means 클러스터링을 위해 부동소수점으로 변환\n",
    "       \n",
    "       criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "       # k-means 종료 조건 설정\n",
    "       # 정확도 또는 최대 반복 횟수에 도달하면 종료\n",
    "       \n",
    "       k = 8\n",
    "       # 색상을 8가지로 제한 (유화의 제한된 팔레트 효과)\n",
    "       \n",
    "       _, labels, centers = cv2.kmeans(data, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "       # k-means 클러스터링으로 색상 그룹화\n",
    "       # 비슷한 색상들을 하나의 대표 색상으로 통합\n",
    "       # centers: 각 클러스터의 중심색상 (대표 색상)\n",
    "       # labels: 각 픽셀이 어느 클러스터에 속하는지 정보\n",
    "       \n",
    "       centers = np.uint8(centers)\n",
    "       # 클러스터 중심을 정수형으로 변환\n",
    "       \n",
    "       quantized_data = centers[labels.flatten()]\n",
    "       # 각 픽셀을 해당 클러스터의 대표 색상으로 변경\n",
    "       # 결과: 원본의 수만 가지 색상이 8가지로 단순화\n",
    "       \n",
    "       quantized_image = quantized_data.reshape(oil_painting.shape)\n",
    "       # 1차원 배열을 다시 원본 이미지 형태로 변환\n",
    "       \n",
    "       return quantized_image\n",
    "       # 유화 효과가 적용된 이미지를 반환\n",
    "   \n",
    "   def apply_filter(self, image, filter_number):\n",
    "       \"\"\"선택된 필터 적용\"\"\"\n",
    "       # 필터 번호에 따라 해당하는 필터를 적용하는 통합 메서드\n",
    "       # 사용자 인터페이스에서 호출되는 메인 필터 적용 함수\n",
    "       \n",
    "       if filter_number == 1:\n",
    "           # 원본: 아무 처리도 하지 않음\n",
    "           return image.copy()\n",
    "           # copy()로 원본을 보호하면서 복사본 반환\n",
    "           \n",
    "       elif filter_number == 2:\n",
    "           # 흑백 변환\n",
    "           gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "           # BGR → GRAY 색상 공간 변환\n",
    "           return cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "           # GRAY → BGR 변환으로 3채널 형식 유지 (UI 호환성)\n",
    "           \n",
    "       elif filter_number == 3:\n",
    "           # 세피아 톤 적용\n",
    "           return self.apply_sepia_filter(image)\n",
    "           # 위에서 정의한 세피아 필터 메서드 호출\n",
    "           \n",
    "       elif filter_number == 4:\n",
    "           # 가우시안 블러 적용\n",
    "           return cv2.GaussianBlur(image, (15, 15), 0)\n",
    "           # 간단한 블러 효과 (부드러운 느낌)\n",
    "           \n",
    "       elif filter_number == 5:\n",
    "           # 샤프닝 적용\n",
    "           return self.apply_sharpen_filter(image)\n",
    "           # 위에서 정의한 샤프닝 필터 메서드 호출\n",
    "           \n",
    "       elif filter_number == 6:\n",
    "           # 엣지 검출 적용\n",
    "           gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "           edges = cv2.Canny(gray, 100, 200)\n",
    "           return cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
    "           # Canny 엣지 검출로 윤곽선만 추출\n",
    "           \n",
    "       elif filter_number == 7:\n",
    "           # 카툰 효과 적용\n",
    "           return self.apply_cartoon_filter(image)\n",
    "           # 위에서 정의한 카툰 필터 메서드 호출\n",
    "           \n",
    "       elif filter_number == 8:\n",
    "           # 유화 효과 적용\n",
    "           return self.apply_oil_painting_filter(image)\n",
    "           # 위에서 정의한 유화 필터 메서드 호출\n",
    "           \n",
    "       else:\n",
    "           # 예상치 못한 번호인 경우 원본 반환 (안전장치)\n",
    "           return image.copy()\n",
    "   \n",
    "   def draw_ui(self, image):\n",
    "       \"\"\"사용자 인터페이스 오버레이 그리기\"\"\"\n",
    "       # 이미지 위에 현재 설정과 조작 방법을 표시하는 UI 그리기\n",
    "       # 사용자가 현재 상태를 쉽게 파악할 수 있도록 도움\n",
    "       \n",
    "       # 반투명 정보 패널 배경\n",
    "       overlay = image.copy()\n",
    "       # 원본 이미지를 복사해서 오버레이 작업용으로 사용\n",
    "       \n",
    "       cv2.rectangle(overlay, (10, 10), (400, 200), (0, 0, 0), -1)\n",
    "       # 검은색 배경 사각형 그리기\n",
    "       # (10, 10)에서 (400, 200)까지 영역\n",
    "       # (0, 0, 0): 검은색\n",
    "       # -1: 내부를 채움 (실심 사각형)\n",
    "       \n",
    "       cv2.addWeighted(overlay, 0.7, image, 0.3, 0, image)\n",
    "       # 반투명 효과 적용\n",
    "       # overlay: 70% 불투명도\n",
    "       # image: 30% 불투명도\n",
    "       # 결과: 텍스트는 읽기 쉽지만 배경 이미지도 어느 정도 보임\n",
    "       \n",
    "       # 현재 설정 정보 표시\n",
    "       info_texts = [\n",
    "           f'Filter: {self.filter_names[self.current_filter]}',\n",
    "           # 현재 적용된 필터 이름 표시\n",
    "           f'Brightness: {self.brightness:+d}',\n",
    "           # 밝기 값 (+/- 부호 포함해서 표시)\n",
    "           f'Contrast: {self.contrast:.1f}',\n",
    "           # 대비 값 (소수점 첫째 자리까지)\n",
    "           f'Saturation: {self.saturation:.1f}',\n",
    "           # 채도 값 (소수점 첫째 자리까지)\n",
    "           f'Saved: {self.saved_count} images',\n",
    "           # 지금까지 저장한 이미지 수\n",
    "           '',\n",
    "           # 빈 줄로 구분\n",
    "           'Controls:',\n",
    "           # 조작 방법 섹션 제목\n",
    "           '1-8: Filters',\n",
    "           # 숫자키로 필터 변경\n",
    "           '+/-: Brightness',\n",
    "           # +/- 키로 밝기 조절\n",
    "           '[/]: Contrast',\n",
    "           # [/] 키로 대비 조절\n",
    "           ';/\\': Saturation',\n",
    "           # ;/' 키로 채도 조절\n",
    "           'r: Reset, s: Save, q: Quit'\n",
    "           # 기타 주요 키 기능\n",
    "       ]\n",
    "       \n",
    "       for i, text in enumerate(info_texts):\n",
    "           # enumerate()로 인덱스와 텍스트를 동시에 가져옴\n",
    "           color = (0, 255, 255) if i < 5 else (255, 255, 255)\n",
    "           # 설정값 (처음 5줄)은 노란색, 조작법은 흰색으로 구분\n",
    "           # 시각적으로 정보의 종류를 쉽게 구분할 수 있게 함\n",
    "           \n",
    "           cv2.putText(image, text, (15, 30 + i * 15), \n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n",
    "           # 각 줄을 15픽셀 간격으로 배치해서 정리된 느낌\n",
    "           # 0.4: 작은 폰트로 많은 정보를 깔끔하게 표시\n",
    "           # 1: 얇은 텍스트 두께로 배경 이미지 방해 최소화\n",
    "   \n",
    "   def reset_settings(self):\n",
    "       \"\"\"모든 설정을 기본값으로 리셋\"\"\"\n",
    "       # 사용자가 'r' 키를 눌렀을 때 모든 조절값을 원래대로 되돌리는 기능\n",
    "       # 실험하다가 원본으로 돌아가고 싶을 때 유용함\n",
    "       \n",
    "       self.brightness = 0\n",
    "       # 밝기를 기본값 0으로 리셋\n",
    "       self.contrast = 1.0\n",
    "       # 대비를 기본값 1.0으로 리셋\n",
    "       self.saturation = 1.0\n",
    "       # 채도를 기본값 1.0으로 리셋\n",
    "       self.current_filter = 1\n",
    "       # 필터를 원본(1번)으로 리셋\n",
    "       print(\"🔄 모든 설정이 리셋되었습니다!\")\n",
    "       # 🔄 새로고침 이모지로 리셋 완료를 알림\n",
    "   \n",
    "   def run(self):\n",
    "       \"\"\"미니 포토 에디터 실행\"\"\"\n",
    "       # 메인 실행 함수: 포토 에디터의 전체 동작을 관리\n",
    "       # 웹캠 연결부터 사용자 인터랙션까지 모든 과정을 포함\n",
    "       \n",
    "       # 웹캠 연결\n",
    "       cap = cv2.VideoCapture(0)\n",
    "       # 기본 웹캠(0번)에 연결 시도\n",
    "       \n",
    "       if not cap.isOpened():\n",
    "           # 웹캠 연결 실패 시 처리\n",
    "           print(\"❌ 웹캠을 열 수 없습니다!\")\n",
    "           return\n",
    "           # 웹캠 없이는 실행할 수 없으므로 함수 종료\n",
    "       \n",
    "       # 웹캠 해상도 설정\n",
    "       cap.set(cv2.CAP_PROP_FRAME_WIDTH, 800)\n",
    "       cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 600)\n",
    "       # 800x600 해상도로 설정해서 적당한 화질과 처리 속도 균형\n",
    "       \n",
    "       print(\"🎨 미니 포토 에디터 시작!\")\n",
    "       print(\"📱 숫자키로 필터 변경, +/-로 밝기 조절\")\n",
    "       print(\"📷 's'키로 저장, 'q'키로 종료\")\n",
    "       # 🎨 팔레트 이모지로 에디터 시작을 표현\n",
    "       # 📱 📷 이모지로 주요 조작 방법을 직관적으로 안내\n",
    "       \n",
    "       while True:\n",
    "           # 무한 루프로 실시간 편집 환경 제공\n",
    "           ret, frame = cap.read()\n",
    "           # 웹캠에서 현재 프레임 읽기\n",
    "           \n",
    "           if not ret:\n",
    "               # 프레임 읽기 실패 시 루프 종료\n",
    "               break\n",
    "           \n",
    "           # 거울 효과\n",
    "           frame = cv2.flip(frame, 1)\n",
    "           # 좌우 반전으로 자연스러운 셀카 모드 구현\n",
    "           \n",
    "           # 1. 선택된 필터 적용\n",
    "           filtered_frame = self.apply_filter(frame, self.current_filter)\n",
    "           # 사용자가 선택한 필터를 먼저 적용\n",
    "           \n",
    "           # 2. 밝기/대비 조절 적용\n",
    "           adjusted_frame = self.adjust_brightness_contrast(\n",
    "               filtered_frame, self.brightness, self.contrast)\n",
    "           # 필터가 적용된 이미지에 밝기와 대비 조절 적용\n",
    "           \n",
    "           # 3. 채도 조절 적용\n",
    "           final_frame = self.adjust_saturation(adjusted_frame, self.saturation)\n",
    "           # 마지막으로 채도 조절을 적용해서 최종 이미지 생성\n",
    "           \n",
    "           # 4. UI 오버레이 그리기\n",
    "           self.draw_ui(final_frame)\n",
    "           # 최종 이미지 위에 사용자 인터페이스 표시\n",
    "           \n",
    "           # 화면에 표시\n",
    "           cv2.imshow('Mini Photo Editor', final_frame)\n",
    "           # 모든 처리가 완료된 최종 이미지를 화면에 출력\n",
    "           \n",
    "           # 키 입력 처리\n",
    "           key = cv2.waitKey(1) & 0xFF\n",
    "           # 1ms 대기로 실시간 반응성 유지\n",
    "           \n",
    "           if key == ord('q'):\n",
    "               # 'q' 키: 프로그램 종료\n",
    "               break\n",
    "               \n",
    "           elif key in [ord(str(i)) for i in range(1, 9)]:\n",
    "               # 숫자키 1~8: 필터 변경\n",
    "               # [ord(str(i)) for i in range(1, 9)]: 1~8의 ASCII 코드 리스트 생성\n",
    "               # 예: [49, 50, 51, 52, 53, 54, 55, 56] (문자 '1'~'8'의 ASCII 값)\n",
    "               # key in [...]: 눌린 키가 1~8 중 하나인지 확인\n",
    "               \n",
    "               self.current_filter = int(chr(key))\n",
    "               # chr(key): ASCII 코드를 문자로 변환 (예: 49 → '1')\n",
    "               # int(): 문자를 정수로 변환 (예: '1' → 1)\n",
    "               # 결과: 눌린 숫자키에 해당하는 필터 번호로 설정\n",
    "               \n",
    "               print(f\"🎭 필터 변경: {self.filter_names[self.current_filter]}\")\n",
    "               # 🎭 마스크 이모지로 필터 변경을 표현\n",
    "               # 딕셔너리에서 필터 번호에 해당하는 이름을 찾아서 출력\n",
    "               \n",
    "           elif key == ord('=') or key == ord('+'):\n",
    "               # '=' 또는 '+' 키: 밝기 증가\n",
    "               # ord('=') = 61, ord('+') = 43\n",
    "               # 두 키 모두 처리하는 이유: 키보드 배치에 따라 다를 수 있음\n",
    "               \n",
    "               self.brightness = min(100, self.brightness + 10)\n",
    "               # min()으로 최대값 100을 넘지 않도록 제한\n",
    "               # 10씩 증가해서 적당한 조절 단위 제공\n",
    "               # 너무 작으면 변화를 느끼기 어렵고, 너무 크면 조절이 거침\n",
    "               \n",
    "               print(f\"☀️ 밝기: {self.brightness:+d}\")\n",
    "               # ☀️ 태양 이모지로 밝기 증가를 표현\n",
    "               # :+d 포맷으로 양수일 때 + 부호 표시 (예: +20)\n",
    "               \n",
    "           elif key == ord('-'):\n",
    "               # '-' 키: 밝기 감소\n",
    "               self.brightness = max(-100, self.brightness - 10)\n",
    "               # max()로 최소값 -100을 밑돌지 않도록 제한\n",
    "               # 10씩 감소해서 일관된 조절 단위 유지\n",
    "               \n",
    "               print(f\"🌙 밝기: {self.brightness:+d}\")\n",
    "               # 🌙 달 이모지로 밝기 감소를 표현\n",
    "               # 음수일 때는 자동으로 - 부호 표시 (예: -30)\n",
    "               \n",
    "           elif key == ord(']'):\n",
    "               # ']' 키: 대비 증가\n",
    "               self.contrast = min(3.0, self.contrast + 0.1)\n",
    "               # 최대값 3.0까지 제한 (너무 높으면 이미지가 너무 극명해짐)\n",
    "               # 0.1씩 증가해서 세밀한 조절 가능\n",
    "               \n",
    "               print(f\"📈 대비: {self.contrast:.1f}\")\n",
    "               # 📈 상승 차트 이모지로 대비 증가 표현\n",
    "               # :.1f 포맷으로 소수점 첫째 자리까지 표시\n",
    "               \n",
    "           elif key == ord('['):\n",
    "               # '[' 키: 대비 감소\n",
    "               self.contrast = max(0.5, self.contrast - 0.1)\n",
    "               # 최소값 0.5까지 제한 (너무 낮으면 이미지가 너무 흐려짐)\n",
    "               # 0.1씩 감소해서 대비 증가와 동일한 조절 단위\n",
    "               \n",
    "               print(f\"📉 대비: {self.contrast:.1f}\")\n",
    "               # 📉 하락 차트 이모지로 대비 감소 표현\n",
    "               \n",
    "           elif key == ord(\"'\"):\n",
    "               # ''' (작은따옴표) 키: 채도 증가\n",
    "               # 키보드에서 ;와 '는 보통 같은 키에 있어서 Shift 누르면 '\n",
    "               self.saturation = min(2.0, self.saturation + 0.1)\n",
    "               # 최대값 2.0까지 제한 (너무 높으면 색상이 부자연스러워짐)\n",
    "               # 0.1씩 증가해서 채도를 세밀하게 조절\n",
    "               \n",
    "               print(f\"🌈 채도: {self.saturation:.1f}\")\n",
    "               # 🌈 무지개 이모지로 채도 증가 (더 선명한 색상) 표현\n",
    "               \n",
    "           elif key == ord(';'):\n",
    "               # ';' (세미콜론) 키: 채도 감소\n",
    "               self.saturation = max(0.0, self.saturation - 0.1)\n",
    "               # 최소값 0.0까지 제한 (0.0이면 완전 무채색/흑백)\n",
    "               # 0.1씩 감소해서 채도 증가와 동일한 조절 단위\n",
    "               \n",
    "               print(f\"🎨 채도: {self.saturation:.1f}\")\n",
    "               # 🎨 팔레트 이모지로 채도 감소 (더 흐린 색상) 표현\n",
    "               \n",
    "           elif key == ord('r'):\n",
    "               # 'r' 키: 모든 설정 리셋\n",
    "               self.reset_settings()\n",
    "               # 위에서 정의한 리셋 메서드 호출\n",
    "               # 밝기, 대비, 채도, 필터를 모두 기본값으로 되돌림\n",
    "               \n",
    "           elif key == ord('s'):\n",
    "               # 's' 키: 현재 화면 저장\n",
    "               self.saved_count += 1\n",
    "               # 저장 횟수를 1 증가시켜서 통계 관리\n",
    "               \n",
    "               filename = f'photo_editor_{self.filter_names[self.current_filter]}_{self.saved_count}_{int(time.time())}.jpg'\n",
    "               # 파일명 구성 요소:\n",
    "               #   'photo_editor_': 프로그램 식별자\n",
    "               #   {self.filter_names[self.current_filter]}: 현재 필터 이름\n",
    "               #   {self.saved_count}: 저장 순서 번호\n",
    "               #   {int(time.time())}: 타임스탬프 (중복 방지)\n",
    "               #   '.jpg': 파일 확장자\n",
    "               # 예: 'photo_editor_Sepia_3_1640995200.jpg'\n",
    "               \n",
    "               cv2.imwrite(filename, final_frame)\n",
    "               # cv2.imwrite()로 UI가 포함된 최종 이미지를 파일로 저장\n",
    "               # 사용자가 보고 있는 그대로의 모습이 저장됨\n",
    "               \n",
    "               print(f\"📸 저장 완료: {filename}\")\n",
    "               # 📸 카메라 이모지로 저장 완료를 알리고 파일명 표시\n",
    "       \n",
    "       # 정리\n",
    "       cap.release()\n",
    "       # 웹캠 자원을 해제해서 다른 프로그램이 사용할 수 있게 함\n",
    "       \n",
    "       cv2.destroyAllWindows()\n",
    "       # 모든 OpenCV 창을 닫고 메모리 정리\n",
    "       \n",
    "       print(f\"✅ 미니 포토 에디터 종료! 총 {self.saved_count}장 저장됨\")\n",
    "       # ✅ 체크마크로 성공적인 종료를 표시\n",
    "       # 최종 통계로 총 저장한 이미지 수를 알려줌\n",
    "\n",
    "# 미니 포토 에디터 인스턴스 생성 및 실행\n",
    "editor = MiniPhotoEditor()\n",
    "# MiniPhotoEditor 클래스의 인스턴스(객체)를 생성\n",
    "# __init__ 메서드가 자동으로 호출되어 초기화 수행\n",
    "\n",
    "editor.run()\n",
    "# 생성된 에디터 객체의 run() 메서드를 호출해서 프로그램 시작\n",
    "# 이 한 줄로 전체 포토 에디터 기능이 작동함\n",
    "\n",
    "# 💡 이 코드에서 배우는 핵심 개념들:\n",
    "# 1. 객체지향 프로그래밍의 기본 개념과 클래스 설계 방법\n",
    "# 2. 실시간 이미지 처리를 위한 다양한 필터 알고리즘 구현\n",
    "# 3. 사용자 인터페이스 설계와 직관적인 조작 방법 제공\n",
    "# 4. 이미지 편집의 기본 원리 (밝기, 대비, 채도 조절)\n",
    "# 5. 고급 이미지 처리 기법 (세피아, 카툰, 유화 효과 등)\n",
    "# 6. 실제 포토 에디터 프로그램의 구조와 동작 원리\n",
    "# 7. 컴퓨터 비전과 이미지 처리의 실무 적용 사례    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ca6ac1",
   "metadata": {},
   "source": [
    "## 🎉 축하합니다! OpenCV 체험 학습 완료!\n",
    "\n",
    "### 🏆 오늘 여러분이 성취한 것들\n",
    "1. **✅ OpenCV 기초**: 이미지 생성, 조작, 표시\n",
    "2. **✅ 실시간 영상 처리**: 웹캠 활용 및 다양한 필터 적용\n",
    "3. **✅ 고급 이미지 변환**: 색상 공간, 히스토그램, 노이즈 제거\n",
    "4. **✅ 얼굴 인식**: AI 기반 객체 검출 체험\n",
    "5. **✅ 완전한 프로젝트**: 미니 포토 에디터 구현\n",
    "\n",
    "### 🚀 이제 여러분은...\n",
    "- 컴퓨터 비전의 기본 원리를 이해했습니다\n",
    "- 실시간 이미지 처리 시스템을 만들 수 있습니다\n",
    "- AI와 OpenCV를 연동할 준비가 되었습니다\n",
    "- 더 복잡한 컴퓨터 비전 프로젝트에 도전할 수 있습니다\n",
    "\n",
    "### 💡 다음 단계 추천\n",
    "**초급 프로젝트**\n",
    "- 간단한 보안 카메라 시스템\n",
    "- 색상 기반 객체 추적기\n",
    "- QR 코드 리더기\n",
    "- 간단한 문서 스캐너\n",
    "\n",
    "**중급 프로젝트**  \n",
    "- 손 제스처 인식기\n",
    "- 차선 검출 시스템\n",
    "- 얼굴 표정 분석기\n",
    "- 실시간 배경 제거\n",
    "\n",
    "**고급 프로젝트**\n",
    "- 증강현실 (AR) 앱\n",
    "- 의료 영상 분석 도구\n",
    "- 자율주행 시뮬레이션\n",
    "- 산업용 품질 검사 시스템\n",
    "\n",
    "### 📚 추천 학습 자료\n",
    "- **OpenCV 공식 문서**: [opencv.org](https://opencv.org/)\n",
    "- **PyImageSearch**: 실용적인 컴퓨터 비전 튜토리얼\n",
    "- **YouTube**: \"OpenCV Python Tutorial\" 시리즈\n",
    "- **GitHub**: OpenCV 예제 프로젝트들\n",
    "\n",
    "### 🔗 실무 연결고리\n",
    "오늘 배운 기술들은 실제로:\n",
    "- **테슬라**: 자율주행 시스템\n",
    "- **인스타그램**: 필터와 AR 효과  \n",
    "- **구글**: 이미지 검색 및 분석\n",
    "- **삼성**: 스마트폰 카메라 AI\n",
    "- **병원**: 의료 영상 진단 시스템\n",
    "\n",
    "에서 핵심 기술로 사용되고 있습니다!\n",
    "\n",
    "### 🎯 마지막 도전과제\n",
    "여러분만의 창의적인 OpenCV 프로젝트를 기획해보세요:\n",
    "1. 어떤 문제를 해결하고 싶나요?\n",
    "2. 어떤 OpenCV 기능을 사용할 건가요?\n",
    "3. 사용자는 어떻게 상호작용할 건가요?\n",
    "\n",
    "### 👨‍💻 개발자로서의 첫걸음\n",
    "컴퓨터 비전은 AI 시대의 핵심 기술입니다. \n",
    "오늘의 경험이 여러분을 미래의 AI 개발자로 이끌어줄 것입니다!\n",
    "\n",
    "**Keep coding, keep exploring! 🚀✨**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87afbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 코드 셀 7: 마무리 및 정리\n",
    "# =============================================================================\n",
    "\n",
    "print(\"🎉 OpenCV 체험 학습 완료!\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# 오늘 학습한 내용 요약\n",
    "print(\"📋 오늘 학습한 OpenCV 기능들:\")\n",
    "features_learned = [\n",
    "    \"✅ 기본 이미지 생성 및 조작\",\n",
    "    \"✅ 도형 그리기 및 텍스트 추가\", \n",
    "    \"✅ 웹캠 실시간 영상 처리\",\n",
    "    \"✅ 다양한 필터 효과 적용\",\n",
    "    \"✅ 색상 공간 변환 및 조작\",\n",
    "    \"✅ 히스토그램 평활화\",\n",
    "    \"✅ 노이즈 제거 필터\",\n",
    "    \"✅ 실시간 얼굴 인식\",\n",
    "    \"✅ 눈 검출 및 특징점 인식\",\n",
    "    \"✅ 완전한 포토 에디터 구현\"\n",
    "]\n",
    "\n",
    "for feature in features_learned:\n",
    "    print(f\"  {feature}\")\n",
    "\n",
    "print(f\"\\n📊 학습 통계:\")\n",
    "print(f\"  🎯 총 기능 수: {len(features_learned)}개\")\n",
    "print(f\"  📱 실습 프로젝트: 5개\")\n",
    "print(f\"  🚀 완성도: 100%\")\n",
    "\n",
    "print(f\"\\n🏆 축하합니다!\")\n",
    "print(\"  여러분은 이제 OpenCV로 기본적인 컴퓨터 비전\")\n",
    "print(\"  시스템을 구축할 수 있는 능력을 갖추었습니다!\")\n",
    "\n",
    "print(f\"\\n🔮 다음 학습 권장사항:\")\n",
    "print(\"  1. YOLO와 OpenCV 연동하여 고급 객체 인식 시스템 구축\")\n",
    "print(\"  2. 딥러닝 모델과 OpenCV 결합한 프로젝트 진행\") \n",
    "print(\"  3. 실시간 영상 스트리밍 및 네트워크 전송 학습\")\n",
    "print(\"  4. 산업용 컴퓨터 비전 솔루션 개발 도전\")\n",
    "\n",
    "print(f\"\\n🌟 Keep exploring the world of Computer Vision! 🚀\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 추가 리소스 및 참고 자료\n",
    "print(\"\\n📖 추가 학습 리소스:\")\n",
    "resources = {\n",
    "    \"공식 문서\": \"https://docs.opencv.org/\",\n",
    "    \"튜토리얼\": \"https://opencv-python-tutroals.readthedocs.io/\",\n",
    "    \"예제 코드\": \"https://github.com/opencv/opencv/tree/master/samples/python\",\n",
    "    \"커뮤니티\": \"https://stackoverflow.com/questions/tagged/opencv\",\n",
    "    \"고급 과정\": \"https://pyimagesearch.com/\"\n",
    "}\n",
    "\n",
    "for name, url in resources.items():\n",
    "    print(f\"  📌 {name}: {url}\")\n",
    "\n",
    "print(\"\\n🎯 실습 파일 정리:\")\n",
    "print(\"  오늘 생성된 파일들을 확인해보세요:\")\n",
    "print(\"  - screenshot_*.jpg (스크린샷들)\")\n",
    "print(\"  - opencv_effect_*.jpg (필터 효과들)\")\n",
    "print(\"  - face_detection_*.jpg (얼굴 인식 결과)\")\n",
    "print(\"  - photo_editor_*.jpg (포토 에디터 작품들)\")\n",
    "\n",
    "print(\"\\n💝 마지막 메시지:\")\n",
    "print(\"  컴퓨터 비전은 끝없이 발전하는 분야입니다.\")\n",
    "print(\"  오늘 배운 기초를 바탕으로 더 큰 꿈을 펼쳐보세요!\")\n",
    "print(\"  여러분의 창의적인 아이디어가 세상을 바꿀 수 있습니다!\")\n",
    "\n",
    "print(\"\\n\" + \"🎉\" * 20)\n",
    "print(\"  OpenCV 체험 학습 완료! 수고하셨습니다!\")\n",
    "print(\"🎉\" * 20)\n",
    "\n",
    "# 시스템 리소스 정리\n",
    "import gc\n",
    "gc.collect()  # 메모리 정리\n",
    "print(\"\\n🧹 시스템 리소스 정리 완료!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f6049e",
   "metadata": {},
   "source": [
    "## 🗂️ 보너스: OpenCV 치트시트\n",
    "\n",
    "### 📝 자주 사용하는 OpenCV 함수들\n",
    "\n",
    "```python\n",
    "# 이미지 읽기/쓰기/표시\n",
    "img = cv2.imread('image.jpg')           # 이미지 읽기\n",
    "cv2.imwrite('output.jpg', img)          # 이미지 저장\n",
    "cv2.imshow('window', img)               # 이미지 표시\n",
    "cv2.waitKey(0)                          # 키 입력 대기\n",
    "cv2.destroyAllWindows()                 # 모든 창 닫기\n",
    "\n",
    "# 기본 이미지 조작\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    # 회색조 변환\n",
    "resized = cv2.resize(img, (width, height))       # 크기 변경\n",
    "flipped = cv2.flip(img, 1)                      # 좌우 반전\n",
    "\n",
    "# 도형 그리기\n",
    "cv2.rectangle(img, (x1,y1), (x2,y2), (B,G,R), thickness)  # 사각형\n",
    "cv2.circle(img, (cx,cy), radius, (B,G,R), thickness)      # 원\n",
    "cv2.line(img, (x1,y1), (x2,y2), (B,G,R), thickness)      # 직선\n",
    "cv2.putText(img, 'text', (x,y), font, size, (B,G,R), thickness)  # 텍스트\n",
    "\n",
    "# 필터 효과\n",
    "blurred = cv2.GaussianBlur(img, (ksize, ksize), 0)        # 가우시안 블러\n",
    "bilateral = cv2.bilateralFilter(img, d, sigmaColor, sigmaSpace)  # 양방향 필터\n",
    "edges = cv2.Canny(gray, threshold1, threshold2)            # 엣지 검출\n",
    "\n",
    "# 웹캠 사용\n",
    "cap = cv2.VideoCapture(0)               # 웹캠 연결\n",
    "ret, frame = cap.read()                 # 프레임 읽기\n",
    "cap.release()                           # 웹캠 해제\n",
    "\n",
    "# 얼굴 인식\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor, minNeighbors)\n",
    "\n",
    "# 색상 변환 상수\n",
    "cv2.COLOR_BGR2GRAY, cv2.COLOR_BGR2HSV, cv2.COLOR_BGR2RGB\n",
    "\n",
    "# 폰트 종류\n",
    "cv2.FONT_HERSHEY_SIMPLEX, cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "# 키 코드 변환\n",
    "ord('q'), ord('s'), ord(' ')  # 문자를 ASCII 코드로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27f1f2a",
   "metadata": {},
   "source": [
    "### 💡 자주 하는 실수들\n",
    "1. **색상 순서**: OpenCV는 BGR, matplotlib은 RGB\n",
    "2. **데이터 타입**: uint8 (0-255) vs float32 (0.0-1.0)\n",
    "3. **좌표계**: (x, y) vs (row, col) 주의\n",
    "4. **메모리 해제**: 웹캠 사용 후 반드시 release()\n",
    "5. **키 입력**: waitKey()의 반환값은 & 0xFF 처리 필요\n",
    "\n",
    "### 📚 참고 자료\n",
    "- [OpenCV 공식 문서](https://docs.opencv.org/)\n",
    "- [OpenCV Python 튜토리얼](https://opencv-python-tutroals.readthedocs.io/)\n",
    "- [PyImageSearch](https://pyimagesearch.com/)\n",
    "\n",
    "이 치트시트를 참고하여 더 많은 OpenCV 프로젝트에 도전해보세요! 📚✨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba5df12",
   "metadata": {},
   "source": [
    "## 🎉 축하합니다! OpenCV 체험 학습 완료!\n",
    "\n",
    "### 🏆 오늘 여러분이 성취한 것들\n",
    "1. **✅ OpenCV 기초**: 이미지 생성, 조작, 표시\n",
    "2. **✅ 실시간 영상 처리**: 웹캠 활용 및 다양한 필터 적용\n",
    "3. **✅ 고급 이미지 변환**: 색상 공간, 히스토그램, 노이즈 제거\n",
    "4. **✅ 얼굴 인식**: AI 기반 객체 검출 체험\n",
    "5. **✅ 완전한 프로젝트**: 미니 포토 에디터 구현\n",
    "\n",
    "### 🚀 이제 여러분은...\n",
    "- **컴퓨터 비전의 기본 원리**를 이해했습니다\n",
    "- **실시간 이미지 처리 시스템**을 만들 수 있습니다\n",
    "- **AI와 OpenCV를 연동**할 준비가 되었습니다\n",
    "- **더 복잡한 컴퓨터 비전 프로젝트**에 도전할 수 있습니다\n",
    "\n",
    "### 💡 다음 단계 추천\n",
    "\n",
    "#### 초급 프로젝트\n",
    "- 간단한 **보안 카메라 시스템**\n",
    "- **색상 기반 객체 추적기**\n",
    "- **QR 코드 리더기**\n",
    "- 간단한 **문서 스캐너**\n",
    "\n",
    "#### 중급 프로젝트\n",
    "- **손 제스처 인식기**\n",
    "- **차선 검출 시스템**\n",
    "- **얼굴 표정 분석기**\n",
    "- **실시간 배경 제거**\n",
    "\n",
    "#### 고급 프로젝트\n",
    "- **증강현실 (AR) 앱**\n",
    "- **의료 영상 분석 도구**\n",
    "- **자율주행 시뮬레이션**\n",
    "- **산업용 품질 검사 시스템**\n",
    "\n",
    "### 📚 추천 학습 자료\n",
    "- **OpenCV 공식 문서**: [opencv.org](https://opencv.org/)\n",
    "- **PyImageSearch**: 실용적인 컴퓨터 비전 튜토리얼\n",
    "- **YouTube**: \"OpenCV Python Tutorial\" 시리즈\n",
    "- **GitHub**: OpenCV 예제 프로젝트들\n",
    "\n",
    "### 🔗 실무 연결고리\n",
    "오늘 배운 기술들은 실제로:\n",
    "- **테슬라**: 자율주행 시스템\n",
    "- **인스타그램**: 필터와 AR 효과  \n",
    "- **구글**: 이미지 검색 및 분석\n",
    "- **삼성**: 스마트폰 카메라 AI\n",
    "- **병원**: 의료 영상 진단 시스템\n",
    "\n",
    "에서 **핵심 기술**로 사용되고 있습니다!\n",
    "\n",
    "### 🎯 마지막 도전과제\n",
    "**여러분만의 창의적인 OpenCV 프로젝트**를 기획해보세요:\n",
    "1. **어떤 문제를 해결하고 싶나요?**\n",
    "2. **어떤 OpenCV 기능을 사용할 건가요?**\n",
    "3. **사용자는 어떻게 상호작용할 건가요?**\n",
    "\n",
    "### 👨‍💻 개발자로서의 첫걸음\n",
    "**컴퓨터 비전은 AI 시대의 핵심 기술입니다.** 오늘의 경험이 여러분을 **미래의 AI 개발자**로 이끌어줄 것입니다!\n",
    "\n",
    "**Keep coding, keep exploring! 🚀✨**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
